{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DotaBuddies**"
      ],
      "metadata": {
        "id": "TZzv25vDL9LQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A DOTA2 machine learning project by David Roper 40131739\n"
      ],
      "metadata": {
        "id": "Ejya6RzzH3fh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "COMP432 W"
      ],
      "metadata": {
        "id": "qUiy9qBkDnoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Professor: Dr. Mirco Ravanelli\n"
      ],
      "metadata": {
        "id": "FMIfC-WjDbw4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Project Advisor: Luca Della Libera"
      ],
      "metadata": {
        "id": "LBSbHj_VDblp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Abstract**\n",
        " \n",
        "\n",
        "   The goal of the DotaBuddies project was to create a machine learning model that can correctly predict the outcome of a DOTA2 match based on the heroes picked for each team, with future development of using the model for a hero recommendation application. Two different DNN (deep neural network) models were tested on two datasets, with one containing new match data from the OpenDOTA API, and the other created with the use of a Kaggle dataset. The results of the project reveal that the simpler of the two DNN models had the best test accuracy, whilst the more powerful model had a better training accuracy but had a the drawback of low test accuracies due to the effect of overfitting. It is concluded that the goal of a model test accuracy of 70% was not reached, which may be caused by the differences in the data factors and models compared to past projects. However with more tuning of the models hyperparameters and regularization techniques the models could still be promising. Future developments for the project are the addition of more match information into the feature vector (Hero bans, pick order) as well as changes to match data gathered as future updates happen to the game. "
      ],
      "metadata": {
        "id": "MP7fynuIMGlg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Introduction**\n",
        "\n"
      ],
      "metadata": {
        "id": "wBGDBctaMYYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DOTA2 is multiplayer online battle arena (MOBA) with hundreds of thousands of people playing daily. The games consists of two teams (the Dire and the Radiant) made up of five players each. The goal of the game is for players to pick their heroes, amass gold and items, and destroy the base of the opposing team. The problem that is trying to be solved by this project to trying to predict the outcome of DOTA2 matches based on the heroes picked by both teams. The importance of this problem is that the hero picking phase can heavily impact the outcome of which team wins the match, thus a model that can correctly predict said outcomes based on these heros picks would help users select the best heros to play with their team in order to win.\n",
        "\n",
        "One of the main challenges is producing a model that can accurate find trends in the heroes picked within each match and learn patterns to correctly which team wins. DOTA2 is a very intricate game in which many factors go into who will win the match, factors in the picking phase alone such as hero bans, pick orders, and the addition of new heros, can all have a effect on the match outcome, thus finding ways to predict based on heros picked alone can be diffcult. Another challenge faced was gathering and preprocessing the data in order to produce a proper feature vector input for the model. Data was taken from two locations, one being up to date match data from the OpenDOTA api, and the other from a Kaggle data set containing matches from an older version of the game. In both cases, the result of the match, and which heroes were picked for each team were extracted and placed into the datasets. Images of formats and info for the preprocessed data can be seen below:\n",
        "\n",
        "> ![OpenDota API](https://drive.google.com/uc?export=view&id=1X6yzL8weQAA7f-Zj1ddCc1pJhdv1Q7sh)\n",
        "\n",
        "> OpenDota Match Request Format\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> ![Stanford Vector](https://drive.google.com/uc?export=view&id=1YkIzDDZQ2lvVuY6cvjOSxi8F_VD0fSIC)\n",
        "> Kaggle Dataset info\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "A previous project that took a similar approach was the model produced by Stanford University students Kevin Conley and Daniel Perry. Their proposed solution used a Scikit learn Logistic Regression model which took in match data from the top 10% of Dota players [1]. The input feature vector contained a total of 216 possible values, which accounted for the 108 possible heroes to be played by both the dire and radiant teams [1]. Their output feature vector was a binary classification, which displays whether the radiant team won or not [1]. Their feature vector can be seen below:\n",
        "\n",
        "\n",
        "> ![Stanford Vector](https://drive.google.com/uc?export=view&id=1FupznQLSkrd6fLocosVaLkLUC0oIWuAs)\n",
        "\n",
        "Furthermore the way to calculate accuracy had to take into account for both dire and radiants chances of winning. In order to do so the top and bottom of the feature vectors are swapped and inputted into the model to predict if the dire team will win [1]. Then using these two predictions their model then calculated an overall probability of which team will win, then with using a sigmoid like function, it predicts if the radiant team will win if said probability is over 50% [1]. In the end their logistic regression model was able to correctly predict 69% of the matches of their test set [1].\n",
        "\n",
        "The proposed solution will be promising as it will be taught with match data that is most applicable to the average DOTA2 player as well as being the more up to date with game balance changes compared to previous projects. For example, the DOTA2 Project previously mentioned only took match data from the top 10% of DOTA players, thus making prediction assuming the Hero is played to their maximum potential [1]. The model produced from this project used data from all skill levels thus making it more applicable to the average player who are not experts at playing certain heros. \n",
        "\n",
        "As for why this solution is promising in a Machine Learning standpoint, the predictions created by the models had an accuracy of over 50%. Since prediction which of two teams one is a binary classification problem, and the usual win rates for each team are around 50%. Any model that can predict correctly above that percentage is already an improvement and confirms that the model is in fact learning from the match data. Furthermore, the models created with the use of PyTorch, unlike the SciKit learn regression models produced by previous projects [1]. This allows for more freedom to edit hyper parameters and allows for faster training using the CUDA GPU option.  \n",
        "\n",
        "However, it will be seen from the results of the models that with future DOTA2 updates and the addition of new heros, that performance reduces as it has to account for more possible hero combinations. Thus changes may have to be done to the feature vectors and model complexity in order to keep up with these changes. \n",
        "\n",
        "\n",
        "As for the results from the multiple models, the ones using old match data from the Kaggle dataset has the best overall accuracies of around 57% to 59% for the test set and 70% for the training set. Whilst the models training on the new match data from the OpenDota API had an accuracy of 52% to 55% for the test set and an training set accuracy of around 54% before early stopping. It was also seen through the results that there was a slight overfit within the models, and that as the feature vector increases with the addition of more heroes, finding ways to improve the accuracies with this feature vector format becomes more diffcult."
      ],
      "metadata": {
        "id": "08_Iuhd6JWQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Methodology**\n"
      ],
      "metadata": {
        "id": "XtzOOJDnMpWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing DotaBuddies data files from drive."
      ],
      "metadata": {
        "id": "YJ2ABzLHreA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 13zc8SNTRcrIMtQIdd_OB0Augj7kdWk_x\n",
        "!unzip -u \"/content/DotabuddiesData-20230423T030150Z-001.zip\" -d \"/content\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKN5nMGzC4MY",
        "outputId": "de07333b-46c6-4522-b1ad-827a0bf91415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13zc8SNTRcrIMtQIdd_OB0Augj7kdWk_x\n",
            "To: /content/DotabuddiesData-20230423T030150Z-001.zip\n",
            "100% 49.2M/49.2M [00:00<00:00, 70.9MB/s]\n",
            "Archive:  /content/DotabuddiesData-20230423T030150Z-001.zip\n",
            "  inflating: /content/DotabuddiesData/heroes.json  \n",
            "   creating: /content/DotabuddiesData/.ipynb_checkpoints/\n",
            "  inflating: /content/DotabuddiesData/oldmatchdata.csv  \n",
            "  inflating: /content/DotabuddiesData/match.csv  \n",
            "  inflating: /content/DotabuddiesData/newmatchdata.csv  \n",
            "  inflating: /content/DotabuddiesData/players.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import warnings\n",
        "import sklearn\n",
        "import sklearn.model_selection\n",
        "!pip install skorch\n",
        "import skorch\n",
        "np.set_printoptions(precision=3, suppress=True)  # Print as 0.001 instead of 9.876e-4\n",
        "torch.set_printoptions(precision=3, sci_mode=False)"
      ],
      "metadata": {
        "id": "yd6w0NfAOsBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce52969a-cca7-4f1d-d933-477bfdfa443c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There were many steps taken in order to achieve the goal of this project, the important steps in order to repeat this project are the preprocessing of both versions of data, the reforming of feature vectors to fit said data, the creation of new deep neural network models with the use of PyTorch, and result comparison of these models. \n",
        "\n",
        "For the preprocessing of the data two csv files were created for both data gathering options as previously mentioned. These final csv files were then processed in to the feature vectors of the models. The originality of the feature vectors, although similar to that of the Stanford project, is that they both contain more possible heroes for both teams, thus increasing the feature space for the models. The theory behind each feature vector can be seen below: \n",
        "\n",
        "> ![Stanford Vector](https://drive.google.com/uc?export=view&id=1g8B6tKwvzoB5DyNY0d1s7cZImdnsnPKW)\n",
        "\n",
        "As seen here the new match data included 138 playable heroes, whilst the old dataset contains 113 heroes, both of which are larger than the 108 possible heroes of the Stanford Project. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rQIOEiWz54DW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to produce the match data needed to train the machine, the matches and information were gathered and manipulated into appropriate formats. The initial data gathering took place using a DOTA2 API known as OpenDOTA [2]. A python script was created to schedule requests for match data. totaling to 40000 matches worth of data. the data was then taken from the JSON request format and converted into a feature friendly CSV data file. The code to produce the data can be seen below. Note that the script is time limited, as the OpenDota API has a request limit of 50 per minute (total of 8 minutes): \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bzGTdf4gPX9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import csv\n",
        "import time\n",
        "\n",
        "last_match_id = ''\n",
        "with open('DotabuddiesData/newmatchdataSample.csv', 'w') as f:\n",
        "    write = csv.writer(f)\n",
        "    write.writerow(['radiant_win','rhero1','rhero2','rhero3','rhero4','rhero5','dhero1','dhero2','dhero3','dhero4','dhero5'])\n",
        "for j in range(8):\n",
        "    \n",
        "    for i in range(50):\n",
        "\n",
        "        url = 'https://api.opendota.com/api/publicMatches?game_mode=22' + last_match_id\n",
        "\n",
        "        response = requests.get(url)\n",
        "\n",
        "        data = response.json()\n",
        "\n",
        "        last = data[0]['match_id']\n",
        "        for d in data:\n",
        "            \n",
        "            win = d['radiant_win']\n",
        "            rHeroes = d['radiant_team'].split(',')\n",
        "            dHeroes = d['dire_team'].split(',')\n",
        "            \n",
        "            toCsv = []\n",
        "            toCsv.append(int(win))\n",
        "            toCsv.extend(rHeroes)\n",
        "            toCsv.extend(dHeroes)\n",
        "            toCsv = [toCsv]\n",
        "\n",
        "            if(d['match_id'] < last):\n",
        "                last = d['match_id'] \n",
        "            \n",
        "\n",
        "            with open('DotabuddiesData/newmatchdata.csv', 'a') as f:\n",
        "                write = csv.writer(f)\n",
        "                write.writerow(toCsv[0])\n",
        "            \n",
        "            \n",
        "            last_match_id = '&less_than_match_id=' + str(last)\n",
        "        print('done match: ', i)\n",
        "    print('last match: ', last)  \n",
        "    time.sleep(60)"
      ],
      "metadata": {
        "id": "XvIB1dd4OXBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "newmatches = pd.read_csv('DotabuddiesData/newmatchdata.csv')\n",
        "print(newmatches)"
      ],
      "metadata": {
        "id": "mOsxAV6CHh7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second form of data was taken from a kaggle dataset. This dataset contains csv files holding information of 50000 matches [3]. However this data has many stark differences than that of the API version. The data was from a older version of a game, thus it did not contain as many heroes which meant that the model had to be adapted differently. The data was taken from the csv files and reformated into a feature friendly version with the use of Pandas. The script to access the Kaggle CSV files a reformat it can be seen below:"
      ],
      "metadata": {
        "id": "UkKEk5hs_yMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "fields = ['match_id','radiant_win']\n",
        "\n",
        "df = pd.read_csv('DotabuddiesData/match.csv',skipinitialspace=True, usecols=fields)\n",
        "\n",
        "df['radiant_win'] = df['radiant_win'].astype(int)\n",
        "\n",
        "fields2 = ['match_id','hero_id']\n",
        "\n",
        "heros = pd.read_csv('DotabuddiesData/players.csv',skipinitialspace=True, usecols=fields2)\n",
        "\n",
        "with open('DotabuddiesData/oldmatchdata.csv', 'w') as f:\n",
        "    write = csv.writer(f)\n",
        "    write.writerow(['radiant_win','rhero1','rhero2','rhero3','rhero4','rhero5','dhero1','dhero2','dhero3','dhero4','dhero5'])\n",
        "\n",
        "for match in df.match_id:\n",
        "    herosPlayed = heros.loc[heros['match_id'] == match]\n",
        "    heroslist = herosPlayed['hero_id'].values.tolist()\n",
        "    \n",
        "    dlist = df['radiant_win'].values[match].tolist()\n",
        "    \n",
        "    \n",
        "    fList = [dlist] + heroslist\n",
        "    \n",
        "    with open('DotabuddiesData/oldmatchdata.csv', 'a') as f:\n",
        "        write = csv.writer(f)\n",
        "        write.writerow(fList)\n",
        "    \n",
        "    \n"
      ],
      "metadata": {
        "id": "KJy7125dGtG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "kaggledf = pd.read_csv('DotabuddiesData/oldmatchdata.csv')\n",
        "print(kaggledf)"
      ],
      "metadata": {
        "id": "EbAATprmF3pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally the feature vectors were produced by extracting the hero ids and match outcome from the final csv. An example of feature vector creation can be seen below. The feature vector contains all possible heroes for both teams in a one-hot format:"
      ],
      "metadata": {
        "id": "-vVVh8mlSsad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#adding match data from file\n",
        "\n",
        "data = np.loadtxt('DotabuddiesData/newmatchdata.csv',skiprows=1,delimiter=',')\n",
        "X_data = np.array(data[:,1:]).astype(np.int32)\n",
        "y_data = np.array(data[:,:1]).astype(np.int32)\n",
        "\n",
        "#turn all data into feature vector\n",
        "#feature vector creation\n",
        "X_val_trn = torch.zeros((40000,138*2),dtype=torch.float32)\n",
        "j = 0\n",
        "\n",
        "#creation of feature vector\n",
        "for d in X_data:\n",
        "    for i in range(len(d)):\n",
        "        #check if the heros are on radiant side\n",
        "        if(i < len(d)/2):\n",
        "            #increment the position the equals the hero id\n",
        "            # in the tensor by 1 \n",
        "            h = d[i]\n",
        "            X_val_trn[j][h] += 1\n",
        "            \n",
        "            \n",
        "        else:\n",
        "          #increment the position that equals \n",
        "          #the (hero id + total_heroes) in the tensor by 1 \n",
        "            h = d[i]\n",
        "            X_val_trn[j][h+137] += 1\n",
        "      \n",
        "    j += 1\n",
        "\n",
        "#print an example feature vector\n",
        "print(X_val_trn[30])"
      ],
      "metadata": {
        "id": "tXDvK6tATPV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After creating the feature vector, the data was the split into train/test groups with a ratio of 80% training data and 20% test data. The training set was then further split to a training/validation set of a 85%/15% ratio."
      ],
      "metadata": {
        "id": "uIpHTn-cVQfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sklearn train test split\n",
        "\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_val_trn,y_data, test_size = 0.2, shuffle= True)\n",
        "\n",
        "#split train into train/validation set\n",
        "\n",
        "X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(X_train,y_train, test_size = 0.15, shuffle= True)\n",
        "\n",
        "X_train = torch.tensor(X_train,dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train,dtype=torch.float32)\n",
        "\n",
        "X_val = torch.tensor(X_val,dtype=torch.float32)\n",
        "\n",
        "y_val = torch.tensor(y_val,dtype=torch.float32)\n",
        "\n",
        "X_test = torch.tensor(X_test,dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test,dtype=torch.float32)"
      ],
      "metadata": {
        "id": "dxKP4EgvVPVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The models produced for this project were all different DNN models of varying complexities. Unlike the related project mentioned, they were produced using PyTorch and used CUDA gpu in order to process the data. The models linear layers of neurons as well as non-linear activation functions in order to process the data (ReLU), regularization techniques used within the model are dropout and batchnorm in order to reduce overfitting the data. The result of the model were run the a binary classification layer (BCELogits), as well as a overall probability calculation similar to that of the past project. the formula for the overall probablilty function as well as diagrams for the models can be seen below.\n",
        "\n",
        "> ![OvrProb Calculation](https://drive.google.com/uc?export=view&id=1swRJiHJwR2qabedXJ2JCF9lNnfSQGJc2)\n",
        "\n",
        "> Calculation of overall probability\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wvcizP_4H1py"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> ![model 1](https://drive.google.com/uc?export=view&id=1_Ic51tt3P67z_U5HOpVHN-96VsgG8tqP)\n",
        "\n",
        "> Model 1: Simple DNN model"
      ],
      "metadata": {
        "id": "vbYnP7sBfdD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> ![model 2](https://drive.google.com/uc?export=view&id=1Q4xGEScOJQ-rnmUStRwfEIxQEoun15OU)\n",
        "\n",
        "> Model 2: Regularized DNN model for OpenDota Matches"
      ],
      "metadata": {
        "id": "-ahjmXKgfc41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ![model 3](https://drive.google.com/uc?export=view&id=18nWgff4nep46ja3FAKd-a_SSOYEDC6qf)\n",
        "\n",
        "> Model 3: Regularized DNN model for Kaggle Matches"
      ],
      "metadata": {
        "id": "HjHYDWXgfcor"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As for finding the best hyperparameters for each model, a gridsearch for PyTorch model as long the train/test split data was done using the skorch package. However this discovery was made later on in the project, when preferrable hyperparameters were already found thus it was more for insight into other possible parameters than initial starting point. In addition, the grid search was also rather slow, making more difficult to find the proper hyperparameters. Even with these flaws the method will still be important in discovering more optimal hyperparameters in the future."
      ],
      "metadata": {
        "id": "ZCoHySxNQzCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import warnings\n",
        "import sklearn\n",
        "import sklearn.model_selection\n",
        "!pip install skorch\n",
        "import skorch\n",
        "np.set_printoptions(precision=3, suppress=True)  # Print as 0.001 instead of 9.876e-4\n",
        "torch.set_printoptions(precision=3, sci_mode=False)"
      ],
      "metadata": {
        "id": "54HGQgPlR8sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skorch import NeuralNetClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "neuralmodel = torch.nn.Sequential(\n",
        "   torch.nn.Linear(276,16),\n",
        "   torch.nn.ReLU(),\n",
        "   torch.nn.Linear(16,1)\n",
        ")\n",
        "\n",
        "model = skorch.NeuralNetClassifier(\n",
        "   neuralmodel,\n",
        "   criterion = torch.nn.BCEWithLogitsLoss(),\n",
        "   max_epochs = 50,\n",
        "   batch_size = 800,\n",
        "   verbose = False\n",
        "\n",
        ")\n",
        "\n",
        "# define the grid search parameters\n",
        "param_grid = {\n",
        "    'optimizer__lr': [1e-5, 1.5e-5],\n",
        "    'optimizer__weight_decay': [ 2e-3, 2.2e-3],\n",
        "}\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uli-dmYkSBcx",
        "outputId": "210a63fe-8e0f-4394-c4ad-f45968ec71df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.495515 using {'optimizer__lr': 1e-05, 'optimizer__weight_decay': 0.002}\n",
            "0.495515 (0.000026) with: {'optimizer__lr': 1e-05, 'optimizer__weight_decay': 0.002}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " The best optimizer used for the models is Adam, as it provided adaptive estimation of the base learning rate, as well as providing an easy way to include L2 regularization into the model (weight decay) in order to help the models generalization. The model that performed the best was the 3rd model on the data from the kaggle dataset, which provided a good training, validation and test accuracy. "
      ],
      "metadata": {
        "id": "BoztSIjchAYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Experimental Setup**\n"
      ],
      "metadata": {
        "id": "YIQOcLeaPq3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As previously mentioned the dataset used for the models were 40000 matches gathered the use of an API, and 50000 matches from a kaggle data set. With use of Pandas and JSON packages, the match data was extract a processed into a csv contain eleven columns, the first column is a binary value if the radiant team won the match. the next five columns contains the hero identification numbers picked on the radiant team and the last 5 are the ids of the heros picked by the dire team. An example of the formatted code can be seen below:"
      ],
      "metadata": {
        "id": "tZIqTbRTXmO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kaggledf = pd.read_csv('DotabuddiesData/oldmatchdata.csv')\n",
        "print(kaggledf)"
      ],
      "metadata": {
        "id": "aDQYvbsrg01C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As for the machine learning techniques used, all the models were produces and trained with Pytorch's BCELogits loss function and Adam optimizer. In addition to the test and training sets for the models, a validation set was also created in order to identify issues such as overfitting. \n",
        "\n",
        "In addition to the linear neuron layers, non-linear (ReLU) layers were added in order to improve the models ability to recognize for complex patterns and dependencies within the data. Furthermore, regularization layers such as drop rates and batchnorm were added in order to decrease the affects of overfitting. \n",
        "\n",
        "Hyperparameters that needed tuning during the project were the learning rate, the batch size (size of data increment ran through the model), epochs (number of runs through the data), and the L2 regularization weight decay values. \n",
        "\n",
        "Code for how to produce and run the models is the following:"
      ],
      "metadata": {
        "id": "u3kvQ0org9LA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the pytorch and sklearn packages"
      ],
      "metadata": {
        "id": "dvqkFtRzPNwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import warnings\n",
        "import sklearn\n",
        "import sklearn.model_selection\n",
        "!pip install skorch\n",
        "import skorch\n",
        "np.set_printoptions(precision=3, suppress=True)  # Print as 0.001 instead of 9.876e-4\n",
        "torch.set_printoptions(precision=3, sci_mode=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egS4nqPYOJpi",
        "outputId": "6e62475d-0f0f-465c-9d53-3858dd4fcdab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: skorch in /usr/local/lib/python3.9/dist-packages (0.12.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.9/dist-packages (from skorch) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.9/dist-packages (from skorch) (4.65.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.9/dist-packages (from skorch) (0.8.10)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from skorch) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.9/dist-packages (from skorch) (1.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.22.0->skorch) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.22.0->skorch) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating feature vector for new match data"
      ],
      "metadata": {
        "id": "7PvBZTU7cyGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#adding match data from file\n",
        "\n",
        "data = np.loadtxt('DotabuddiesData/newmatchdata.csv',skiprows=1,delimiter=',')\n",
        "X_data = np.array(data[:,1:]).astype(np.int32)\n",
        "y_data = np.array(data[:,:1]).astype(np.int32)\n",
        "\n",
        "#turn all data into feature vector\n",
        "#feature vector creation\n",
        "X_val_trn = torch.zeros((40000,138*2),dtype=torch.float32)\n",
        "j = 0\n",
        "\n",
        "#creation of feature vector\n",
        "for d in X_data:\n",
        "    for i in range(len(d)):\n",
        "        #check if the heros are on radiant side\n",
        "        if(i < len(d)/2):\n",
        "            #increment the position the equals the hero id\n",
        "            # in the tensor by 1 \n",
        "            h = d[i]\n",
        "            X_val_trn[j][h] += 1\n",
        "            \n",
        "            \n",
        "        else:\n",
        "          #increment the position that equals \n",
        "          #the (hero id + total_heroes) in the tensor by 1 \n",
        "            h = d[i]\n",
        "            X_val_trn[j][h+137] += 1\n",
        "      \n",
        "    j += 1"
      ],
      "metadata": {
        "id": "u7GSm-SZcxvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating train/test split"
      ],
      "metadata": {
        "id": "tGYo5Lsic7jO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sklearn train test split\n",
        "\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_val_trn,y_data, test_size = 0.2, shuffle= True)\n",
        "\n",
        "#split train into train/validation set\n",
        "\n",
        "X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(X_train,y_train, test_size = 0.15, shuffle= True)\n",
        "\n",
        "X_train = torch.tensor(X_train,dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train,dtype=torch.float32)\n",
        "\n",
        "X_val = torch.tensor(X_val,dtype=torch.float32)\n",
        "\n",
        "y_val = torch.tensor(y_val,dtype=torch.float32)\n",
        "\n",
        "X_test = torch.tensor(X_test,dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test,dtype=torch.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv2yLlWuc5bw",
        "outputId": "209ea614-1fc0-4183-ed23-1586b3b9855a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-106-1addabef4563>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_train = torch.tensor(X_train,dtype=torch.float32)\n",
            "<ipython-input-106-1addabef4563>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_val = torch.tensor(X_val,dtype=torch.float32)\n",
            "<ipython-input-106-1addabef4563>:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_test = torch.tensor(X_test,dtype=torch.float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training and Testing**\n",
        "\n",
        "The following code shows the training and testing of each model and dataset. The training loops involve producing a label prediction (predicting which team won), which is then compared to the actual outcome. These two values are then put into the BCELogitsloss function in order to calculate loss, which is then used in the backward function in order to further progress the solution gradient after reseting the gradient values back to zero. The Adam optimizer then uses this loss calculation in order to make a gradient step in a direction of a possible solution. Losses and accuracies for both training and validation sets are calculated with the overall probability function used for the former. \n",
        "\n",
        "The test accuracies are calculated at the end of training, in which the overall probability function is used again. \n",
        "\n"
      ],
      "metadata": {
        "id": "TyMPZnY5lbV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up CUDA"
      ],
      "metadata": {
        "id": "g9W4BTe9PnZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available(): \n",
        " dev = \"cuda:0\" \n",
        "else: \n",
        " dev = \"cpu\" \n",
        "device = torch.device(dev)"
      ],
      "metadata": {
        "id": "N1I7ow-MPHS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training model 1 on match data from OpenDota API, the following hyperparameters provided the best results early stopping was not included as the data was not overfitting within this model:\n",
        "\n",
        "* Learning rate = 2.7e-5\n",
        "* Optimizer = Adam\n",
        "* weight decay (L2 regularization) = 1.5e-3\n",
        "* Batchsize = 400\n",
        "* Epochs = 600"
      ],
      "metadata": {
        "id": "N5P-nfI3iqOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skorch import NeuralNetClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#lists for matplot graphing\n",
        "new_model1_val_acc = []\n",
        "new_model1_train_acc = []\n",
        "new_model1_val_loss = []\n",
        "new_model1_train_loss = []\n",
        "epochs_1 = []\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "   torch.nn.Linear(276,16),\n",
        "   torch.nn.ReLU(),\n",
        "   torch.nn.Linear(16,1)\n",
        ")\n",
        "\n",
        "\n",
        "if torch.cuda.is_available(): \n",
        " dev = \"cuda:0\" \n",
        "else: \n",
        " dev = \"cpu\" \n",
        "device = torch.device(dev)\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "#loss function and optimizer\n",
        "loss = torch.nn.BCEWithLogitsLoss()\n",
        "optim = torch.optim.Adam(model.parameters(),lr=2.7e-5, weight_decay=1.5e-3)\n",
        "\n",
        "#epoch number\n",
        "num_epoch = 600\n",
        "next_epoch = 1\n",
        "batch_size = 400\n",
        "\n",
        "\n",
        "valid_loss = 100000000000\n",
        "loss_flag = False\n",
        "\n",
        "#training loop\n",
        "for epoch in range(next_epoch, next_epoch+num_epoch):\n",
        "    #put model in training mode\n",
        "    model.train()\n",
        "    \n",
        "    \n",
        "    # Make an entire pass (an 'epoch') over the training data in batch_size chunks\n",
        "    for i in range(0, len(X_train), batch_size):        \n",
        "        X = X_train[i:i+batch_size].to(device)     # Slice out a mini-batch of features\n",
        "        y = y_train[i:i+batch_size].to(device)     # Slice out a mini-batch of targets\n",
        "        \n",
        "        \n",
        "        # Make predictions with model\n",
        "        y_pred = model(X)                   \n",
        "        \n",
        "        l = loss(y_pred, y)                 # Compute loss with respect to predictions\n",
        "        \n",
        "        model.zero_grad()                   # Reset all gradient accumulators to zero\n",
        "        l.backward()                        # Compute gradient of loss with backprop\n",
        "        optim.step()                    # Use the gradients to take a step with Adam.\n",
        "        \n",
        "    print(\"Epoch %2d: loss on final training batch: %.4f\" % (epoch, l.item()))\n",
        "    \n",
        "    #put model into eval mode\n",
        "    model.eval()\n",
        "\n",
        "    #create dire query\n",
        "    \n",
        "    #validation set calculations\n",
        "    dire_X =  torch.index_select(X_val, 1, torch.LongTensor([*range(138,276)]))\n",
        "    dire_X = torch.cat((dire_X,torch.index_select(X_val, 1, torch.LongTensor([*range(0,138)]))),1).to(device)\n",
        "\n",
        "    dire_pred = (model(dire_X) >= 0).float()\n",
        "    \n",
        "    \n",
        "    rad_pred = (model(X_val.to(device)) >= 0).float()\n",
        "    \n",
        "    #calculation of overall probability\n",
        "    overall_prob = (((rad_pred + (1 - dire_pred))/2) > 0.5).float()\n",
        "    \n",
        "    val_acc = torch.mean((overall_prob.to('cpu') == y_val.to('cpu')).float())\n",
        "\n",
        "    #training set calculations\n",
        "    dire_X_train =  torch.index_select(X_train, 1, torch.LongTensor([*range(138,276)]))\n",
        "    dire_X_train = torch.cat((dire_X_train,torch.index_select(X_train, 1, torch.LongTensor([*range(0,138)]))),1).to(device)\n",
        "\n",
        "    dire_pred = (model(dire_X_train) >= 0).float()\n",
        "    \n",
        "    rad_pred = (model(X_train.to(device)) >= 0).float()\n",
        "    \n",
        "\n",
        "    overall_prob = (((rad_pred + (1 - dire_pred))/2) > 0.5).float()\n",
        "    \n",
        "    train_acc = torch.mean((overall_prob.to('cpu') == y_train.to('cpu')).float())\n",
        "    \n",
        "    print(\"Epoch %2d: accuracy on validation set: %.4f\" % (epoch, val_acc))\n",
        "    print(\"Epoch %2d: accuracy on training set: %.4f\" % (epoch, train_acc))\n",
        "    \n",
        "    print(\"Epoch %2d: loss on validation set: %.4f\" % (epoch, loss(model(X_val.to(device)), y_val.to(device))))\n",
        "    new_val_loss = loss(model(X_val.to(device)), y_val.to(device))\n",
        "\n",
        "    \n",
        "    #append info for matplot graphs\n",
        "    new_model1_val_acc.append(val_acc)\n",
        "    new_model1_train_acc.append(train_acc)\n",
        "    new_model1_val_loss.append(new_val_loss.item())\n",
        "    new_model1_train_loss.append(l.item())\n",
        "    epochs_1.append(epoch)\n",
        "       \n",
        "\n",
        "    valid_loss = new_val_loss\n",
        "    \n",
        "   \n",
        "\n",
        "next_epoch = epoch+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AAahjhRip9V",
        "outputId": "b84f2e25-6ab3-49f9-cd0f-96a8e19e4c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1: loss on final training batch: 0.6981\n",
            "Epoch  1: accuracy on validation set: 0.4994\n",
            "Epoch  1: accuracy on training set: 0.4938\n",
            "Epoch  1: loss on validation set: 0.6980\n",
            "Epoch  2: loss on final training batch: 0.6976\n",
            "Epoch  2: accuracy on validation set: 0.4994\n",
            "Epoch  2: accuracy on training set: 0.4938\n",
            "Epoch  2: loss on validation set: 0.6975\n",
            "Epoch  3: loss on final training batch: 0.6971\n",
            "Epoch  3: accuracy on validation set: 0.4994\n",
            "Epoch  3: accuracy on training set: 0.4938\n",
            "Epoch  3: loss on validation set: 0.6970\n",
            "Epoch  4: loss on final training batch: 0.6966\n",
            "Epoch  4: accuracy on validation set: 0.4994\n",
            "Epoch  4: accuracy on training set: 0.4938\n",
            "Epoch  4: loss on validation set: 0.6966\n",
            "Epoch  5: loss on final training batch: 0.6962\n",
            "Epoch  5: accuracy on validation set: 0.4994\n",
            "Epoch  5: accuracy on training set: 0.4938\n",
            "Epoch  5: loss on validation set: 0.6961\n",
            "Epoch  6: loss on final training batch: 0.6957\n",
            "Epoch  6: accuracy on validation set: 0.4994\n",
            "Epoch  6: accuracy on training set: 0.4938\n",
            "Epoch  6: loss on validation set: 0.6957\n",
            "Epoch  7: loss on final training batch: 0.6953\n",
            "Epoch  7: accuracy on validation set: 0.4994\n",
            "Epoch  7: accuracy on training set: 0.4938\n",
            "Epoch  7: loss on validation set: 0.6953\n",
            "Epoch  8: loss on final training batch: 0.6948\n",
            "Epoch  8: accuracy on validation set: 0.4994\n",
            "Epoch  8: accuracy on training set: 0.4938\n",
            "Epoch  8: loss on validation set: 0.6949\n",
            "Epoch  9: loss on final training batch: 0.6944\n",
            "Epoch  9: accuracy on validation set: 0.4994\n",
            "Epoch  9: accuracy on training set: 0.4938\n",
            "Epoch  9: loss on validation set: 0.6945\n",
            "Epoch 10: loss on final training batch: 0.6940\n",
            "Epoch 10: accuracy on validation set: 0.4994\n",
            "Epoch 10: accuracy on training set: 0.4937\n",
            "Epoch 10: loss on validation set: 0.6942\n",
            "Epoch 11: loss on final training batch: 0.6936\n",
            "Epoch 11: accuracy on validation set: 0.4996\n",
            "Epoch 11: accuracy on training set: 0.4937\n",
            "Epoch 11: loss on validation set: 0.6938\n",
            "Epoch 12: loss on final training batch: 0.6932\n",
            "Epoch 12: accuracy on validation set: 0.4996\n",
            "Epoch 12: accuracy on training set: 0.4936\n",
            "Epoch 12: loss on validation set: 0.6935\n",
            "Epoch 13: loss on final training batch: 0.6928\n",
            "Epoch 13: accuracy on validation set: 0.4990\n",
            "Epoch 13: accuracy on training set: 0.4937\n",
            "Epoch 13: loss on validation set: 0.6932\n",
            "Epoch 14: loss on final training batch: 0.6924\n",
            "Epoch 14: accuracy on validation set: 0.4988\n",
            "Epoch 14: accuracy on training set: 0.4939\n",
            "Epoch 14: loss on validation set: 0.6929\n",
            "Epoch 15: loss on final training batch: 0.6921\n",
            "Epoch 15: accuracy on validation set: 0.4981\n",
            "Epoch 15: accuracy on training set: 0.4940\n",
            "Epoch 15: loss on validation set: 0.6926\n",
            "Epoch 16: loss on final training batch: 0.6917\n",
            "Epoch 16: accuracy on validation set: 0.4981\n",
            "Epoch 16: accuracy on training set: 0.4942\n",
            "Epoch 16: loss on validation set: 0.6923\n",
            "Epoch 17: loss on final training batch: 0.6914\n",
            "Epoch 17: accuracy on validation set: 0.4965\n",
            "Epoch 17: accuracy on training set: 0.4937\n",
            "Epoch 17: loss on validation set: 0.6920\n",
            "Epoch 18: loss on final training batch: 0.6911\n",
            "Epoch 18: accuracy on validation set: 0.4960\n",
            "Epoch 18: accuracy on training set: 0.4944\n",
            "Epoch 18: loss on validation set: 0.6917\n",
            "Epoch 19: loss on final training batch: 0.6908\n",
            "Epoch 19: accuracy on validation set: 0.4954\n",
            "Epoch 19: accuracy on training set: 0.4948\n",
            "Epoch 19: loss on validation set: 0.6915\n",
            "Epoch 20: loss on final training batch: 0.6905\n",
            "Epoch 20: accuracy on validation set: 0.4944\n",
            "Epoch 20: accuracy on training set: 0.4949\n",
            "Epoch 20: loss on validation set: 0.6912\n",
            "Epoch 21: loss on final training batch: 0.6902\n",
            "Epoch 21: accuracy on validation set: 0.4967\n",
            "Epoch 21: accuracy on training set: 0.4953\n",
            "Epoch 21: loss on validation set: 0.6910\n",
            "Epoch 22: loss on final training batch: 0.6899\n",
            "Epoch 22: accuracy on validation set: 0.4988\n",
            "Epoch 22: accuracy on training set: 0.4962\n",
            "Epoch 22: loss on validation set: 0.6907\n",
            "Epoch 23: loss on final training batch: 0.6897\n",
            "Epoch 23: accuracy on validation set: 0.4994\n",
            "Epoch 23: accuracy on training set: 0.4973\n",
            "Epoch 23: loss on validation set: 0.6905\n",
            "Epoch 24: loss on final training batch: 0.6894\n",
            "Epoch 24: accuracy on validation set: 0.4992\n",
            "Epoch 24: accuracy on training set: 0.4989\n",
            "Epoch 24: loss on validation set: 0.6903\n",
            "Epoch 25: loss on final training batch: 0.6891\n",
            "Epoch 25: accuracy on validation set: 0.4990\n",
            "Epoch 25: accuracy on training set: 0.5015\n",
            "Epoch 25: loss on validation set: 0.6901\n",
            "Epoch 26: loss on final training batch: 0.6889\n",
            "Epoch 26: accuracy on validation set: 0.4996\n",
            "Epoch 26: accuracy on training set: 0.5024\n",
            "Epoch 26: loss on validation set: 0.6899\n",
            "Epoch 27: loss on final training batch: 0.6886\n",
            "Epoch 27: accuracy on validation set: 0.5023\n",
            "Epoch 27: accuracy on training set: 0.5029\n",
            "Epoch 27: loss on validation set: 0.6897\n",
            "Epoch 28: loss on final training batch: 0.6884\n",
            "Epoch 28: accuracy on validation set: 0.5092\n",
            "Epoch 28: accuracy on training set: 0.5044\n",
            "Epoch 28: loss on validation set: 0.6894\n",
            "Epoch 29: loss on final training batch: 0.6881\n",
            "Epoch 29: accuracy on validation set: 0.5100\n",
            "Epoch 29: accuracy on training set: 0.5061\n",
            "Epoch 29: loss on validation set: 0.6892\n",
            "Epoch 30: loss on final training batch: 0.6879\n",
            "Epoch 30: accuracy on validation set: 0.5110\n",
            "Epoch 30: accuracy on training set: 0.5091\n",
            "Epoch 30: loss on validation set: 0.6890\n",
            "Epoch 31: loss on final training batch: 0.6876\n",
            "Epoch 31: accuracy on validation set: 0.5108\n",
            "Epoch 31: accuracy on training set: 0.5117\n",
            "Epoch 31: loss on validation set: 0.6889\n",
            "Epoch 32: loss on final training batch: 0.6874\n",
            "Epoch 32: accuracy on validation set: 0.5129\n",
            "Epoch 32: accuracy on training set: 0.5139\n",
            "Epoch 32: loss on validation set: 0.6887\n",
            "Epoch 33: loss on final training batch: 0.6871\n",
            "Epoch 33: accuracy on validation set: 0.5169\n",
            "Epoch 33: accuracy on training set: 0.5151\n",
            "Epoch 33: loss on validation set: 0.6885\n",
            "Epoch 34: loss on final training batch: 0.6869\n",
            "Epoch 34: accuracy on validation set: 0.5160\n",
            "Epoch 34: accuracy on training set: 0.5162\n",
            "Epoch 34: loss on validation set: 0.6883\n",
            "Epoch 35: loss on final training batch: 0.6867\n",
            "Epoch 35: accuracy on validation set: 0.5185\n",
            "Epoch 35: accuracy on training set: 0.5166\n",
            "Epoch 35: loss on validation set: 0.6881\n",
            "Epoch 36: loss on final training batch: 0.6864\n",
            "Epoch 36: accuracy on validation set: 0.5202\n",
            "Epoch 36: accuracy on training set: 0.5181\n",
            "Epoch 36: loss on validation set: 0.6879\n",
            "Epoch 37: loss on final training batch: 0.6862\n",
            "Epoch 37: accuracy on validation set: 0.5221\n",
            "Epoch 37: accuracy on training set: 0.5188\n",
            "Epoch 37: loss on validation set: 0.6877\n",
            "Epoch 38: loss on final training batch: 0.6860\n",
            "Epoch 38: accuracy on validation set: 0.5235\n",
            "Epoch 38: accuracy on training set: 0.5198\n",
            "Epoch 38: loss on validation set: 0.6875\n",
            "Epoch 39: loss on final training batch: 0.6858\n",
            "Epoch 39: accuracy on validation set: 0.5231\n",
            "Epoch 39: accuracy on training set: 0.5206\n",
            "Epoch 39: loss on validation set: 0.6873\n",
            "Epoch 40: loss on final training batch: 0.6855\n",
            "Epoch 40: accuracy on validation set: 0.5204\n",
            "Epoch 40: accuracy on training set: 0.5218\n",
            "Epoch 40: loss on validation set: 0.6871\n",
            "Epoch 41: loss on final training batch: 0.6853\n",
            "Epoch 41: accuracy on validation set: 0.5227\n",
            "Epoch 41: accuracy on training set: 0.5219\n",
            "Epoch 41: loss on validation set: 0.6870\n",
            "Epoch 42: loss on final training batch: 0.6851\n",
            "Epoch 42: accuracy on validation set: 0.5217\n",
            "Epoch 42: accuracy on training set: 0.5229\n",
            "Epoch 42: loss on validation set: 0.6868\n",
            "Epoch 43: loss on final training batch: 0.6849\n",
            "Epoch 43: accuracy on validation set: 0.5221\n",
            "Epoch 43: accuracy on training set: 0.5234\n",
            "Epoch 43: loss on validation set: 0.6866\n",
            "Epoch 44: loss on final training batch: 0.6847\n",
            "Epoch 44: accuracy on validation set: 0.5225\n",
            "Epoch 44: accuracy on training set: 0.5235\n",
            "Epoch 44: loss on validation set: 0.6864\n",
            "Epoch 45: loss on final training batch: 0.6844\n",
            "Epoch 45: accuracy on validation set: 0.5225\n",
            "Epoch 45: accuracy on training set: 0.5247\n",
            "Epoch 45: loss on validation set: 0.6862\n",
            "Epoch 46: loss on final training batch: 0.6842\n",
            "Epoch 46: accuracy on validation set: 0.5267\n",
            "Epoch 46: accuracy on training set: 0.5254\n",
            "Epoch 46: loss on validation set: 0.6860\n",
            "Epoch 47: loss on final training batch: 0.6840\n",
            "Epoch 47: accuracy on validation set: 0.5252\n",
            "Epoch 47: accuracy on training set: 0.5263\n",
            "Epoch 47: loss on validation set: 0.6859\n",
            "Epoch 48: loss on final training batch: 0.6838\n",
            "Epoch 48: accuracy on validation set: 0.5271\n",
            "Epoch 48: accuracy on training set: 0.5273\n",
            "Epoch 48: loss on validation set: 0.6857\n",
            "Epoch 49: loss on final training batch: 0.6836\n",
            "Epoch 49: accuracy on validation set: 0.5265\n",
            "Epoch 49: accuracy on training set: 0.5280\n",
            "Epoch 49: loss on validation set: 0.6855\n",
            "Epoch 50: loss on final training batch: 0.6834\n",
            "Epoch 50: accuracy on validation set: 0.5273\n",
            "Epoch 50: accuracy on training set: 0.5293\n",
            "Epoch 50: loss on validation set: 0.6853\n",
            "Epoch 51: loss on final training batch: 0.6832\n",
            "Epoch 51: accuracy on validation set: 0.5279\n",
            "Epoch 51: accuracy on training set: 0.5303\n",
            "Epoch 51: loss on validation set: 0.6852\n",
            "Epoch 52: loss on final training batch: 0.6830\n",
            "Epoch 52: accuracy on validation set: 0.5292\n",
            "Epoch 52: accuracy on training set: 0.5303\n",
            "Epoch 52: loss on validation set: 0.6850\n",
            "Epoch 53: loss on final training batch: 0.6828\n",
            "Epoch 53: accuracy on validation set: 0.5298\n",
            "Epoch 53: accuracy on training set: 0.5307\n",
            "Epoch 53: loss on validation set: 0.6848\n",
            "Epoch 54: loss on final training batch: 0.6826\n",
            "Epoch 54: accuracy on validation set: 0.5292\n",
            "Epoch 54: accuracy on training set: 0.5315\n",
            "Epoch 54: loss on validation set: 0.6847\n",
            "Epoch 55: loss on final training batch: 0.6824\n",
            "Epoch 55: accuracy on validation set: 0.5300\n",
            "Epoch 55: accuracy on training set: 0.5322\n",
            "Epoch 55: loss on validation set: 0.6845\n",
            "Epoch 56: loss on final training batch: 0.6822\n",
            "Epoch 56: accuracy on validation set: 0.5296\n",
            "Epoch 56: accuracy on training set: 0.5332\n",
            "Epoch 56: loss on validation set: 0.6843\n",
            "Epoch 57: loss on final training batch: 0.6820\n",
            "Epoch 57: accuracy on validation set: 0.5317\n",
            "Epoch 57: accuracy on training set: 0.5336\n",
            "Epoch 57: loss on validation set: 0.6842\n",
            "Epoch 58: loss on final training batch: 0.6818\n",
            "Epoch 58: accuracy on validation set: 0.5315\n",
            "Epoch 58: accuracy on training set: 0.5340\n",
            "Epoch 58: loss on validation set: 0.6840\n",
            "Epoch 59: loss on final training batch: 0.6816\n",
            "Epoch 59: accuracy on validation set: 0.5300\n",
            "Epoch 59: accuracy on training set: 0.5347\n",
            "Epoch 59: loss on validation set: 0.6839\n",
            "Epoch 60: loss on final training batch: 0.6814\n",
            "Epoch 60: accuracy on validation set: 0.5302\n",
            "Epoch 60: accuracy on training set: 0.5357\n",
            "Epoch 60: loss on validation set: 0.6837\n",
            "Epoch 61: loss on final training batch: 0.6813\n",
            "Epoch 61: accuracy on validation set: 0.5302\n",
            "Epoch 61: accuracy on training set: 0.5353\n",
            "Epoch 61: loss on validation set: 0.6835\n",
            "Epoch 62: loss on final training batch: 0.6811\n",
            "Epoch 62: accuracy on validation set: 0.5308\n",
            "Epoch 62: accuracy on training set: 0.5354\n",
            "Epoch 62: loss on validation set: 0.6834\n",
            "Epoch 63: loss on final training batch: 0.6809\n",
            "Epoch 63: accuracy on validation set: 0.5310\n",
            "Epoch 63: accuracy on training set: 0.5357\n",
            "Epoch 63: loss on validation set: 0.6832\n",
            "Epoch 64: loss on final training batch: 0.6807\n",
            "Epoch 64: accuracy on validation set: 0.5315\n",
            "Epoch 64: accuracy on training set: 0.5362\n",
            "Epoch 64: loss on validation set: 0.6831\n",
            "Epoch 65: loss on final training batch: 0.6806\n",
            "Epoch 65: accuracy on validation set: 0.5329\n",
            "Epoch 65: accuracy on training set: 0.5365\n",
            "Epoch 65: loss on validation set: 0.6830\n",
            "Epoch 66: loss on final training batch: 0.6804\n",
            "Epoch 66: accuracy on validation set: 0.5335\n",
            "Epoch 66: accuracy on training set: 0.5366\n",
            "Epoch 66: loss on validation set: 0.6828\n",
            "Epoch 67: loss on final training batch: 0.6803\n",
            "Epoch 67: accuracy on validation set: 0.5342\n",
            "Epoch 67: accuracy on training set: 0.5365\n",
            "Epoch 67: loss on validation set: 0.6827\n",
            "Epoch 68: loss on final training batch: 0.6801\n",
            "Epoch 68: accuracy on validation set: 0.5344\n",
            "Epoch 68: accuracy on training set: 0.5365\n",
            "Epoch 68: loss on validation set: 0.6825\n",
            "Epoch 69: loss on final training batch: 0.6800\n",
            "Epoch 69: accuracy on validation set: 0.5337\n",
            "Epoch 69: accuracy on training set: 0.5368\n",
            "Epoch 69: loss on validation set: 0.6824\n",
            "Epoch 70: loss on final training batch: 0.6798\n",
            "Epoch 70: accuracy on validation set: 0.5337\n",
            "Epoch 70: accuracy on training set: 0.5371\n",
            "Epoch 70: loss on validation set: 0.6823\n",
            "Epoch 71: loss on final training batch: 0.6797\n",
            "Epoch 71: accuracy on validation set: 0.5350\n",
            "Epoch 71: accuracy on training set: 0.5371\n",
            "Epoch 71: loss on validation set: 0.6821\n",
            "Epoch 72: loss on final training batch: 0.6796\n",
            "Epoch 72: accuracy on validation set: 0.5354\n",
            "Epoch 72: accuracy on training set: 0.5373\n",
            "Epoch 72: loss on validation set: 0.6820\n",
            "Epoch 73: loss on final training batch: 0.6794\n",
            "Epoch 73: accuracy on validation set: 0.5350\n",
            "Epoch 73: accuracy on training set: 0.5379\n",
            "Epoch 73: loss on validation set: 0.6819\n",
            "Epoch 74: loss on final training batch: 0.6793\n",
            "Epoch 74: accuracy on validation set: 0.5346\n",
            "Epoch 74: accuracy on training set: 0.5383\n",
            "Epoch 74: loss on validation set: 0.6818\n",
            "Epoch 75: loss on final training batch: 0.6792\n",
            "Epoch 75: accuracy on validation set: 0.5346\n",
            "Epoch 75: accuracy on training set: 0.5386\n",
            "Epoch 75: loss on validation set: 0.6817\n",
            "Epoch 76: loss on final training batch: 0.6791\n",
            "Epoch 76: accuracy on validation set: 0.5354\n",
            "Epoch 76: accuracy on training set: 0.5385\n",
            "Epoch 76: loss on validation set: 0.6815\n",
            "Epoch 77: loss on final training batch: 0.6789\n",
            "Epoch 77: accuracy on validation set: 0.5346\n",
            "Epoch 77: accuracy on training set: 0.5389\n",
            "Epoch 77: loss on validation set: 0.6814\n",
            "Epoch 78: loss on final training batch: 0.6788\n",
            "Epoch 78: accuracy on validation set: 0.5352\n",
            "Epoch 78: accuracy on training set: 0.5393\n",
            "Epoch 78: loss on validation set: 0.6813\n",
            "Epoch 79: loss on final training batch: 0.6787\n",
            "Epoch 79: accuracy on validation set: 0.5358\n",
            "Epoch 79: accuracy on training set: 0.5395\n",
            "Epoch 79: loss on validation set: 0.6812\n",
            "Epoch 80: loss on final training batch: 0.6786\n",
            "Epoch 80: accuracy on validation set: 0.5362\n",
            "Epoch 80: accuracy on training set: 0.5393\n",
            "Epoch 80: loss on validation set: 0.6811\n",
            "Epoch 81: loss on final training batch: 0.6785\n",
            "Epoch 81: accuracy on validation set: 0.5367\n",
            "Epoch 81: accuracy on training set: 0.5398\n",
            "Epoch 81: loss on validation set: 0.6810\n",
            "Epoch 82: loss on final training batch: 0.6784\n",
            "Epoch 82: accuracy on validation set: 0.5365\n",
            "Epoch 82: accuracy on training set: 0.5401\n",
            "Epoch 82: loss on validation set: 0.6809\n",
            "Epoch 83: loss on final training batch: 0.6783\n",
            "Epoch 83: accuracy on validation set: 0.5367\n",
            "Epoch 83: accuracy on training set: 0.5403\n",
            "Epoch 83: loss on validation set: 0.6808\n",
            "Epoch 84: loss on final training batch: 0.6782\n",
            "Epoch 84: accuracy on validation set: 0.5373\n",
            "Epoch 84: accuracy on training set: 0.5402\n",
            "Epoch 84: loss on validation set: 0.6807\n",
            "Epoch 85: loss on final training batch: 0.6781\n",
            "Epoch 85: accuracy on validation set: 0.5369\n",
            "Epoch 85: accuracy on training set: 0.5405\n",
            "Epoch 85: loss on validation set: 0.6806\n",
            "Epoch 86: loss on final training batch: 0.6780\n",
            "Epoch 86: accuracy on validation set: 0.5375\n",
            "Epoch 86: accuracy on training set: 0.5404\n",
            "Epoch 86: loss on validation set: 0.6805\n",
            "Epoch 87: loss on final training batch: 0.6779\n",
            "Epoch 87: accuracy on validation set: 0.5390\n",
            "Epoch 87: accuracy on training set: 0.5405\n",
            "Epoch 87: loss on validation set: 0.6804\n",
            "Epoch 88: loss on final training batch: 0.6778\n",
            "Epoch 88: accuracy on validation set: 0.5398\n",
            "Epoch 88: accuracy on training set: 0.5403\n",
            "Epoch 88: loss on validation set: 0.6803\n",
            "Epoch 89: loss on final training batch: 0.6777\n",
            "Epoch 89: accuracy on validation set: 0.5392\n",
            "Epoch 89: accuracy on training set: 0.5403\n",
            "Epoch 89: loss on validation set: 0.6803\n",
            "Epoch 90: loss on final training batch: 0.6776\n",
            "Epoch 90: accuracy on validation set: 0.5394\n",
            "Epoch 90: accuracy on training set: 0.5407\n",
            "Epoch 90: loss on validation set: 0.6802\n",
            "Epoch 91: loss on final training batch: 0.6775\n",
            "Epoch 91: accuracy on validation set: 0.5392\n",
            "Epoch 91: accuracy on training set: 0.5408\n",
            "Epoch 91: loss on validation set: 0.6801\n",
            "Epoch 92: loss on final training batch: 0.6774\n",
            "Epoch 92: accuracy on validation set: 0.5387\n",
            "Epoch 92: accuracy on training set: 0.5409\n",
            "Epoch 92: loss on validation set: 0.6800\n",
            "Epoch 93: loss on final training batch: 0.6773\n",
            "Epoch 93: accuracy on validation set: 0.5400\n",
            "Epoch 93: accuracy on training set: 0.5410\n",
            "Epoch 93: loss on validation set: 0.6799\n",
            "Epoch 94: loss on final training batch: 0.6772\n",
            "Epoch 94: accuracy on validation set: 0.5400\n",
            "Epoch 94: accuracy on training set: 0.5411\n",
            "Epoch 94: loss on validation set: 0.6799\n",
            "Epoch 95: loss on final training batch: 0.6772\n",
            "Epoch 95: accuracy on validation set: 0.5406\n",
            "Epoch 95: accuracy on training set: 0.5411\n",
            "Epoch 95: loss on validation set: 0.6798\n",
            "Epoch 96: loss on final training batch: 0.6771\n",
            "Epoch 96: accuracy on validation set: 0.5406\n",
            "Epoch 96: accuracy on training set: 0.5413\n",
            "Epoch 96: loss on validation set: 0.6797\n",
            "Epoch 97: loss on final training batch: 0.6770\n",
            "Epoch 97: accuracy on validation set: 0.5419\n",
            "Epoch 97: accuracy on training set: 0.5412\n",
            "Epoch 97: loss on validation set: 0.6796\n",
            "Epoch 98: loss on final training batch: 0.6769\n",
            "Epoch 98: accuracy on validation set: 0.5419\n",
            "Epoch 98: accuracy on training set: 0.5413\n",
            "Epoch 98: loss on validation set: 0.6796\n",
            "Epoch 99: loss on final training batch: 0.6768\n",
            "Epoch 99: accuracy on validation set: 0.5423\n",
            "Epoch 99: accuracy on training set: 0.5414\n",
            "Epoch 99: loss on validation set: 0.6795\n",
            "Epoch 100: loss on final training batch: 0.6768\n",
            "Epoch 100: accuracy on validation set: 0.5433\n",
            "Epoch 100: accuracy on training set: 0.5413\n",
            "Epoch 100: loss on validation set: 0.6795\n",
            "Epoch 101: loss on final training batch: 0.6767\n",
            "Epoch 101: accuracy on validation set: 0.5437\n",
            "Epoch 101: accuracy on training set: 0.5411\n",
            "Epoch 101: loss on validation set: 0.6794\n",
            "Epoch 102: loss on final training batch: 0.6766\n",
            "Epoch 102: accuracy on validation set: 0.5440\n",
            "Epoch 102: accuracy on training set: 0.5414\n",
            "Epoch 102: loss on validation set: 0.6793\n",
            "Epoch 103: loss on final training batch: 0.6765\n",
            "Epoch 103: accuracy on validation set: 0.5440\n",
            "Epoch 103: accuracy on training set: 0.5411\n",
            "Epoch 103: loss on validation set: 0.6793\n",
            "Epoch 104: loss on final training batch: 0.6765\n",
            "Epoch 104: accuracy on validation set: 0.5444\n",
            "Epoch 104: accuracy on training set: 0.5414\n",
            "Epoch 104: loss on validation set: 0.6792\n",
            "Epoch 105: loss on final training batch: 0.6764\n",
            "Epoch 105: accuracy on validation set: 0.5442\n",
            "Epoch 105: accuracy on training set: 0.5411\n",
            "Epoch 105: loss on validation set: 0.6792\n",
            "Epoch 106: loss on final training batch: 0.6763\n",
            "Epoch 106: accuracy on validation set: 0.5442\n",
            "Epoch 106: accuracy on training set: 0.5412\n",
            "Epoch 106: loss on validation set: 0.6791\n",
            "Epoch 107: loss on final training batch: 0.6762\n",
            "Epoch 107: accuracy on validation set: 0.5442\n",
            "Epoch 107: accuracy on training set: 0.5412\n",
            "Epoch 107: loss on validation set: 0.6791\n",
            "Epoch 108: loss on final training batch: 0.6762\n",
            "Epoch 108: accuracy on validation set: 0.5435\n",
            "Epoch 108: accuracy on training set: 0.5412\n",
            "Epoch 108: loss on validation set: 0.6790\n",
            "Epoch 109: loss on final training batch: 0.6761\n",
            "Epoch 109: accuracy on validation set: 0.5435\n",
            "Epoch 109: accuracy on training set: 0.5414\n",
            "Epoch 109: loss on validation set: 0.6790\n",
            "Epoch 110: loss on final training batch: 0.6761\n",
            "Epoch 110: accuracy on validation set: 0.5427\n",
            "Epoch 110: accuracy on training set: 0.5416\n",
            "Epoch 110: loss on validation set: 0.6789\n",
            "Epoch 111: loss on final training batch: 0.6760\n",
            "Epoch 111: accuracy on validation set: 0.5429\n",
            "Epoch 111: accuracy on training set: 0.5415\n",
            "Epoch 111: loss on validation set: 0.6789\n",
            "Epoch 112: loss on final training batch: 0.6759\n",
            "Epoch 112: accuracy on validation set: 0.5437\n",
            "Epoch 112: accuracy on training set: 0.5413\n",
            "Epoch 112: loss on validation set: 0.6788\n",
            "Epoch 113: loss on final training batch: 0.6759\n",
            "Epoch 113: accuracy on validation set: 0.5435\n",
            "Epoch 113: accuracy on training set: 0.5411\n",
            "Epoch 113: loss on validation set: 0.6788\n",
            "Epoch 114: loss on final training batch: 0.6758\n",
            "Epoch 114: accuracy on validation set: 0.5431\n",
            "Epoch 114: accuracy on training set: 0.5411\n",
            "Epoch 114: loss on validation set: 0.6787\n",
            "Epoch 115: loss on final training batch: 0.6758\n",
            "Epoch 115: accuracy on validation set: 0.5433\n",
            "Epoch 115: accuracy on training set: 0.5410\n",
            "Epoch 115: loss on validation set: 0.6787\n",
            "Epoch 116: loss on final training batch: 0.6757\n",
            "Epoch 116: accuracy on validation set: 0.5429\n",
            "Epoch 116: accuracy on training set: 0.5411\n",
            "Epoch 116: loss on validation set: 0.6786\n",
            "Epoch 117: loss on final training batch: 0.6756\n",
            "Epoch 117: accuracy on validation set: 0.5431\n",
            "Epoch 117: accuracy on training set: 0.5410\n",
            "Epoch 117: loss on validation set: 0.6786\n",
            "Epoch 118: loss on final training batch: 0.6756\n",
            "Epoch 118: accuracy on validation set: 0.5431\n",
            "Epoch 118: accuracy on training set: 0.5410\n",
            "Epoch 118: loss on validation set: 0.6786\n",
            "Epoch 119: loss on final training batch: 0.6755\n",
            "Epoch 119: accuracy on validation set: 0.5429\n",
            "Epoch 119: accuracy on training set: 0.5411\n",
            "Epoch 119: loss on validation set: 0.6785\n",
            "Epoch 120: loss on final training batch: 0.6755\n",
            "Epoch 120: accuracy on validation set: 0.5429\n",
            "Epoch 120: accuracy on training set: 0.5411\n",
            "Epoch 120: loss on validation set: 0.6785\n",
            "Epoch 121: loss on final training batch: 0.6754\n",
            "Epoch 121: accuracy on validation set: 0.5433\n",
            "Epoch 121: accuracy on training set: 0.5412\n",
            "Epoch 121: loss on validation set: 0.6785\n",
            "Epoch 122: loss on final training batch: 0.6754\n",
            "Epoch 122: accuracy on validation set: 0.5433\n",
            "Epoch 122: accuracy on training set: 0.5409\n",
            "Epoch 122: loss on validation set: 0.6784\n",
            "Epoch 123: loss on final training batch: 0.6753\n",
            "Epoch 123: accuracy on validation set: 0.5431\n",
            "Epoch 123: accuracy on training set: 0.5409\n",
            "Epoch 123: loss on validation set: 0.6784\n",
            "Epoch 124: loss on final training batch: 0.6753\n",
            "Epoch 124: accuracy on validation set: 0.5433\n",
            "Epoch 124: accuracy on training set: 0.5411\n",
            "Epoch 124: loss on validation set: 0.6784\n",
            "Epoch 125: loss on final training batch: 0.6752\n",
            "Epoch 125: accuracy on validation set: 0.5431\n",
            "Epoch 125: accuracy on training set: 0.5412\n",
            "Epoch 125: loss on validation set: 0.6783\n",
            "Epoch 126: loss on final training batch: 0.6752\n",
            "Epoch 126: accuracy on validation set: 0.5435\n",
            "Epoch 126: accuracy on training set: 0.5413\n",
            "Epoch 126: loss on validation set: 0.6783\n",
            "Epoch 127: loss on final training batch: 0.6751\n",
            "Epoch 127: accuracy on validation set: 0.5442\n",
            "Epoch 127: accuracy on training set: 0.5414\n",
            "Epoch 127: loss on validation set: 0.6783\n",
            "Epoch 128: loss on final training batch: 0.6751\n",
            "Epoch 128: accuracy on validation set: 0.5440\n",
            "Epoch 128: accuracy on training set: 0.5415\n",
            "Epoch 128: loss on validation set: 0.6782\n",
            "Epoch 129: loss on final training batch: 0.6751\n",
            "Epoch 129: accuracy on validation set: 0.5440\n",
            "Epoch 129: accuracy on training set: 0.5417\n",
            "Epoch 129: loss on validation set: 0.6782\n",
            "Epoch 130: loss on final training batch: 0.6750\n",
            "Epoch 130: accuracy on validation set: 0.5437\n",
            "Epoch 130: accuracy on training set: 0.5418\n",
            "Epoch 130: loss on validation set: 0.6782\n",
            "Epoch 131: loss on final training batch: 0.6750\n",
            "Epoch 131: accuracy on validation set: 0.5440\n",
            "Epoch 131: accuracy on training set: 0.5419\n",
            "Epoch 131: loss on validation set: 0.6781\n",
            "Epoch 132: loss on final training batch: 0.6749\n",
            "Epoch 132: accuracy on validation set: 0.5442\n",
            "Epoch 132: accuracy on training set: 0.5419\n",
            "Epoch 132: loss on validation set: 0.6781\n",
            "Epoch 133: loss on final training batch: 0.6749\n",
            "Epoch 133: accuracy on validation set: 0.5440\n",
            "Epoch 133: accuracy on training set: 0.5420\n",
            "Epoch 133: loss on validation set: 0.6781\n",
            "Epoch 134: loss on final training batch: 0.6749\n",
            "Epoch 134: accuracy on validation set: 0.5440\n",
            "Epoch 134: accuracy on training set: 0.5420\n",
            "Epoch 134: loss on validation set: 0.6781\n",
            "Epoch 135: loss on final training batch: 0.6748\n",
            "Epoch 135: accuracy on validation set: 0.5437\n",
            "Epoch 135: accuracy on training set: 0.5420\n",
            "Epoch 135: loss on validation set: 0.6780\n",
            "Epoch 136: loss on final training batch: 0.6748\n",
            "Epoch 136: accuracy on validation set: 0.5440\n",
            "Epoch 136: accuracy on training set: 0.5423\n",
            "Epoch 136: loss on validation set: 0.6780\n",
            "Epoch 137: loss on final training batch: 0.6747\n",
            "Epoch 137: accuracy on validation set: 0.5437\n",
            "Epoch 137: accuracy on training set: 0.5422\n",
            "Epoch 137: loss on validation set: 0.6780\n",
            "Epoch 138: loss on final training batch: 0.6747\n",
            "Epoch 138: accuracy on validation set: 0.5435\n",
            "Epoch 138: accuracy on training set: 0.5423\n",
            "Epoch 138: loss on validation set: 0.6780\n",
            "Epoch 139: loss on final training batch: 0.6747\n",
            "Epoch 139: accuracy on validation set: 0.5433\n",
            "Epoch 139: accuracy on training set: 0.5422\n",
            "Epoch 139: loss on validation set: 0.6780\n",
            "Epoch 140: loss on final training batch: 0.6746\n",
            "Epoch 140: accuracy on validation set: 0.5433\n",
            "Epoch 140: accuracy on training set: 0.5424\n",
            "Epoch 140: loss on validation set: 0.6779\n",
            "Epoch 141: loss on final training batch: 0.6746\n",
            "Epoch 141: accuracy on validation set: 0.5435\n",
            "Epoch 141: accuracy on training set: 0.5425\n",
            "Epoch 141: loss on validation set: 0.6779\n",
            "Epoch 142: loss on final training batch: 0.6745\n",
            "Epoch 142: accuracy on validation set: 0.5435\n",
            "Epoch 142: accuracy on training set: 0.5426\n",
            "Epoch 142: loss on validation set: 0.6779\n",
            "Epoch 143: loss on final training batch: 0.6745\n",
            "Epoch 143: accuracy on validation set: 0.5433\n",
            "Epoch 143: accuracy on training set: 0.5425\n",
            "Epoch 143: loss on validation set: 0.6779\n",
            "Epoch 144: loss on final training batch: 0.6745\n",
            "Epoch 144: accuracy on validation set: 0.5433\n",
            "Epoch 144: accuracy on training set: 0.5426\n",
            "Epoch 144: loss on validation set: 0.6779\n",
            "Epoch 145: loss on final training batch: 0.6744\n",
            "Epoch 145: accuracy on validation set: 0.5433\n",
            "Epoch 145: accuracy on training set: 0.5427\n",
            "Epoch 145: loss on validation set: 0.6778\n",
            "Epoch 146: loss on final training batch: 0.6744\n",
            "Epoch 146: accuracy on validation set: 0.5431\n",
            "Epoch 146: accuracy on training set: 0.5426\n",
            "Epoch 146: loss on validation set: 0.6778\n",
            "Epoch 147: loss on final training batch: 0.6744\n",
            "Epoch 147: accuracy on validation set: 0.5429\n",
            "Epoch 147: accuracy on training set: 0.5425\n",
            "Epoch 147: loss on validation set: 0.6778\n",
            "Epoch 148: loss on final training batch: 0.6743\n",
            "Epoch 148: accuracy on validation set: 0.5433\n",
            "Epoch 148: accuracy on training set: 0.5426\n",
            "Epoch 148: loss on validation set: 0.6778\n",
            "Epoch 149: loss on final training batch: 0.6743\n",
            "Epoch 149: accuracy on validation set: 0.5435\n",
            "Epoch 149: accuracy on training set: 0.5426\n",
            "Epoch 149: loss on validation set: 0.6778\n",
            "Epoch 150: loss on final training batch: 0.6743\n",
            "Epoch 150: accuracy on validation set: 0.5435\n",
            "Epoch 150: accuracy on training set: 0.5427\n",
            "Epoch 150: loss on validation set: 0.6778\n",
            "Epoch 151: loss on final training batch: 0.6742\n",
            "Epoch 151: accuracy on validation set: 0.5427\n",
            "Epoch 151: accuracy on training set: 0.5427\n",
            "Epoch 151: loss on validation set: 0.6777\n",
            "Epoch 152: loss on final training batch: 0.6742\n",
            "Epoch 152: accuracy on validation set: 0.5431\n",
            "Epoch 152: accuracy on training set: 0.5428\n",
            "Epoch 152: loss on validation set: 0.6777\n",
            "Epoch 153: loss on final training batch: 0.6742\n",
            "Epoch 153: accuracy on validation set: 0.5433\n",
            "Epoch 153: accuracy on training set: 0.5430\n",
            "Epoch 153: loss on validation set: 0.6777\n",
            "Epoch 154: loss on final training batch: 0.6741\n",
            "Epoch 154: accuracy on validation set: 0.5429\n",
            "Epoch 154: accuracy on training set: 0.5431\n",
            "Epoch 154: loss on validation set: 0.6777\n",
            "Epoch 155: loss on final training batch: 0.6741\n",
            "Epoch 155: accuracy on validation set: 0.5431\n",
            "Epoch 155: accuracy on training set: 0.5430\n",
            "Epoch 155: loss on validation set: 0.6777\n",
            "Epoch 156: loss on final training batch: 0.6741\n",
            "Epoch 156: accuracy on validation set: 0.5431\n",
            "Epoch 156: accuracy on training set: 0.5431\n",
            "Epoch 156: loss on validation set: 0.6777\n",
            "Epoch 157: loss on final training batch: 0.6740\n",
            "Epoch 157: accuracy on validation set: 0.5431\n",
            "Epoch 157: accuracy on training set: 0.5431\n",
            "Epoch 157: loss on validation set: 0.6777\n",
            "Epoch 158: loss on final training batch: 0.6740\n",
            "Epoch 158: accuracy on validation set: 0.5431\n",
            "Epoch 158: accuracy on training set: 0.5431\n",
            "Epoch 158: loss on validation set: 0.6776\n",
            "Epoch 159: loss on final training batch: 0.6740\n",
            "Epoch 159: accuracy on validation set: 0.5431\n",
            "Epoch 159: accuracy on training set: 0.5429\n",
            "Epoch 159: loss on validation set: 0.6776\n",
            "Epoch 160: loss on final training batch: 0.6740\n",
            "Epoch 160: accuracy on validation set: 0.5427\n",
            "Epoch 160: accuracy on training set: 0.5429\n",
            "Epoch 160: loss on validation set: 0.6776\n",
            "Epoch 161: loss on final training batch: 0.6739\n",
            "Epoch 161: accuracy on validation set: 0.5425\n",
            "Epoch 161: accuracy on training set: 0.5431\n",
            "Epoch 161: loss on validation set: 0.6776\n",
            "Epoch 162: loss on final training batch: 0.6739\n",
            "Epoch 162: accuracy on validation set: 0.5423\n",
            "Epoch 162: accuracy on training set: 0.5430\n",
            "Epoch 162: loss on validation set: 0.6776\n",
            "Epoch 163: loss on final training batch: 0.6739\n",
            "Epoch 163: accuracy on validation set: 0.5423\n",
            "Epoch 163: accuracy on training set: 0.5431\n",
            "Epoch 163: loss on validation set: 0.6776\n",
            "Epoch 164: loss on final training batch: 0.6738\n",
            "Epoch 164: accuracy on validation set: 0.5419\n",
            "Epoch 164: accuracy on training set: 0.5432\n",
            "Epoch 164: loss on validation set: 0.6776\n",
            "Epoch 165: loss on final training batch: 0.6738\n",
            "Epoch 165: accuracy on validation set: 0.5419\n",
            "Epoch 165: accuracy on training set: 0.5433\n",
            "Epoch 165: loss on validation set: 0.6776\n",
            "Epoch 166: loss on final training batch: 0.6738\n",
            "Epoch 166: accuracy on validation set: 0.5421\n",
            "Epoch 166: accuracy on training set: 0.5432\n",
            "Epoch 166: loss on validation set: 0.6776\n",
            "Epoch 167: loss on final training batch: 0.6737\n",
            "Epoch 167: accuracy on validation set: 0.5421\n",
            "Epoch 167: accuracy on training set: 0.5433\n",
            "Epoch 167: loss on validation set: 0.6775\n",
            "Epoch 168: loss on final training batch: 0.6737\n",
            "Epoch 168: accuracy on validation set: 0.5423\n",
            "Epoch 168: accuracy on training set: 0.5435\n",
            "Epoch 168: loss on validation set: 0.6775\n",
            "Epoch 169: loss on final training batch: 0.6737\n",
            "Epoch 169: accuracy on validation set: 0.5421\n",
            "Epoch 169: accuracy on training set: 0.5433\n",
            "Epoch 169: loss on validation set: 0.6775\n",
            "Epoch 170: loss on final training batch: 0.6737\n",
            "Epoch 170: accuracy on validation set: 0.5423\n",
            "Epoch 170: accuracy on training set: 0.5433\n",
            "Epoch 170: loss on validation set: 0.6775\n",
            "Epoch 171: loss on final training batch: 0.6736\n",
            "Epoch 171: accuracy on validation set: 0.5423\n",
            "Epoch 171: accuracy on training set: 0.5431\n",
            "Epoch 171: loss on validation set: 0.6775\n",
            "Epoch 172: loss on final training batch: 0.6736\n",
            "Epoch 172: accuracy on validation set: 0.5423\n",
            "Epoch 172: accuracy on training set: 0.5431\n",
            "Epoch 172: loss on validation set: 0.6775\n",
            "Epoch 173: loss on final training batch: 0.6736\n",
            "Epoch 173: accuracy on validation set: 0.5421\n",
            "Epoch 173: accuracy on training set: 0.5432\n",
            "Epoch 173: loss on validation set: 0.6775\n",
            "Epoch 174: loss on final training batch: 0.6736\n",
            "Epoch 174: accuracy on validation set: 0.5423\n",
            "Epoch 174: accuracy on training set: 0.5432\n",
            "Epoch 174: loss on validation set: 0.6775\n",
            "Epoch 175: loss on final training batch: 0.6735\n",
            "Epoch 175: accuracy on validation set: 0.5425\n",
            "Epoch 175: accuracy on training set: 0.5432\n",
            "Epoch 175: loss on validation set: 0.6775\n",
            "Epoch 176: loss on final training batch: 0.6735\n",
            "Epoch 176: accuracy on validation set: 0.5425\n",
            "Epoch 176: accuracy on training set: 0.5434\n",
            "Epoch 176: loss on validation set: 0.6775\n",
            "Epoch 177: loss on final training batch: 0.6735\n",
            "Epoch 177: accuracy on validation set: 0.5429\n",
            "Epoch 177: accuracy on training set: 0.5434\n",
            "Epoch 177: loss on validation set: 0.6775\n",
            "Epoch 178: loss on final training batch: 0.6734\n",
            "Epoch 178: accuracy on validation set: 0.5427\n",
            "Epoch 178: accuracy on training set: 0.5433\n",
            "Epoch 178: loss on validation set: 0.6774\n",
            "Epoch 179: loss on final training batch: 0.6734\n",
            "Epoch 179: accuracy on validation set: 0.5425\n",
            "Epoch 179: accuracy on training set: 0.5433\n",
            "Epoch 179: loss on validation set: 0.6774\n",
            "Epoch 180: loss on final training batch: 0.6734\n",
            "Epoch 180: accuracy on validation set: 0.5425\n",
            "Epoch 180: accuracy on training set: 0.5434\n",
            "Epoch 180: loss on validation set: 0.6774\n",
            "Epoch 181: loss on final training batch: 0.6734\n",
            "Epoch 181: accuracy on validation set: 0.5423\n",
            "Epoch 181: accuracy on training set: 0.5435\n",
            "Epoch 181: loss on validation set: 0.6774\n",
            "Epoch 182: loss on final training batch: 0.6734\n",
            "Epoch 182: accuracy on validation set: 0.5421\n",
            "Epoch 182: accuracy on training set: 0.5435\n",
            "Epoch 182: loss on validation set: 0.6774\n",
            "Epoch 183: loss on final training batch: 0.6733\n",
            "Epoch 183: accuracy on validation set: 0.5421\n",
            "Epoch 183: accuracy on training set: 0.5437\n",
            "Epoch 183: loss on validation set: 0.6774\n",
            "Epoch 184: loss on final training batch: 0.6733\n",
            "Epoch 184: accuracy on validation set: 0.5423\n",
            "Epoch 184: accuracy on training set: 0.5436\n",
            "Epoch 184: loss on validation set: 0.6774\n",
            "Epoch 185: loss on final training batch: 0.6733\n",
            "Epoch 185: accuracy on validation set: 0.5421\n",
            "Epoch 185: accuracy on training set: 0.5436\n",
            "Epoch 185: loss on validation set: 0.6774\n",
            "Epoch 186: loss on final training batch: 0.6733\n",
            "Epoch 186: accuracy on validation set: 0.5421\n",
            "Epoch 186: accuracy on training set: 0.5435\n",
            "Epoch 186: loss on validation set: 0.6774\n",
            "Epoch 187: loss on final training batch: 0.6732\n",
            "Epoch 187: accuracy on validation set: 0.5419\n",
            "Epoch 187: accuracy on training set: 0.5436\n",
            "Epoch 187: loss on validation set: 0.6774\n",
            "Epoch 188: loss on final training batch: 0.6732\n",
            "Epoch 188: accuracy on validation set: 0.5423\n",
            "Epoch 188: accuracy on training set: 0.5435\n",
            "Epoch 188: loss on validation set: 0.6774\n",
            "Epoch 189: loss on final training batch: 0.6732\n",
            "Epoch 189: accuracy on validation set: 0.5423\n",
            "Epoch 189: accuracy on training set: 0.5435\n",
            "Epoch 189: loss on validation set: 0.6774\n",
            "Epoch 190: loss on final training batch: 0.6732\n",
            "Epoch 190: accuracy on validation set: 0.5419\n",
            "Epoch 190: accuracy on training set: 0.5436\n",
            "Epoch 190: loss on validation set: 0.6774\n",
            "Epoch 191: loss on final training batch: 0.6731\n",
            "Epoch 191: accuracy on validation set: 0.5417\n",
            "Epoch 191: accuracy on training set: 0.5436\n",
            "Epoch 191: loss on validation set: 0.6774\n",
            "Epoch 192: loss on final training batch: 0.6731\n",
            "Epoch 192: accuracy on validation set: 0.5419\n",
            "Epoch 192: accuracy on training set: 0.5437\n",
            "Epoch 192: loss on validation set: 0.6774\n",
            "Epoch 193: loss on final training batch: 0.6731\n",
            "Epoch 193: accuracy on validation set: 0.5419\n",
            "Epoch 193: accuracy on training set: 0.5437\n",
            "Epoch 193: loss on validation set: 0.6774\n",
            "Epoch 194: loss on final training batch: 0.6731\n",
            "Epoch 194: accuracy on validation set: 0.5423\n",
            "Epoch 194: accuracy on training set: 0.5437\n",
            "Epoch 194: loss on validation set: 0.6773\n",
            "Epoch 195: loss on final training batch: 0.6730\n",
            "Epoch 195: accuracy on validation set: 0.5423\n",
            "Epoch 195: accuracy on training set: 0.5438\n",
            "Epoch 195: loss on validation set: 0.6773\n",
            "Epoch 196: loss on final training batch: 0.6730\n",
            "Epoch 196: accuracy on validation set: 0.5425\n",
            "Epoch 196: accuracy on training set: 0.5439\n",
            "Epoch 196: loss on validation set: 0.6773\n",
            "Epoch 197: loss on final training batch: 0.6730\n",
            "Epoch 197: accuracy on validation set: 0.5423\n",
            "Epoch 197: accuracy on training set: 0.5439\n",
            "Epoch 197: loss on validation set: 0.6773\n",
            "Epoch 198: loss on final training batch: 0.6730\n",
            "Epoch 198: accuracy on validation set: 0.5421\n",
            "Epoch 198: accuracy on training set: 0.5439\n",
            "Epoch 198: loss on validation set: 0.6773\n",
            "Epoch 199: loss on final training batch: 0.6730\n",
            "Epoch 199: accuracy on validation set: 0.5419\n",
            "Epoch 199: accuracy on training set: 0.5439\n",
            "Epoch 199: loss on validation set: 0.6773\n",
            "Epoch 200: loss on final training batch: 0.6729\n",
            "Epoch 200: accuracy on validation set: 0.5417\n",
            "Epoch 200: accuracy on training set: 0.5439\n",
            "Epoch 200: loss on validation set: 0.6773\n",
            "Epoch 201: loss on final training batch: 0.6729\n",
            "Epoch 201: accuracy on validation set: 0.5419\n",
            "Epoch 201: accuracy on training set: 0.5438\n",
            "Epoch 201: loss on validation set: 0.6773\n",
            "Epoch 202: loss on final training batch: 0.6729\n",
            "Epoch 202: accuracy on validation set: 0.5419\n",
            "Epoch 202: accuracy on training set: 0.5439\n",
            "Epoch 202: loss on validation set: 0.6773\n",
            "Epoch 203: loss on final training batch: 0.6729\n",
            "Epoch 203: accuracy on validation set: 0.5419\n",
            "Epoch 203: accuracy on training set: 0.5439\n",
            "Epoch 203: loss on validation set: 0.6773\n",
            "Epoch 204: loss on final training batch: 0.6729\n",
            "Epoch 204: accuracy on validation set: 0.5423\n",
            "Epoch 204: accuracy on training set: 0.5439\n",
            "Epoch 204: loss on validation set: 0.6773\n",
            "Epoch 205: loss on final training batch: 0.6728\n",
            "Epoch 205: accuracy on validation set: 0.5423\n",
            "Epoch 205: accuracy on training set: 0.5439\n",
            "Epoch 205: loss on validation set: 0.6773\n",
            "Epoch 206: loss on final training batch: 0.6728\n",
            "Epoch 206: accuracy on validation set: 0.5423\n",
            "Epoch 206: accuracy on training set: 0.5439\n",
            "Epoch 206: loss on validation set: 0.6773\n",
            "Epoch 207: loss on final training batch: 0.6728\n",
            "Epoch 207: accuracy on validation set: 0.5423\n",
            "Epoch 207: accuracy on training set: 0.5439\n",
            "Epoch 207: loss on validation set: 0.6773\n",
            "Epoch 208: loss on final training batch: 0.6728\n",
            "Epoch 208: accuracy on validation set: 0.5425\n",
            "Epoch 208: accuracy on training set: 0.5440\n",
            "Epoch 208: loss on validation set: 0.6773\n",
            "Epoch 209: loss on final training batch: 0.6727\n",
            "Epoch 209: accuracy on validation set: 0.5427\n",
            "Epoch 209: accuracy on training set: 0.5441\n",
            "Epoch 209: loss on validation set: 0.6773\n",
            "Epoch 210: loss on final training batch: 0.6727\n",
            "Epoch 210: accuracy on validation set: 0.5427\n",
            "Epoch 210: accuracy on training set: 0.5440\n",
            "Epoch 210: loss on validation set: 0.6773\n",
            "Epoch 211: loss on final training batch: 0.6727\n",
            "Epoch 211: accuracy on validation set: 0.5427\n",
            "Epoch 211: accuracy on training set: 0.5440\n",
            "Epoch 211: loss on validation set: 0.6773\n",
            "Epoch 212: loss on final training batch: 0.6727\n",
            "Epoch 212: accuracy on validation set: 0.5427\n",
            "Epoch 212: accuracy on training set: 0.5439\n",
            "Epoch 212: loss on validation set: 0.6773\n",
            "Epoch 213: loss on final training batch: 0.6727\n",
            "Epoch 213: accuracy on validation set: 0.5429\n",
            "Epoch 213: accuracy on training set: 0.5439\n",
            "Epoch 213: loss on validation set: 0.6773\n",
            "Epoch 214: loss on final training batch: 0.6727\n",
            "Epoch 214: accuracy on validation set: 0.5427\n",
            "Epoch 214: accuracy on training set: 0.5440\n",
            "Epoch 214: loss on validation set: 0.6773\n",
            "Epoch 215: loss on final training batch: 0.6726\n",
            "Epoch 215: accuracy on validation set: 0.5427\n",
            "Epoch 215: accuracy on training set: 0.5441\n",
            "Epoch 215: loss on validation set: 0.6773\n",
            "Epoch 216: loss on final training batch: 0.6726\n",
            "Epoch 216: accuracy on validation set: 0.5429\n",
            "Epoch 216: accuracy on training set: 0.5442\n",
            "Epoch 216: loss on validation set: 0.6773\n",
            "Epoch 217: loss on final training batch: 0.6726\n",
            "Epoch 217: accuracy on validation set: 0.5427\n",
            "Epoch 217: accuracy on training set: 0.5443\n",
            "Epoch 217: loss on validation set: 0.6772\n",
            "Epoch 218: loss on final training batch: 0.6726\n",
            "Epoch 218: accuracy on validation set: 0.5427\n",
            "Epoch 218: accuracy on training set: 0.5442\n",
            "Epoch 218: loss on validation set: 0.6772\n",
            "Epoch 219: loss on final training batch: 0.6726\n",
            "Epoch 219: accuracy on validation set: 0.5429\n",
            "Epoch 219: accuracy on training set: 0.5442\n",
            "Epoch 219: loss on validation set: 0.6772\n",
            "Epoch 220: loss on final training batch: 0.6725\n",
            "Epoch 220: accuracy on validation set: 0.5433\n",
            "Epoch 220: accuracy on training set: 0.5442\n",
            "Epoch 220: loss on validation set: 0.6772\n",
            "Epoch 221: loss on final training batch: 0.6725\n",
            "Epoch 221: accuracy on validation set: 0.5435\n",
            "Epoch 221: accuracy on training set: 0.5440\n",
            "Epoch 221: loss on validation set: 0.6772\n",
            "Epoch 222: loss on final training batch: 0.6725\n",
            "Epoch 222: accuracy on validation set: 0.5437\n",
            "Epoch 222: accuracy on training set: 0.5441\n",
            "Epoch 222: loss on validation set: 0.6772\n",
            "Epoch 223: loss on final training batch: 0.6725\n",
            "Epoch 223: accuracy on validation set: 0.5437\n",
            "Epoch 223: accuracy on training set: 0.5442\n",
            "Epoch 223: loss on validation set: 0.6772\n",
            "Epoch 224: loss on final training batch: 0.6725\n",
            "Epoch 224: accuracy on validation set: 0.5440\n",
            "Epoch 224: accuracy on training set: 0.5442\n",
            "Epoch 224: loss on validation set: 0.6772\n",
            "Epoch 225: loss on final training batch: 0.6725\n",
            "Epoch 225: accuracy on validation set: 0.5442\n",
            "Epoch 225: accuracy on training set: 0.5440\n",
            "Epoch 225: loss on validation set: 0.6772\n",
            "Epoch 226: loss on final training batch: 0.6724\n",
            "Epoch 226: accuracy on validation set: 0.5442\n",
            "Epoch 226: accuracy on training set: 0.5440\n",
            "Epoch 226: loss on validation set: 0.6772\n",
            "Epoch 227: loss on final training batch: 0.6724\n",
            "Epoch 227: accuracy on validation set: 0.5444\n",
            "Epoch 227: accuracy on training set: 0.5438\n",
            "Epoch 227: loss on validation set: 0.6772\n",
            "Epoch 228: loss on final training batch: 0.6724\n",
            "Epoch 228: accuracy on validation set: 0.5442\n",
            "Epoch 228: accuracy on training set: 0.5438\n",
            "Epoch 228: loss on validation set: 0.6772\n",
            "Epoch 229: loss on final training batch: 0.6724\n",
            "Epoch 229: accuracy on validation set: 0.5440\n",
            "Epoch 229: accuracy on training set: 0.5439\n",
            "Epoch 229: loss on validation set: 0.6772\n",
            "Epoch 230: loss on final training batch: 0.6724\n",
            "Epoch 230: accuracy on validation set: 0.5442\n",
            "Epoch 230: accuracy on training set: 0.5440\n",
            "Epoch 230: loss on validation set: 0.6772\n",
            "Epoch 231: loss on final training batch: 0.6724\n",
            "Epoch 231: accuracy on validation set: 0.5442\n",
            "Epoch 231: accuracy on training set: 0.5439\n",
            "Epoch 231: loss on validation set: 0.6772\n",
            "Epoch 232: loss on final training batch: 0.6724\n",
            "Epoch 232: accuracy on validation set: 0.5442\n",
            "Epoch 232: accuracy on training set: 0.5440\n",
            "Epoch 232: loss on validation set: 0.6772\n",
            "Epoch 233: loss on final training batch: 0.6723\n",
            "Epoch 233: accuracy on validation set: 0.5440\n",
            "Epoch 233: accuracy on training set: 0.5440\n",
            "Epoch 233: loss on validation set: 0.6772\n",
            "Epoch 234: loss on final training batch: 0.6723\n",
            "Epoch 234: accuracy on validation set: 0.5442\n",
            "Epoch 234: accuracy on training set: 0.5441\n",
            "Epoch 234: loss on validation set: 0.6772\n",
            "Epoch 235: loss on final training batch: 0.6723\n",
            "Epoch 235: accuracy on validation set: 0.5444\n",
            "Epoch 235: accuracy on training set: 0.5442\n",
            "Epoch 235: loss on validation set: 0.6772\n",
            "Epoch 236: loss on final training batch: 0.6723\n",
            "Epoch 236: accuracy on validation set: 0.5442\n",
            "Epoch 236: accuracy on training set: 0.5443\n",
            "Epoch 236: loss on validation set: 0.6772\n",
            "Epoch 237: loss on final training batch: 0.6723\n",
            "Epoch 237: accuracy on validation set: 0.5440\n",
            "Epoch 237: accuracy on training set: 0.5443\n",
            "Epoch 237: loss on validation set: 0.6772\n",
            "Epoch 238: loss on final training batch: 0.6723\n",
            "Epoch 238: accuracy on validation set: 0.5442\n",
            "Epoch 238: accuracy on training set: 0.5444\n",
            "Epoch 238: loss on validation set: 0.6772\n",
            "Epoch 239: loss on final training batch: 0.6723\n",
            "Epoch 239: accuracy on validation set: 0.5442\n",
            "Epoch 239: accuracy on training set: 0.5445\n",
            "Epoch 239: loss on validation set: 0.6772\n",
            "Epoch 240: loss on final training batch: 0.6722\n",
            "Epoch 240: accuracy on validation set: 0.5444\n",
            "Epoch 240: accuracy on training set: 0.5444\n",
            "Epoch 240: loss on validation set: 0.6772\n",
            "Epoch 241: loss on final training batch: 0.6722\n",
            "Epoch 241: accuracy on validation set: 0.5444\n",
            "Epoch 241: accuracy on training set: 0.5444\n",
            "Epoch 241: loss on validation set: 0.6772\n",
            "Epoch 242: loss on final training batch: 0.6722\n",
            "Epoch 242: accuracy on validation set: 0.5444\n",
            "Epoch 242: accuracy on training set: 0.5444\n",
            "Epoch 242: loss on validation set: 0.6772\n",
            "Epoch 243: loss on final training batch: 0.6722\n",
            "Epoch 243: accuracy on validation set: 0.5442\n",
            "Epoch 243: accuracy on training set: 0.5443\n",
            "Epoch 243: loss on validation set: 0.6772\n",
            "Epoch 244: loss on final training batch: 0.6722\n",
            "Epoch 244: accuracy on validation set: 0.5442\n",
            "Epoch 244: accuracy on training set: 0.5444\n",
            "Epoch 244: loss on validation set: 0.6772\n",
            "Epoch 245: loss on final training batch: 0.6722\n",
            "Epoch 245: accuracy on validation set: 0.5444\n",
            "Epoch 245: accuracy on training set: 0.5444\n",
            "Epoch 245: loss on validation set: 0.6772\n",
            "Epoch 246: loss on final training batch: 0.6722\n",
            "Epoch 246: accuracy on validation set: 0.5442\n",
            "Epoch 246: accuracy on training set: 0.5445\n",
            "Epoch 246: loss on validation set: 0.6772\n",
            "Epoch 247: loss on final training batch: 0.6722\n",
            "Epoch 247: accuracy on validation set: 0.5442\n",
            "Epoch 247: accuracy on training set: 0.5446\n",
            "Epoch 247: loss on validation set: 0.6772\n",
            "Epoch 248: loss on final training batch: 0.6721\n",
            "Epoch 248: accuracy on validation set: 0.5442\n",
            "Epoch 248: accuracy on training set: 0.5445\n",
            "Epoch 248: loss on validation set: 0.6772\n",
            "Epoch 249: loss on final training batch: 0.6721\n",
            "Epoch 249: accuracy on validation set: 0.5440\n",
            "Epoch 249: accuracy on training set: 0.5446\n",
            "Epoch 249: loss on validation set: 0.6772\n",
            "Epoch 250: loss on final training batch: 0.6721\n",
            "Epoch 250: accuracy on validation set: 0.5440\n",
            "Epoch 250: accuracy on training set: 0.5446\n",
            "Epoch 250: loss on validation set: 0.6772\n",
            "Epoch 251: loss on final training batch: 0.6721\n",
            "Epoch 251: accuracy on validation set: 0.5437\n",
            "Epoch 251: accuracy on training set: 0.5444\n",
            "Epoch 251: loss on validation set: 0.6772\n",
            "Epoch 252: loss on final training batch: 0.6721\n",
            "Epoch 252: accuracy on validation set: 0.5437\n",
            "Epoch 252: accuracy on training set: 0.5444\n",
            "Epoch 252: loss on validation set: 0.6772\n",
            "Epoch 253: loss on final training batch: 0.6721\n",
            "Epoch 253: accuracy on validation set: 0.5437\n",
            "Epoch 253: accuracy on training set: 0.5443\n",
            "Epoch 253: loss on validation set: 0.6772\n",
            "Epoch 254: loss on final training batch: 0.6721\n",
            "Epoch 254: accuracy on validation set: 0.5442\n",
            "Epoch 254: accuracy on training set: 0.5442\n",
            "Epoch 254: loss on validation set: 0.6772\n",
            "Epoch 255: loss on final training batch: 0.6720\n",
            "Epoch 255: accuracy on validation set: 0.5440\n",
            "Epoch 255: accuracy on training set: 0.5443\n",
            "Epoch 255: loss on validation set: 0.6772\n",
            "Epoch 256: loss on final training batch: 0.6720\n",
            "Epoch 256: accuracy on validation set: 0.5437\n",
            "Epoch 256: accuracy on training set: 0.5445\n",
            "Epoch 256: loss on validation set: 0.6772\n",
            "Epoch 257: loss on final training batch: 0.6720\n",
            "Epoch 257: accuracy on validation set: 0.5437\n",
            "Epoch 257: accuracy on training set: 0.5445\n",
            "Epoch 257: loss on validation set: 0.6772\n",
            "Epoch 258: loss on final training batch: 0.6720\n",
            "Epoch 258: accuracy on validation set: 0.5437\n",
            "Epoch 258: accuracy on training set: 0.5447\n",
            "Epoch 258: loss on validation set: 0.6772\n",
            "Epoch 259: loss on final training batch: 0.6720\n",
            "Epoch 259: accuracy on validation set: 0.5437\n",
            "Epoch 259: accuracy on training set: 0.5446\n",
            "Epoch 259: loss on validation set: 0.6772\n",
            "Epoch 260: loss on final training batch: 0.6720\n",
            "Epoch 260: accuracy on validation set: 0.5440\n",
            "Epoch 260: accuracy on training set: 0.5446\n",
            "Epoch 260: loss on validation set: 0.6772\n",
            "Epoch 261: loss on final training batch: 0.6720\n",
            "Epoch 261: accuracy on validation set: 0.5442\n",
            "Epoch 261: accuracy on training set: 0.5447\n",
            "Epoch 261: loss on validation set: 0.6771\n",
            "Epoch 262: loss on final training batch: 0.6719\n",
            "Epoch 262: accuracy on validation set: 0.5446\n",
            "Epoch 262: accuracy on training set: 0.5448\n",
            "Epoch 262: loss on validation set: 0.6771\n",
            "Epoch 263: loss on final training batch: 0.6719\n",
            "Epoch 263: accuracy on validation set: 0.5446\n",
            "Epoch 263: accuracy on training set: 0.5447\n",
            "Epoch 263: loss on validation set: 0.6771\n",
            "Epoch 264: loss on final training batch: 0.6719\n",
            "Epoch 264: accuracy on validation set: 0.5446\n",
            "Epoch 264: accuracy on training set: 0.5447\n",
            "Epoch 264: loss on validation set: 0.6771\n",
            "Epoch 265: loss on final training batch: 0.6719\n",
            "Epoch 265: accuracy on validation set: 0.5446\n",
            "Epoch 265: accuracy on training set: 0.5446\n",
            "Epoch 265: loss on validation set: 0.6771\n",
            "Epoch 266: loss on final training batch: 0.6719\n",
            "Epoch 266: accuracy on validation set: 0.5444\n",
            "Epoch 266: accuracy on training set: 0.5447\n",
            "Epoch 266: loss on validation set: 0.6771\n",
            "Epoch 267: loss on final training batch: 0.6719\n",
            "Epoch 267: accuracy on validation set: 0.5444\n",
            "Epoch 267: accuracy on training set: 0.5448\n",
            "Epoch 267: loss on validation set: 0.6771\n",
            "Epoch 268: loss on final training batch: 0.6719\n",
            "Epoch 268: accuracy on validation set: 0.5440\n",
            "Epoch 268: accuracy on training set: 0.5447\n",
            "Epoch 268: loss on validation set: 0.6771\n",
            "Epoch 269: loss on final training batch: 0.6718\n",
            "Epoch 269: accuracy on validation set: 0.5437\n",
            "Epoch 269: accuracy on training set: 0.5447\n",
            "Epoch 269: loss on validation set: 0.6771\n",
            "Epoch 270: loss on final training batch: 0.6718\n",
            "Epoch 270: accuracy on validation set: 0.5437\n",
            "Epoch 270: accuracy on training set: 0.5446\n",
            "Epoch 270: loss on validation set: 0.6771\n",
            "Epoch 271: loss on final training batch: 0.6718\n",
            "Epoch 271: accuracy on validation set: 0.5440\n",
            "Epoch 271: accuracy on training set: 0.5446\n",
            "Epoch 271: loss on validation set: 0.6771\n",
            "Epoch 272: loss on final training batch: 0.6718\n",
            "Epoch 272: accuracy on validation set: 0.5440\n",
            "Epoch 272: accuracy on training set: 0.5447\n",
            "Epoch 272: loss on validation set: 0.6771\n",
            "Epoch 273: loss on final training batch: 0.6718\n",
            "Epoch 273: accuracy on validation set: 0.5444\n",
            "Epoch 273: accuracy on training set: 0.5448\n",
            "Epoch 273: loss on validation set: 0.6771\n",
            "Epoch 274: loss on final training batch: 0.6718\n",
            "Epoch 274: accuracy on validation set: 0.5440\n",
            "Epoch 274: accuracy on training set: 0.5449\n",
            "Epoch 274: loss on validation set: 0.6771\n",
            "Epoch 275: loss on final training batch: 0.6718\n",
            "Epoch 275: accuracy on validation set: 0.5437\n",
            "Epoch 275: accuracy on training set: 0.5450\n",
            "Epoch 275: loss on validation set: 0.6771\n",
            "Epoch 276: loss on final training batch: 0.6717\n",
            "Epoch 276: accuracy on validation set: 0.5437\n",
            "Epoch 276: accuracy on training set: 0.5448\n",
            "Epoch 276: loss on validation set: 0.6771\n",
            "Epoch 277: loss on final training batch: 0.6717\n",
            "Epoch 277: accuracy on validation set: 0.5440\n",
            "Epoch 277: accuracy on training set: 0.5447\n",
            "Epoch 277: loss on validation set: 0.6771\n",
            "Epoch 278: loss on final training batch: 0.6717\n",
            "Epoch 278: accuracy on validation set: 0.5437\n",
            "Epoch 278: accuracy on training set: 0.5448\n",
            "Epoch 278: loss on validation set: 0.6771\n",
            "Epoch 279: loss on final training batch: 0.6717\n",
            "Epoch 279: accuracy on validation set: 0.5437\n",
            "Epoch 279: accuracy on training set: 0.5448\n",
            "Epoch 279: loss on validation set: 0.6771\n",
            "Epoch 280: loss on final training batch: 0.6717\n",
            "Epoch 280: accuracy on validation set: 0.5437\n",
            "Epoch 280: accuracy on training set: 0.5447\n",
            "Epoch 280: loss on validation set: 0.6771\n",
            "Epoch 281: loss on final training batch: 0.6717\n",
            "Epoch 281: accuracy on validation set: 0.5433\n",
            "Epoch 281: accuracy on training set: 0.5447\n",
            "Epoch 281: loss on validation set: 0.6771\n",
            "Epoch 282: loss on final training batch: 0.6717\n",
            "Epoch 282: accuracy on validation set: 0.5433\n",
            "Epoch 282: accuracy on training set: 0.5449\n",
            "Epoch 282: loss on validation set: 0.6771\n",
            "Epoch 283: loss on final training batch: 0.6716\n",
            "Epoch 283: accuracy on validation set: 0.5433\n",
            "Epoch 283: accuracy on training set: 0.5450\n",
            "Epoch 283: loss on validation set: 0.6771\n",
            "Epoch 284: loss on final training batch: 0.6716\n",
            "Epoch 284: accuracy on validation set: 0.5433\n",
            "Epoch 284: accuracy on training set: 0.5451\n",
            "Epoch 284: loss on validation set: 0.6771\n",
            "Epoch 285: loss on final training batch: 0.6716\n",
            "Epoch 285: accuracy on validation set: 0.5435\n",
            "Epoch 285: accuracy on training set: 0.5453\n",
            "Epoch 285: loss on validation set: 0.6771\n",
            "Epoch 286: loss on final training batch: 0.6716\n",
            "Epoch 286: accuracy on validation set: 0.5435\n",
            "Epoch 286: accuracy on training set: 0.5452\n",
            "Epoch 286: loss on validation set: 0.6771\n",
            "Epoch 287: loss on final training batch: 0.6716\n",
            "Epoch 287: accuracy on validation set: 0.5440\n",
            "Epoch 287: accuracy on training set: 0.5452\n",
            "Epoch 287: loss on validation set: 0.6771\n",
            "Epoch 288: loss on final training batch: 0.6716\n",
            "Epoch 288: accuracy on validation set: 0.5440\n",
            "Epoch 288: accuracy on training set: 0.5453\n",
            "Epoch 288: loss on validation set: 0.6771\n",
            "Epoch 289: loss on final training batch: 0.6716\n",
            "Epoch 289: accuracy on validation set: 0.5440\n",
            "Epoch 289: accuracy on training set: 0.5453\n",
            "Epoch 289: loss on validation set: 0.6771\n",
            "Epoch 290: loss on final training batch: 0.6715\n",
            "Epoch 290: accuracy on validation set: 0.5437\n",
            "Epoch 290: accuracy on training set: 0.5452\n",
            "Epoch 290: loss on validation set: 0.6771\n",
            "Epoch 291: loss on final training batch: 0.6715\n",
            "Epoch 291: accuracy on validation set: 0.5435\n",
            "Epoch 291: accuracy on training set: 0.5452\n",
            "Epoch 291: loss on validation set: 0.6771\n",
            "Epoch 292: loss on final training batch: 0.6715\n",
            "Epoch 292: accuracy on validation set: 0.5435\n",
            "Epoch 292: accuracy on training set: 0.5452\n",
            "Epoch 292: loss on validation set: 0.6771\n",
            "Epoch 293: loss on final training batch: 0.6715\n",
            "Epoch 293: accuracy on validation set: 0.5437\n",
            "Epoch 293: accuracy on training set: 0.5452\n",
            "Epoch 293: loss on validation set: 0.6771\n",
            "Epoch 294: loss on final training batch: 0.6715\n",
            "Epoch 294: accuracy on validation set: 0.5435\n",
            "Epoch 294: accuracy on training set: 0.5452\n",
            "Epoch 294: loss on validation set: 0.6771\n",
            "Epoch 295: loss on final training batch: 0.6715\n",
            "Epoch 295: accuracy on validation set: 0.5435\n",
            "Epoch 295: accuracy on training set: 0.5453\n",
            "Epoch 295: loss on validation set: 0.6771\n",
            "Epoch 296: loss on final training batch: 0.6715\n",
            "Epoch 296: accuracy on validation set: 0.5433\n",
            "Epoch 296: accuracy on training set: 0.5453\n",
            "Epoch 296: loss on validation set: 0.6771\n",
            "Epoch 297: loss on final training batch: 0.6714\n",
            "Epoch 297: accuracy on validation set: 0.5431\n",
            "Epoch 297: accuracy on training set: 0.5452\n",
            "Epoch 297: loss on validation set: 0.6771\n",
            "Epoch 298: loss on final training batch: 0.6714\n",
            "Epoch 298: accuracy on validation set: 0.5431\n",
            "Epoch 298: accuracy on training set: 0.5452\n",
            "Epoch 298: loss on validation set: 0.6771\n",
            "Epoch 299: loss on final training batch: 0.6714\n",
            "Epoch 299: accuracy on validation set: 0.5431\n",
            "Epoch 299: accuracy on training set: 0.5451\n",
            "Epoch 299: loss on validation set: 0.6771\n",
            "Epoch 300: loss on final training batch: 0.6714\n",
            "Epoch 300: accuracy on validation set: 0.5431\n",
            "Epoch 300: accuracy on training set: 0.5451\n",
            "Epoch 300: loss on validation set: 0.6771\n",
            "Epoch 301: loss on final training batch: 0.6714\n",
            "Epoch 301: accuracy on validation set: 0.5429\n",
            "Epoch 301: accuracy on training set: 0.5453\n",
            "Epoch 301: loss on validation set: 0.6771\n",
            "Epoch 302: loss on final training batch: 0.6714\n",
            "Epoch 302: accuracy on validation set: 0.5425\n",
            "Epoch 302: accuracy on training set: 0.5451\n",
            "Epoch 302: loss on validation set: 0.6771\n",
            "Epoch 303: loss on final training batch: 0.6714\n",
            "Epoch 303: accuracy on validation set: 0.5425\n",
            "Epoch 303: accuracy on training set: 0.5450\n",
            "Epoch 303: loss on validation set: 0.6771\n",
            "Epoch 304: loss on final training batch: 0.6714\n",
            "Epoch 304: accuracy on validation set: 0.5425\n",
            "Epoch 304: accuracy on training set: 0.5450\n",
            "Epoch 304: loss on validation set: 0.6771\n",
            "Epoch 305: loss on final training batch: 0.6713\n",
            "Epoch 305: accuracy on validation set: 0.5423\n",
            "Epoch 305: accuracy on training set: 0.5450\n",
            "Epoch 305: loss on validation set: 0.6771\n",
            "Epoch 306: loss on final training batch: 0.6713\n",
            "Epoch 306: accuracy on validation set: 0.5425\n",
            "Epoch 306: accuracy on training set: 0.5450\n",
            "Epoch 306: loss on validation set: 0.6771\n",
            "Epoch 307: loss on final training batch: 0.6713\n",
            "Epoch 307: accuracy on validation set: 0.5425\n",
            "Epoch 307: accuracy on training set: 0.5450\n",
            "Epoch 307: loss on validation set: 0.6771\n",
            "Epoch 308: loss on final training batch: 0.6713\n",
            "Epoch 308: accuracy on validation set: 0.5425\n",
            "Epoch 308: accuracy on training set: 0.5450\n",
            "Epoch 308: loss on validation set: 0.6771\n",
            "Epoch 309: loss on final training batch: 0.6713\n",
            "Epoch 309: accuracy on validation set: 0.5425\n",
            "Epoch 309: accuracy on training set: 0.5450\n",
            "Epoch 309: loss on validation set: 0.6771\n",
            "Epoch 310: loss on final training batch: 0.6713\n",
            "Epoch 310: accuracy on validation set: 0.5425\n",
            "Epoch 310: accuracy on training set: 0.5450\n",
            "Epoch 310: loss on validation set: 0.6771\n",
            "Epoch 311: loss on final training batch: 0.6713\n",
            "Epoch 311: accuracy on validation set: 0.5425\n",
            "Epoch 311: accuracy on training set: 0.5450\n",
            "Epoch 311: loss on validation set: 0.6771\n",
            "Epoch 312: loss on final training batch: 0.6713\n",
            "Epoch 312: accuracy on validation set: 0.5425\n",
            "Epoch 312: accuracy on training set: 0.5449\n",
            "Epoch 312: loss on validation set: 0.6771\n",
            "Epoch 313: loss on final training batch: 0.6712\n",
            "Epoch 313: accuracy on validation set: 0.5425\n",
            "Epoch 313: accuracy on training set: 0.5449\n",
            "Epoch 313: loss on validation set: 0.6771\n",
            "Epoch 314: loss on final training batch: 0.6712\n",
            "Epoch 314: accuracy on validation set: 0.5425\n",
            "Epoch 314: accuracy on training set: 0.5449\n",
            "Epoch 314: loss on validation set: 0.6771\n",
            "Epoch 315: loss on final training batch: 0.6712\n",
            "Epoch 315: accuracy on validation set: 0.5425\n",
            "Epoch 315: accuracy on training set: 0.5449\n",
            "Epoch 315: loss on validation set: 0.6771\n",
            "Epoch 316: loss on final training batch: 0.6712\n",
            "Epoch 316: accuracy on validation set: 0.5425\n",
            "Epoch 316: accuracy on training set: 0.5450\n",
            "Epoch 316: loss on validation set: 0.6771\n",
            "Epoch 317: loss on final training batch: 0.6712\n",
            "Epoch 317: accuracy on validation set: 0.5429\n",
            "Epoch 317: accuracy on training set: 0.5450\n",
            "Epoch 317: loss on validation set: 0.6771\n",
            "Epoch 318: loss on final training batch: 0.6712\n",
            "Epoch 318: accuracy on validation set: 0.5429\n",
            "Epoch 318: accuracy on training set: 0.5450\n",
            "Epoch 318: loss on validation set: 0.6771\n",
            "Epoch 319: loss on final training batch: 0.6712\n",
            "Epoch 319: accuracy on validation set: 0.5427\n",
            "Epoch 319: accuracy on training set: 0.5450\n",
            "Epoch 319: loss on validation set: 0.6771\n",
            "Epoch 320: loss on final training batch: 0.6712\n",
            "Epoch 320: accuracy on validation set: 0.5425\n",
            "Epoch 320: accuracy on training set: 0.5449\n",
            "Epoch 320: loss on validation set: 0.6771\n",
            "Epoch 321: loss on final training batch: 0.6711\n",
            "Epoch 321: accuracy on validation set: 0.5425\n",
            "Epoch 321: accuracy on training set: 0.5449\n",
            "Epoch 321: loss on validation set: 0.6771\n",
            "Epoch 322: loss on final training batch: 0.6711\n",
            "Epoch 322: accuracy on validation set: 0.5425\n",
            "Epoch 322: accuracy on training set: 0.5450\n",
            "Epoch 322: loss on validation set: 0.6771\n",
            "Epoch 323: loss on final training batch: 0.6711\n",
            "Epoch 323: accuracy on validation set: 0.5425\n",
            "Epoch 323: accuracy on training set: 0.5450\n",
            "Epoch 323: loss on validation set: 0.6771\n",
            "Epoch 324: loss on final training batch: 0.6711\n",
            "Epoch 324: accuracy on validation set: 0.5425\n",
            "Epoch 324: accuracy on training set: 0.5450\n",
            "Epoch 324: loss on validation set: 0.6771\n",
            "Epoch 325: loss on final training batch: 0.6711\n",
            "Epoch 325: accuracy on validation set: 0.5425\n",
            "Epoch 325: accuracy on training set: 0.5449\n",
            "Epoch 325: loss on validation set: 0.6771\n",
            "Epoch 326: loss on final training batch: 0.6711\n",
            "Epoch 326: accuracy on validation set: 0.5425\n",
            "Epoch 326: accuracy on training set: 0.5450\n",
            "Epoch 326: loss on validation set: 0.6771\n",
            "Epoch 327: loss on final training batch: 0.6711\n",
            "Epoch 327: accuracy on validation set: 0.5425\n",
            "Epoch 327: accuracy on training set: 0.5450\n",
            "Epoch 327: loss on validation set: 0.6771\n",
            "Epoch 328: loss on final training batch: 0.6711\n",
            "Epoch 328: accuracy on validation set: 0.5425\n",
            "Epoch 328: accuracy on training set: 0.5450\n",
            "Epoch 328: loss on validation set: 0.6771\n",
            "Epoch 329: loss on final training batch: 0.6710\n",
            "Epoch 329: accuracy on validation set: 0.5425\n",
            "Epoch 329: accuracy on training set: 0.5451\n",
            "Epoch 329: loss on validation set: 0.6771\n",
            "Epoch 330: loss on final training batch: 0.6710\n",
            "Epoch 330: accuracy on validation set: 0.5427\n",
            "Epoch 330: accuracy on training set: 0.5450\n",
            "Epoch 330: loss on validation set: 0.6771\n",
            "Epoch 331: loss on final training batch: 0.6710\n",
            "Epoch 331: accuracy on validation set: 0.5427\n",
            "Epoch 331: accuracy on training set: 0.5448\n",
            "Epoch 331: loss on validation set: 0.6771\n",
            "Epoch 332: loss on final training batch: 0.6710\n",
            "Epoch 332: accuracy on validation set: 0.5429\n",
            "Epoch 332: accuracy on training set: 0.5448\n",
            "Epoch 332: loss on validation set: 0.6771\n",
            "Epoch 333: loss on final training batch: 0.6710\n",
            "Epoch 333: accuracy on validation set: 0.5429\n",
            "Epoch 333: accuracy on training set: 0.5449\n",
            "Epoch 333: loss on validation set: 0.6771\n",
            "Epoch 334: loss on final training batch: 0.6710\n",
            "Epoch 334: accuracy on validation set: 0.5429\n",
            "Epoch 334: accuracy on training set: 0.5450\n",
            "Epoch 334: loss on validation set: 0.6771\n",
            "Epoch 335: loss on final training batch: 0.6710\n",
            "Epoch 335: accuracy on validation set: 0.5427\n",
            "Epoch 335: accuracy on training set: 0.5450\n",
            "Epoch 335: loss on validation set: 0.6771\n",
            "Epoch 336: loss on final training batch: 0.6710\n",
            "Epoch 336: accuracy on validation set: 0.5427\n",
            "Epoch 336: accuracy on training set: 0.5450\n",
            "Epoch 336: loss on validation set: 0.6771\n",
            "Epoch 337: loss on final training batch: 0.6710\n",
            "Epoch 337: accuracy on validation set: 0.5429\n",
            "Epoch 337: accuracy on training set: 0.5451\n",
            "Epoch 337: loss on validation set: 0.6771\n",
            "Epoch 338: loss on final training batch: 0.6709\n",
            "Epoch 338: accuracy on validation set: 0.5431\n",
            "Epoch 338: accuracy on training set: 0.5451\n",
            "Epoch 338: loss on validation set: 0.6771\n",
            "Epoch 339: loss on final training batch: 0.6709\n",
            "Epoch 339: accuracy on validation set: 0.5431\n",
            "Epoch 339: accuracy on training set: 0.5451\n",
            "Epoch 339: loss on validation set: 0.6771\n",
            "Epoch 340: loss on final training batch: 0.6709\n",
            "Epoch 340: accuracy on validation set: 0.5431\n",
            "Epoch 340: accuracy on training set: 0.5452\n",
            "Epoch 340: loss on validation set: 0.6771\n",
            "Epoch 341: loss on final training batch: 0.6709\n",
            "Epoch 341: accuracy on validation set: 0.5431\n",
            "Epoch 341: accuracy on training set: 0.5451\n",
            "Epoch 341: loss on validation set: 0.6771\n",
            "Epoch 342: loss on final training batch: 0.6709\n",
            "Epoch 342: accuracy on validation set: 0.5429\n",
            "Epoch 342: accuracy on training set: 0.5451\n",
            "Epoch 342: loss on validation set: 0.6771\n",
            "Epoch 343: loss on final training batch: 0.6709\n",
            "Epoch 343: accuracy on validation set: 0.5429\n",
            "Epoch 343: accuracy on training set: 0.5451\n",
            "Epoch 343: loss on validation set: 0.6771\n",
            "Epoch 344: loss on final training batch: 0.6709\n",
            "Epoch 344: accuracy on validation set: 0.5429\n",
            "Epoch 344: accuracy on training set: 0.5452\n",
            "Epoch 344: loss on validation set: 0.6771\n",
            "Epoch 345: loss on final training batch: 0.6709\n",
            "Epoch 345: accuracy on validation set: 0.5429\n",
            "Epoch 345: accuracy on training set: 0.5453\n",
            "Epoch 345: loss on validation set: 0.6771\n",
            "Epoch 346: loss on final training batch: 0.6708\n",
            "Epoch 346: accuracy on validation set: 0.5429\n",
            "Epoch 346: accuracy on training set: 0.5455\n",
            "Epoch 346: loss on validation set: 0.6771\n",
            "Epoch 347: loss on final training batch: 0.6708\n",
            "Epoch 347: accuracy on validation set: 0.5431\n",
            "Epoch 347: accuracy on training set: 0.5454\n",
            "Epoch 347: loss on validation set: 0.6771\n",
            "Epoch 348: loss on final training batch: 0.6708\n",
            "Epoch 348: accuracy on validation set: 0.5431\n",
            "Epoch 348: accuracy on training set: 0.5453\n",
            "Epoch 348: loss on validation set: 0.6771\n",
            "Epoch 349: loss on final training batch: 0.6708\n",
            "Epoch 349: accuracy on validation set: 0.5431\n",
            "Epoch 349: accuracy on training set: 0.5453\n",
            "Epoch 349: loss on validation set: 0.6771\n",
            "Epoch 350: loss on final training batch: 0.6708\n",
            "Epoch 350: accuracy on validation set: 0.5431\n",
            "Epoch 350: accuracy on training set: 0.5453\n",
            "Epoch 350: loss on validation set: 0.6771\n",
            "Epoch 351: loss on final training batch: 0.6708\n",
            "Epoch 351: accuracy on validation set: 0.5433\n",
            "Epoch 351: accuracy on training set: 0.5453\n",
            "Epoch 351: loss on validation set: 0.6771\n",
            "Epoch 352: loss on final training batch: 0.6708\n",
            "Epoch 352: accuracy on validation set: 0.5433\n",
            "Epoch 352: accuracy on training set: 0.5454\n",
            "Epoch 352: loss on validation set: 0.6771\n",
            "Epoch 353: loss on final training batch: 0.6707\n",
            "Epoch 353: accuracy on validation set: 0.5433\n",
            "Epoch 353: accuracy on training set: 0.5454\n",
            "Epoch 353: loss on validation set: 0.6771\n",
            "Epoch 354: loss on final training batch: 0.6707\n",
            "Epoch 354: accuracy on validation set: 0.5433\n",
            "Epoch 354: accuracy on training set: 0.5455\n",
            "Epoch 354: loss on validation set: 0.6771\n",
            "Epoch 355: loss on final training batch: 0.6707\n",
            "Epoch 355: accuracy on validation set: 0.5435\n",
            "Epoch 355: accuracy on training set: 0.5454\n",
            "Epoch 355: loss on validation set: 0.6771\n",
            "Epoch 356: loss on final training batch: 0.6707\n",
            "Epoch 356: accuracy on validation set: 0.5431\n",
            "Epoch 356: accuracy on training set: 0.5454\n",
            "Epoch 356: loss on validation set: 0.6771\n",
            "Epoch 357: loss on final training batch: 0.6707\n",
            "Epoch 357: accuracy on validation set: 0.5431\n",
            "Epoch 357: accuracy on training set: 0.5455\n",
            "Epoch 357: loss on validation set: 0.6771\n",
            "Epoch 358: loss on final training batch: 0.6707\n",
            "Epoch 358: accuracy on validation set: 0.5431\n",
            "Epoch 358: accuracy on training set: 0.5454\n",
            "Epoch 358: loss on validation set: 0.6771\n",
            "Epoch 359: loss on final training batch: 0.6707\n",
            "Epoch 359: accuracy on validation set: 0.5431\n",
            "Epoch 359: accuracy on training set: 0.5453\n",
            "Epoch 359: loss on validation set: 0.6771\n",
            "Epoch 360: loss on final training batch: 0.6707\n",
            "Epoch 360: accuracy on validation set: 0.5433\n",
            "Epoch 360: accuracy on training set: 0.5453\n",
            "Epoch 360: loss on validation set: 0.6771\n",
            "Epoch 361: loss on final training batch: 0.6706\n",
            "Epoch 361: accuracy on validation set: 0.5433\n",
            "Epoch 361: accuracy on training set: 0.5453\n",
            "Epoch 361: loss on validation set: 0.6771\n",
            "Epoch 362: loss on final training batch: 0.6706\n",
            "Epoch 362: accuracy on validation set: 0.5433\n",
            "Epoch 362: accuracy on training set: 0.5454\n",
            "Epoch 362: loss on validation set: 0.6771\n",
            "Epoch 363: loss on final training batch: 0.6706\n",
            "Epoch 363: accuracy on validation set: 0.5433\n",
            "Epoch 363: accuracy on training set: 0.5454\n",
            "Epoch 363: loss on validation set: 0.6771\n",
            "Epoch 364: loss on final training batch: 0.6706\n",
            "Epoch 364: accuracy on validation set: 0.5433\n",
            "Epoch 364: accuracy on training set: 0.5454\n",
            "Epoch 364: loss on validation set: 0.6771\n",
            "Epoch 365: loss on final training batch: 0.6706\n",
            "Epoch 365: accuracy on validation set: 0.5431\n",
            "Epoch 365: accuracy on training set: 0.5454\n",
            "Epoch 365: loss on validation set: 0.6771\n",
            "Epoch 366: loss on final training batch: 0.6706\n",
            "Epoch 366: accuracy on validation set: 0.5429\n",
            "Epoch 366: accuracy on training set: 0.5454\n",
            "Epoch 366: loss on validation set: 0.6771\n",
            "Epoch 367: loss on final training batch: 0.6706\n",
            "Epoch 367: accuracy on validation set: 0.5431\n",
            "Epoch 367: accuracy on training set: 0.5453\n",
            "Epoch 367: loss on validation set: 0.6771\n",
            "Epoch 368: loss on final training batch: 0.6706\n",
            "Epoch 368: accuracy on validation set: 0.5431\n",
            "Epoch 368: accuracy on training set: 0.5453\n",
            "Epoch 368: loss on validation set: 0.6771\n",
            "Epoch 369: loss on final training batch: 0.6705\n",
            "Epoch 369: accuracy on validation set: 0.5427\n",
            "Epoch 369: accuracy on training set: 0.5451\n",
            "Epoch 369: loss on validation set: 0.6771\n",
            "Epoch 370: loss on final training batch: 0.6705\n",
            "Epoch 370: accuracy on validation set: 0.5425\n",
            "Epoch 370: accuracy on training set: 0.5451\n",
            "Epoch 370: loss on validation set: 0.6771\n",
            "Epoch 371: loss on final training batch: 0.6705\n",
            "Epoch 371: accuracy on validation set: 0.5421\n",
            "Epoch 371: accuracy on training set: 0.5450\n",
            "Epoch 371: loss on validation set: 0.6771\n",
            "Epoch 372: loss on final training batch: 0.6705\n",
            "Epoch 372: accuracy on validation set: 0.5421\n",
            "Epoch 372: accuracy on training set: 0.5450\n",
            "Epoch 372: loss on validation set: 0.6771\n",
            "Epoch 373: loss on final training batch: 0.6705\n",
            "Epoch 373: accuracy on validation set: 0.5419\n",
            "Epoch 373: accuracy on training set: 0.5449\n",
            "Epoch 373: loss on validation set: 0.6771\n",
            "Epoch 374: loss on final training batch: 0.6705\n",
            "Epoch 374: accuracy on validation set: 0.5419\n",
            "Epoch 374: accuracy on training set: 0.5449\n",
            "Epoch 374: loss on validation set: 0.6771\n",
            "Epoch 375: loss on final training batch: 0.6705\n",
            "Epoch 375: accuracy on validation set: 0.5419\n",
            "Epoch 375: accuracy on training set: 0.5449\n",
            "Epoch 375: loss on validation set: 0.6771\n",
            "Epoch 376: loss on final training batch: 0.6705\n",
            "Epoch 376: accuracy on validation set: 0.5417\n",
            "Epoch 376: accuracy on training set: 0.5449\n",
            "Epoch 376: loss on validation set: 0.6771\n",
            "Epoch 377: loss on final training batch: 0.6705\n",
            "Epoch 377: accuracy on validation set: 0.5417\n",
            "Epoch 377: accuracy on training set: 0.5450\n",
            "Epoch 377: loss on validation set: 0.6771\n",
            "Epoch 378: loss on final training batch: 0.6704\n",
            "Epoch 378: accuracy on validation set: 0.5417\n",
            "Epoch 378: accuracy on training set: 0.5450\n",
            "Epoch 378: loss on validation set: 0.6771\n",
            "Epoch 379: loss on final training batch: 0.6704\n",
            "Epoch 379: accuracy on validation set: 0.5417\n",
            "Epoch 379: accuracy on training set: 0.5450\n",
            "Epoch 379: loss on validation set: 0.6771\n",
            "Epoch 380: loss on final training batch: 0.6704\n",
            "Epoch 380: accuracy on validation set: 0.5417\n",
            "Epoch 380: accuracy on training set: 0.5450\n",
            "Epoch 380: loss on validation set: 0.6771\n",
            "Epoch 381: loss on final training batch: 0.6704\n",
            "Epoch 381: accuracy on validation set: 0.5417\n",
            "Epoch 381: accuracy on training set: 0.5450\n",
            "Epoch 381: loss on validation set: 0.6771\n",
            "Epoch 382: loss on final training batch: 0.6704\n",
            "Epoch 382: accuracy on validation set: 0.5415\n",
            "Epoch 382: accuracy on training set: 0.5451\n",
            "Epoch 382: loss on validation set: 0.6771\n",
            "Epoch 383: loss on final training batch: 0.6704\n",
            "Epoch 383: accuracy on validation set: 0.5415\n",
            "Epoch 383: accuracy on training set: 0.5451\n",
            "Epoch 383: loss on validation set: 0.6771\n",
            "Epoch 384: loss on final training batch: 0.6704\n",
            "Epoch 384: accuracy on validation set: 0.5415\n",
            "Epoch 384: accuracy on training set: 0.5451\n",
            "Epoch 384: loss on validation set: 0.6771\n",
            "Epoch 385: loss on final training batch: 0.6704\n",
            "Epoch 385: accuracy on validation set: 0.5415\n",
            "Epoch 385: accuracy on training set: 0.5451\n",
            "Epoch 385: loss on validation set: 0.6771\n",
            "Epoch 386: loss on final training batch: 0.6703\n",
            "Epoch 386: accuracy on validation set: 0.5415\n",
            "Epoch 386: accuracy on training set: 0.5451\n",
            "Epoch 386: loss on validation set: 0.6771\n",
            "Epoch 387: loss on final training batch: 0.6703\n",
            "Epoch 387: accuracy on validation set: 0.5415\n",
            "Epoch 387: accuracy on training set: 0.5452\n",
            "Epoch 387: loss on validation set: 0.6771\n",
            "Epoch 388: loss on final training batch: 0.6703\n",
            "Epoch 388: accuracy on validation set: 0.5415\n",
            "Epoch 388: accuracy on training set: 0.5451\n",
            "Epoch 388: loss on validation set: 0.6771\n",
            "Epoch 389: loss on final training batch: 0.6703\n",
            "Epoch 389: accuracy on validation set: 0.5417\n",
            "Epoch 389: accuracy on training set: 0.5453\n",
            "Epoch 389: loss on validation set: 0.6771\n",
            "Epoch 390: loss on final training batch: 0.6703\n",
            "Epoch 390: accuracy on validation set: 0.5417\n",
            "Epoch 390: accuracy on training set: 0.5453\n",
            "Epoch 390: loss on validation set: 0.6771\n",
            "Epoch 391: loss on final training batch: 0.6703\n",
            "Epoch 391: accuracy on validation set: 0.5417\n",
            "Epoch 391: accuracy on training set: 0.5452\n",
            "Epoch 391: loss on validation set: 0.6771\n",
            "Epoch 392: loss on final training batch: 0.6703\n",
            "Epoch 392: accuracy on validation set: 0.5417\n",
            "Epoch 392: accuracy on training set: 0.5453\n",
            "Epoch 392: loss on validation set: 0.6771\n",
            "Epoch 393: loss on final training batch: 0.6703\n",
            "Epoch 393: accuracy on validation set: 0.5419\n",
            "Epoch 393: accuracy on training set: 0.5454\n",
            "Epoch 393: loss on validation set: 0.6771\n",
            "Epoch 394: loss on final training batch: 0.6702\n",
            "Epoch 394: accuracy on validation set: 0.5415\n",
            "Epoch 394: accuracy on training set: 0.5453\n",
            "Epoch 394: loss on validation set: 0.6771\n",
            "Epoch 395: loss on final training batch: 0.6702\n",
            "Epoch 395: accuracy on validation set: 0.5410\n",
            "Epoch 395: accuracy on training set: 0.5453\n",
            "Epoch 395: loss on validation set: 0.6771\n",
            "Epoch 396: loss on final training batch: 0.6702\n",
            "Epoch 396: accuracy on validation set: 0.5410\n",
            "Epoch 396: accuracy on training set: 0.5453\n",
            "Epoch 396: loss on validation set: 0.6771\n",
            "Epoch 397: loss on final training batch: 0.6702\n",
            "Epoch 397: accuracy on validation set: 0.5410\n",
            "Epoch 397: accuracy on training set: 0.5453\n",
            "Epoch 397: loss on validation set: 0.6771\n",
            "Epoch 398: loss on final training batch: 0.6702\n",
            "Epoch 398: accuracy on validation set: 0.5410\n",
            "Epoch 398: accuracy on training set: 0.5455\n",
            "Epoch 398: loss on validation set: 0.6771\n",
            "Epoch 399: loss on final training batch: 0.6702\n",
            "Epoch 399: accuracy on validation set: 0.5410\n",
            "Epoch 399: accuracy on training set: 0.5454\n",
            "Epoch 399: loss on validation set: 0.6771\n",
            "Epoch 400: loss on final training batch: 0.6702\n",
            "Epoch 400: accuracy on validation set: 0.5412\n",
            "Epoch 400: accuracy on training set: 0.5453\n",
            "Epoch 400: loss on validation set: 0.6771\n",
            "Epoch 401: loss on final training batch: 0.6702\n",
            "Epoch 401: accuracy on validation set: 0.5412\n",
            "Epoch 401: accuracy on training set: 0.5453\n",
            "Epoch 401: loss on validation set: 0.6771\n",
            "Epoch 402: loss on final training batch: 0.6701\n",
            "Epoch 402: accuracy on validation set: 0.5412\n",
            "Epoch 402: accuracy on training set: 0.5453\n",
            "Epoch 402: loss on validation set: 0.6771\n",
            "Epoch 403: loss on final training batch: 0.6701\n",
            "Epoch 403: accuracy on validation set: 0.5412\n",
            "Epoch 403: accuracy on training set: 0.5454\n",
            "Epoch 403: loss on validation set: 0.6771\n",
            "Epoch 404: loss on final training batch: 0.6701\n",
            "Epoch 404: accuracy on validation set: 0.5412\n",
            "Epoch 404: accuracy on training set: 0.5455\n",
            "Epoch 404: loss on validation set: 0.6771\n",
            "Epoch 405: loss on final training batch: 0.6701\n",
            "Epoch 405: accuracy on validation set: 0.5412\n",
            "Epoch 405: accuracy on training set: 0.5455\n",
            "Epoch 405: loss on validation set: 0.6771\n",
            "Epoch 406: loss on final training batch: 0.6701\n",
            "Epoch 406: accuracy on validation set: 0.5410\n",
            "Epoch 406: accuracy on training set: 0.5456\n",
            "Epoch 406: loss on validation set: 0.6771\n",
            "Epoch 407: loss on final training batch: 0.6701\n",
            "Epoch 407: accuracy on validation set: 0.5412\n",
            "Epoch 407: accuracy on training set: 0.5455\n",
            "Epoch 407: loss on validation set: 0.6771\n",
            "Epoch 408: loss on final training batch: 0.6701\n",
            "Epoch 408: accuracy on validation set: 0.5412\n",
            "Epoch 408: accuracy on training set: 0.5456\n",
            "Epoch 408: loss on validation set: 0.6771\n",
            "Epoch 409: loss on final training batch: 0.6701\n",
            "Epoch 409: accuracy on validation set: 0.5412\n",
            "Epoch 409: accuracy on training set: 0.5457\n",
            "Epoch 409: loss on validation set: 0.6771\n",
            "Epoch 410: loss on final training batch: 0.6701\n",
            "Epoch 410: accuracy on validation set: 0.5412\n",
            "Epoch 410: accuracy on training set: 0.5458\n",
            "Epoch 410: loss on validation set: 0.6771\n",
            "Epoch 411: loss on final training batch: 0.6700\n",
            "Epoch 411: accuracy on validation set: 0.5412\n",
            "Epoch 411: accuracy on training set: 0.5456\n",
            "Epoch 411: loss on validation set: 0.6771\n",
            "Epoch 412: loss on final training batch: 0.6700\n",
            "Epoch 412: accuracy on validation set: 0.5412\n",
            "Epoch 412: accuracy on training set: 0.5456\n",
            "Epoch 412: loss on validation set: 0.6771\n",
            "Epoch 413: loss on final training batch: 0.6700\n",
            "Epoch 413: accuracy on validation set: 0.5410\n",
            "Epoch 413: accuracy on training set: 0.5456\n",
            "Epoch 413: loss on validation set: 0.6771\n",
            "Epoch 414: loss on final training batch: 0.6700\n",
            "Epoch 414: accuracy on validation set: 0.5408\n",
            "Epoch 414: accuracy on training set: 0.5456\n",
            "Epoch 414: loss on validation set: 0.6771\n",
            "Epoch 415: loss on final training batch: 0.6700\n",
            "Epoch 415: accuracy on validation set: 0.5408\n",
            "Epoch 415: accuracy on training set: 0.5455\n",
            "Epoch 415: loss on validation set: 0.6771\n",
            "Epoch 416: loss on final training batch: 0.6700\n",
            "Epoch 416: accuracy on validation set: 0.5408\n",
            "Epoch 416: accuracy on training set: 0.5455\n",
            "Epoch 416: loss on validation set: 0.6771\n",
            "Epoch 417: loss on final training batch: 0.6700\n",
            "Epoch 417: accuracy on validation set: 0.5410\n",
            "Epoch 417: accuracy on training set: 0.5456\n",
            "Epoch 417: loss on validation set: 0.6771\n",
            "Epoch 418: loss on final training batch: 0.6700\n",
            "Epoch 418: accuracy on validation set: 0.5410\n",
            "Epoch 418: accuracy on training set: 0.5456\n",
            "Epoch 418: loss on validation set: 0.6771\n",
            "Epoch 419: loss on final training batch: 0.6699\n",
            "Epoch 419: accuracy on validation set: 0.5410\n",
            "Epoch 419: accuracy on training set: 0.5456\n",
            "Epoch 419: loss on validation set: 0.6771\n",
            "Epoch 420: loss on final training batch: 0.6699\n",
            "Epoch 420: accuracy on validation set: 0.5410\n",
            "Epoch 420: accuracy on training set: 0.5456\n",
            "Epoch 420: loss on validation set: 0.6771\n",
            "Epoch 421: loss on final training batch: 0.6699\n",
            "Epoch 421: accuracy on validation set: 0.5408\n",
            "Epoch 421: accuracy on training set: 0.5456\n",
            "Epoch 421: loss on validation set: 0.6771\n",
            "Epoch 422: loss on final training batch: 0.6699\n",
            "Epoch 422: accuracy on validation set: 0.5408\n",
            "Epoch 422: accuracy on training set: 0.5456\n",
            "Epoch 422: loss on validation set: 0.6771\n",
            "Epoch 423: loss on final training batch: 0.6699\n",
            "Epoch 423: accuracy on validation set: 0.5406\n",
            "Epoch 423: accuracy on training set: 0.5457\n",
            "Epoch 423: loss on validation set: 0.6771\n",
            "Epoch 424: loss on final training batch: 0.6699\n",
            "Epoch 424: accuracy on validation set: 0.5404\n",
            "Epoch 424: accuracy on training set: 0.5457\n",
            "Epoch 424: loss on validation set: 0.6771\n",
            "Epoch 425: loss on final training batch: 0.6699\n",
            "Epoch 425: accuracy on validation set: 0.5404\n",
            "Epoch 425: accuracy on training set: 0.5459\n",
            "Epoch 425: loss on validation set: 0.6771\n",
            "Epoch 426: loss on final training batch: 0.6698\n",
            "Epoch 426: accuracy on validation set: 0.5404\n",
            "Epoch 426: accuracy on training set: 0.5458\n",
            "Epoch 426: loss on validation set: 0.6771\n",
            "Epoch 427: loss on final training batch: 0.6698\n",
            "Epoch 427: accuracy on validation set: 0.5404\n",
            "Epoch 427: accuracy on training set: 0.5458\n",
            "Epoch 427: loss on validation set: 0.6771\n",
            "Epoch 428: loss on final training batch: 0.6698\n",
            "Epoch 428: accuracy on validation set: 0.5404\n",
            "Epoch 428: accuracy on training set: 0.5458\n",
            "Epoch 428: loss on validation set: 0.6771\n",
            "Epoch 429: loss on final training batch: 0.6698\n",
            "Epoch 429: accuracy on validation set: 0.5406\n",
            "Epoch 429: accuracy on training set: 0.5459\n",
            "Epoch 429: loss on validation set: 0.6771\n",
            "Epoch 430: loss on final training batch: 0.6698\n",
            "Epoch 430: accuracy on validation set: 0.5404\n",
            "Epoch 430: accuracy on training set: 0.5459\n",
            "Epoch 430: loss on validation set: 0.6771\n",
            "Epoch 431: loss on final training batch: 0.6698\n",
            "Epoch 431: accuracy on validation set: 0.5404\n",
            "Epoch 431: accuracy on training set: 0.5459\n",
            "Epoch 431: loss on validation set: 0.6771\n",
            "Epoch 432: loss on final training batch: 0.6698\n",
            "Epoch 432: accuracy on validation set: 0.5406\n",
            "Epoch 432: accuracy on training set: 0.5458\n",
            "Epoch 432: loss on validation set: 0.6771\n",
            "Epoch 433: loss on final training batch: 0.6698\n",
            "Epoch 433: accuracy on validation set: 0.5406\n",
            "Epoch 433: accuracy on training set: 0.5458\n",
            "Epoch 433: loss on validation set: 0.6771\n",
            "Epoch 434: loss on final training batch: 0.6697\n",
            "Epoch 434: accuracy on validation set: 0.5406\n",
            "Epoch 434: accuracy on training set: 0.5458\n",
            "Epoch 434: loss on validation set: 0.6771\n",
            "Epoch 435: loss on final training batch: 0.6697\n",
            "Epoch 435: accuracy on validation set: 0.5410\n",
            "Epoch 435: accuracy on training set: 0.5458\n",
            "Epoch 435: loss on validation set: 0.6771\n",
            "Epoch 436: loss on final training batch: 0.6697\n",
            "Epoch 436: accuracy on validation set: 0.5410\n",
            "Epoch 436: accuracy on training set: 0.5458\n",
            "Epoch 436: loss on validation set: 0.6771\n",
            "Epoch 437: loss on final training batch: 0.6697\n",
            "Epoch 437: accuracy on validation set: 0.5408\n",
            "Epoch 437: accuracy on training set: 0.5458\n",
            "Epoch 437: loss on validation set: 0.6771\n",
            "Epoch 438: loss on final training batch: 0.6697\n",
            "Epoch 438: accuracy on validation set: 0.5408\n",
            "Epoch 438: accuracy on training set: 0.5460\n",
            "Epoch 438: loss on validation set: 0.6771\n",
            "Epoch 439: loss on final training batch: 0.6697\n",
            "Epoch 439: accuracy on validation set: 0.5406\n",
            "Epoch 439: accuracy on training set: 0.5460\n",
            "Epoch 439: loss on validation set: 0.6771\n",
            "Epoch 440: loss on final training batch: 0.6697\n",
            "Epoch 440: accuracy on validation set: 0.5406\n",
            "Epoch 440: accuracy on training set: 0.5460\n",
            "Epoch 440: loss on validation set: 0.6771\n",
            "Epoch 441: loss on final training batch: 0.6696\n",
            "Epoch 441: accuracy on validation set: 0.5406\n",
            "Epoch 441: accuracy on training set: 0.5460\n",
            "Epoch 441: loss on validation set: 0.6771\n",
            "Epoch 442: loss on final training batch: 0.6696\n",
            "Epoch 442: accuracy on validation set: 0.5408\n",
            "Epoch 442: accuracy on training set: 0.5460\n",
            "Epoch 442: loss on validation set: 0.6771\n",
            "Epoch 443: loss on final training batch: 0.6696\n",
            "Epoch 443: accuracy on validation set: 0.5406\n",
            "Epoch 443: accuracy on training set: 0.5461\n",
            "Epoch 443: loss on validation set: 0.6771\n",
            "Epoch 444: loss on final training batch: 0.6696\n",
            "Epoch 444: accuracy on validation set: 0.5404\n",
            "Epoch 444: accuracy on training set: 0.5460\n",
            "Epoch 444: loss on validation set: 0.6771\n",
            "Epoch 445: loss on final training batch: 0.6696\n",
            "Epoch 445: accuracy on validation set: 0.5406\n",
            "Epoch 445: accuracy on training set: 0.5460\n",
            "Epoch 445: loss on validation set: 0.6771\n",
            "Epoch 446: loss on final training batch: 0.6696\n",
            "Epoch 446: accuracy on validation set: 0.5406\n",
            "Epoch 446: accuracy on training set: 0.5459\n",
            "Epoch 446: loss on validation set: 0.6771\n",
            "Epoch 447: loss on final training batch: 0.6696\n",
            "Epoch 447: accuracy on validation set: 0.5408\n",
            "Epoch 447: accuracy on training set: 0.5460\n",
            "Epoch 447: loss on validation set: 0.6771\n",
            "Epoch 448: loss on final training batch: 0.6695\n",
            "Epoch 448: accuracy on validation set: 0.5408\n",
            "Epoch 448: accuracy on training set: 0.5460\n",
            "Epoch 448: loss on validation set: 0.6771\n",
            "Epoch 449: loss on final training batch: 0.6695\n",
            "Epoch 449: accuracy on validation set: 0.5408\n",
            "Epoch 449: accuracy on training set: 0.5461\n",
            "Epoch 449: loss on validation set: 0.6771\n",
            "Epoch 450: loss on final training batch: 0.6695\n",
            "Epoch 450: accuracy on validation set: 0.5408\n",
            "Epoch 450: accuracy on training set: 0.5461\n",
            "Epoch 450: loss on validation set: 0.6771\n",
            "Epoch 451: loss on final training batch: 0.6695\n",
            "Epoch 451: accuracy on validation set: 0.5410\n",
            "Epoch 451: accuracy on training set: 0.5462\n",
            "Epoch 451: loss on validation set: 0.6771\n",
            "Epoch 452: loss on final training batch: 0.6695\n",
            "Epoch 452: accuracy on validation set: 0.5410\n",
            "Epoch 452: accuracy on training set: 0.5462\n",
            "Epoch 452: loss on validation set: 0.6771\n",
            "Epoch 453: loss on final training batch: 0.6695\n",
            "Epoch 453: accuracy on validation set: 0.5410\n",
            "Epoch 453: accuracy on training set: 0.5462\n",
            "Epoch 453: loss on validation set: 0.6771\n",
            "Epoch 454: loss on final training batch: 0.6695\n",
            "Epoch 454: accuracy on validation set: 0.5410\n",
            "Epoch 454: accuracy on training set: 0.5463\n",
            "Epoch 454: loss on validation set: 0.6771\n",
            "Epoch 455: loss on final training batch: 0.6694\n",
            "Epoch 455: accuracy on validation set: 0.5410\n",
            "Epoch 455: accuracy on training set: 0.5463\n",
            "Epoch 455: loss on validation set: 0.6771\n",
            "Epoch 456: loss on final training batch: 0.6694\n",
            "Epoch 456: accuracy on validation set: 0.5410\n",
            "Epoch 456: accuracy on training set: 0.5462\n",
            "Epoch 456: loss on validation set: 0.6771\n",
            "Epoch 457: loss on final training batch: 0.6694\n",
            "Epoch 457: accuracy on validation set: 0.5410\n",
            "Epoch 457: accuracy on training set: 0.5463\n",
            "Epoch 457: loss on validation set: 0.6771\n",
            "Epoch 458: loss on final training batch: 0.6694\n",
            "Epoch 458: accuracy on validation set: 0.5412\n",
            "Epoch 458: accuracy on training set: 0.5463\n",
            "Epoch 458: loss on validation set: 0.6771\n",
            "Epoch 459: loss on final training batch: 0.6694\n",
            "Epoch 459: accuracy on validation set: 0.5417\n",
            "Epoch 459: accuracy on training set: 0.5464\n",
            "Epoch 459: loss on validation set: 0.6771\n",
            "Epoch 460: loss on final training batch: 0.6694\n",
            "Epoch 460: accuracy on validation set: 0.5417\n",
            "Epoch 460: accuracy on training set: 0.5462\n",
            "Epoch 460: loss on validation set: 0.6771\n",
            "Epoch 461: loss on final training batch: 0.6694\n",
            "Epoch 461: accuracy on validation set: 0.5417\n",
            "Epoch 461: accuracy on training set: 0.5462\n",
            "Epoch 461: loss on validation set: 0.6771\n",
            "Epoch 462: loss on final training batch: 0.6693\n",
            "Epoch 462: accuracy on validation set: 0.5417\n",
            "Epoch 462: accuracy on training set: 0.5464\n",
            "Epoch 462: loss on validation set: 0.6771\n",
            "Epoch 463: loss on final training batch: 0.6693\n",
            "Epoch 463: accuracy on validation set: 0.5419\n",
            "Epoch 463: accuracy on training set: 0.5464\n",
            "Epoch 463: loss on validation set: 0.6771\n",
            "Epoch 464: loss on final training batch: 0.6693\n",
            "Epoch 464: accuracy on validation set: 0.5419\n",
            "Epoch 464: accuracy on training set: 0.5463\n",
            "Epoch 464: loss on validation set: 0.6771\n",
            "Epoch 465: loss on final training batch: 0.6693\n",
            "Epoch 465: accuracy on validation set: 0.5419\n",
            "Epoch 465: accuracy on training set: 0.5463\n",
            "Epoch 465: loss on validation set: 0.6771\n",
            "Epoch 466: loss on final training batch: 0.6693\n",
            "Epoch 466: accuracy on validation set: 0.5419\n",
            "Epoch 466: accuracy on training set: 0.5464\n",
            "Epoch 466: loss on validation set: 0.6771\n",
            "Epoch 467: loss on final training batch: 0.6693\n",
            "Epoch 467: accuracy on validation set: 0.5419\n",
            "Epoch 467: accuracy on training set: 0.5464\n",
            "Epoch 467: loss on validation set: 0.6771\n",
            "Epoch 468: loss on final training batch: 0.6693\n",
            "Epoch 468: accuracy on validation set: 0.5419\n",
            "Epoch 468: accuracy on training set: 0.5465\n",
            "Epoch 468: loss on validation set: 0.6771\n",
            "Epoch 469: loss on final training batch: 0.6693\n",
            "Epoch 469: accuracy on validation set: 0.5421\n",
            "Epoch 469: accuracy on training set: 0.5464\n",
            "Epoch 469: loss on validation set: 0.6771\n",
            "Epoch 470: loss on final training batch: 0.6692\n",
            "Epoch 470: accuracy on validation set: 0.5421\n",
            "Epoch 470: accuracy on training set: 0.5465\n",
            "Epoch 470: loss on validation set: 0.6771\n",
            "Epoch 471: loss on final training batch: 0.6692\n",
            "Epoch 471: accuracy on validation set: 0.5421\n",
            "Epoch 471: accuracy on training set: 0.5465\n",
            "Epoch 471: loss on validation set: 0.6771\n",
            "Epoch 472: loss on final training batch: 0.6692\n",
            "Epoch 472: accuracy on validation set: 0.5419\n",
            "Epoch 472: accuracy on training set: 0.5465\n",
            "Epoch 472: loss on validation set: 0.6771\n",
            "Epoch 473: loss on final training batch: 0.6692\n",
            "Epoch 473: accuracy on validation set: 0.5419\n",
            "Epoch 473: accuracy on training set: 0.5465\n",
            "Epoch 473: loss on validation set: 0.6771\n",
            "Epoch 474: loss on final training batch: 0.6692\n",
            "Epoch 474: accuracy on validation set: 0.5419\n",
            "Epoch 474: accuracy on training set: 0.5465\n",
            "Epoch 474: loss on validation set: 0.6771\n",
            "Epoch 475: loss on final training batch: 0.6692\n",
            "Epoch 475: accuracy on validation set: 0.5421\n",
            "Epoch 475: accuracy on training set: 0.5465\n",
            "Epoch 475: loss on validation set: 0.6771\n",
            "Epoch 476: loss on final training batch: 0.6692\n",
            "Epoch 476: accuracy on validation set: 0.5419\n",
            "Epoch 476: accuracy on training set: 0.5466\n",
            "Epoch 476: loss on validation set: 0.6771\n",
            "Epoch 477: loss on final training batch: 0.6691\n",
            "Epoch 477: accuracy on validation set: 0.5419\n",
            "Epoch 477: accuracy on training set: 0.5467\n",
            "Epoch 477: loss on validation set: 0.6771\n",
            "Epoch 478: loss on final training batch: 0.6691\n",
            "Epoch 478: accuracy on validation set: 0.5421\n",
            "Epoch 478: accuracy on training set: 0.5467\n",
            "Epoch 478: loss on validation set: 0.6771\n",
            "Epoch 479: loss on final training batch: 0.6691\n",
            "Epoch 479: accuracy on validation set: 0.5421\n",
            "Epoch 479: accuracy on training set: 0.5467\n",
            "Epoch 479: loss on validation set: 0.6771\n",
            "Epoch 480: loss on final training batch: 0.6691\n",
            "Epoch 480: accuracy on validation set: 0.5419\n",
            "Epoch 480: accuracy on training set: 0.5468\n",
            "Epoch 480: loss on validation set: 0.6771\n",
            "Epoch 481: loss on final training batch: 0.6691\n",
            "Epoch 481: accuracy on validation set: 0.5421\n",
            "Epoch 481: accuracy on training set: 0.5468\n",
            "Epoch 481: loss on validation set: 0.6771\n",
            "Epoch 482: loss on final training batch: 0.6691\n",
            "Epoch 482: accuracy on validation set: 0.5421\n",
            "Epoch 482: accuracy on training set: 0.5468\n",
            "Epoch 482: loss on validation set: 0.6771\n",
            "Epoch 483: loss on final training batch: 0.6691\n",
            "Epoch 483: accuracy on validation set: 0.5421\n",
            "Epoch 483: accuracy on training set: 0.5468\n",
            "Epoch 483: loss on validation set: 0.6771\n",
            "Epoch 484: loss on final training batch: 0.6691\n",
            "Epoch 484: accuracy on validation set: 0.5421\n",
            "Epoch 484: accuracy on training set: 0.5468\n",
            "Epoch 484: loss on validation set: 0.6771\n",
            "Epoch 485: loss on final training batch: 0.6690\n",
            "Epoch 485: accuracy on validation set: 0.5421\n",
            "Epoch 485: accuracy on training set: 0.5468\n",
            "Epoch 485: loss on validation set: 0.6771\n",
            "Epoch 486: loss on final training batch: 0.6690\n",
            "Epoch 486: accuracy on validation set: 0.5421\n",
            "Epoch 486: accuracy on training set: 0.5469\n",
            "Epoch 486: loss on validation set: 0.6771\n",
            "Epoch 487: loss on final training batch: 0.6690\n",
            "Epoch 487: accuracy on validation set: 0.5421\n",
            "Epoch 487: accuracy on training set: 0.5470\n",
            "Epoch 487: loss on validation set: 0.6771\n",
            "Epoch 488: loss on final training batch: 0.6690\n",
            "Epoch 488: accuracy on validation set: 0.5421\n",
            "Epoch 488: accuracy on training set: 0.5470\n",
            "Epoch 488: loss on validation set: 0.6771\n",
            "Epoch 489: loss on final training batch: 0.6690\n",
            "Epoch 489: accuracy on validation set: 0.5423\n",
            "Epoch 489: accuracy on training set: 0.5471\n",
            "Epoch 489: loss on validation set: 0.6771\n",
            "Epoch 490: loss on final training batch: 0.6690\n",
            "Epoch 490: accuracy on validation set: 0.5423\n",
            "Epoch 490: accuracy on training set: 0.5472\n",
            "Epoch 490: loss on validation set: 0.6771\n",
            "Epoch 491: loss on final training batch: 0.6690\n",
            "Epoch 491: accuracy on validation set: 0.5421\n",
            "Epoch 491: accuracy on training set: 0.5473\n",
            "Epoch 491: loss on validation set: 0.6771\n",
            "Epoch 492: loss on final training batch: 0.6690\n",
            "Epoch 492: accuracy on validation set: 0.5421\n",
            "Epoch 492: accuracy on training set: 0.5474\n",
            "Epoch 492: loss on validation set: 0.6771\n",
            "Epoch 493: loss on final training batch: 0.6690\n",
            "Epoch 493: accuracy on validation set: 0.5421\n",
            "Epoch 493: accuracy on training set: 0.5474\n",
            "Epoch 493: loss on validation set: 0.6771\n",
            "Epoch 494: loss on final training batch: 0.6689\n",
            "Epoch 494: accuracy on validation set: 0.5421\n",
            "Epoch 494: accuracy on training set: 0.5473\n",
            "Epoch 494: loss on validation set: 0.6770\n",
            "Epoch 495: loss on final training batch: 0.6689\n",
            "Epoch 495: accuracy on validation set: 0.5421\n",
            "Epoch 495: accuracy on training set: 0.5474\n",
            "Epoch 495: loss on validation set: 0.6770\n",
            "Epoch 496: loss on final training batch: 0.6689\n",
            "Epoch 496: accuracy on validation set: 0.5421\n",
            "Epoch 496: accuracy on training set: 0.5473\n",
            "Epoch 496: loss on validation set: 0.6770\n",
            "Epoch 497: loss on final training batch: 0.6689\n",
            "Epoch 497: accuracy on validation set: 0.5421\n",
            "Epoch 497: accuracy on training set: 0.5473\n",
            "Epoch 497: loss on validation set: 0.6770\n",
            "Epoch 498: loss on final training batch: 0.6689\n",
            "Epoch 498: accuracy on validation set: 0.5421\n",
            "Epoch 498: accuracy on training set: 0.5475\n",
            "Epoch 498: loss on validation set: 0.6770\n",
            "Epoch 499: loss on final training batch: 0.6689\n",
            "Epoch 499: accuracy on validation set: 0.5421\n",
            "Epoch 499: accuracy on training set: 0.5475\n",
            "Epoch 499: loss on validation set: 0.6770\n",
            "Epoch 500: loss on final training batch: 0.6689\n",
            "Epoch 500: accuracy on validation set: 0.5423\n",
            "Epoch 500: accuracy on training set: 0.5474\n",
            "Epoch 500: loss on validation set: 0.6770\n",
            "Epoch 501: loss on final training batch: 0.6689\n",
            "Epoch 501: accuracy on validation set: 0.5423\n",
            "Epoch 501: accuracy on training set: 0.5474\n",
            "Epoch 501: loss on validation set: 0.6770\n",
            "Epoch 502: loss on final training batch: 0.6689\n",
            "Epoch 502: accuracy on validation set: 0.5423\n",
            "Epoch 502: accuracy on training set: 0.5475\n",
            "Epoch 502: loss on validation set: 0.6770\n",
            "Epoch 503: loss on final training batch: 0.6688\n",
            "Epoch 503: accuracy on validation set: 0.5423\n",
            "Epoch 503: accuracy on training set: 0.5475\n",
            "Epoch 503: loss on validation set: 0.6770\n",
            "Epoch 504: loss on final training batch: 0.6688\n",
            "Epoch 504: accuracy on validation set: 0.5423\n",
            "Epoch 504: accuracy on training set: 0.5475\n",
            "Epoch 504: loss on validation set: 0.6770\n",
            "Epoch 505: loss on final training batch: 0.6688\n",
            "Epoch 505: accuracy on validation set: 0.5425\n",
            "Epoch 505: accuracy on training set: 0.5475\n",
            "Epoch 505: loss on validation set: 0.6770\n",
            "Epoch 506: loss on final training batch: 0.6688\n",
            "Epoch 506: accuracy on validation set: 0.5425\n",
            "Epoch 506: accuracy on training set: 0.5475\n",
            "Epoch 506: loss on validation set: 0.6770\n",
            "Epoch 507: loss on final training batch: 0.6688\n",
            "Epoch 507: accuracy on validation set: 0.5425\n",
            "Epoch 507: accuracy on training set: 0.5475\n",
            "Epoch 507: loss on validation set: 0.6770\n",
            "Epoch 508: loss on final training batch: 0.6688\n",
            "Epoch 508: accuracy on validation set: 0.5425\n",
            "Epoch 508: accuracy on training set: 0.5476\n",
            "Epoch 508: loss on validation set: 0.6770\n",
            "Epoch 509: loss on final training batch: 0.6688\n",
            "Epoch 509: accuracy on validation set: 0.5425\n",
            "Epoch 509: accuracy on training set: 0.5476\n",
            "Epoch 509: loss on validation set: 0.6770\n",
            "Epoch 510: loss on final training batch: 0.6688\n",
            "Epoch 510: accuracy on validation set: 0.5425\n",
            "Epoch 510: accuracy on training set: 0.5476\n",
            "Epoch 510: loss on validation set: 0.6770\n",
            "Epoch 511: loss on final training batch: 0.6687\n",
            "Epoch 511: accuracy on validation set: 0.5425\n",
            "Epoch 511: accuracy on training set: 0.5475\n",
            "Epoch 511: loss on validation set: 0.6770\n",
            "Epoch 512: loss on final training batch: 0.6687\n",
            "Epoch 512: accuracy on validation set: 0.5425\n",
            "Epoch 512: accuracy on training set: 0.5475\n",
            "Epoch 512: loss on validation set: 0.6770\n",
            "Epoch 513: loss on final training batch: 0.6687\n",
            "Epoch 513: accuracy on validation set: 0.5425\n",
            "Epoch 513: accuracy on training set: 0.5475\n",
            "Epoch 513: loss on validation set: 0.6770\n",
            "Epoch 514: loss on final training batch: 0.6687\n",
            "Epoch 514: accuracy on validation set: 0.5425\n",
            "Epoch 514: accuracy on training set: 0.5475\n",
            "Epoch 514: loss on validation set: 0.6770\n",
            "Epoch 515: loss on final training batch: 0.6687\n",
            "Epoch 515: accuracy on validation set: 0.5425\n",
            "Epoch 515: accuracy on training set: 0.5476\n",
            "Epoch 515: loss on validation set: 0.6770\n",
            "Epoch 516: loss on final training batch: 0.6687\n",
            "Epoch 516: accuracy on validation set: 0.5425\n",
            "Epoch 516: accuracy on training set: 0.5475\n",
            "Epoch 516: loss on validation set: 0.6770\n",
            "Epoch 517: loss on final training batch: 0.6687\n",
            "Epoch 517: accuracy on validation set: 0.5425\n",
            "Epoch 517: accuracy on training set: 0.5476\n",
            "Epoch 517: loss on validation set: 0.6770\n",
            "Epoch 518: loss on final training batch: 0.6687\n",
            "Epoch 518: accuracy on validation set: 0.5427\n",
            "Epoch 518: accuracy on training set: 0.5476\n",
            "Epoch 518: loss on validation set: 0.6770\n",
            "Epoch 519: loss on final training batch: 0.6686\n",
            "Epoch 519: accuracy on validation set: 0.5427\n",
            "Epoch 519: accuracy on training set: 0.5478\n",
            "Epoch 519: loss on validation set: 0.6770\n",
            "Epoch 520: loss on final training batch: 0.6686\n",
            "Epoch 520: accuracy on validation set: 0.5429\n",
            "Epoch 520: accuracy on training set: 0.5479\n",
            "Epoch 520: loss on validation set: 0.6770\n",
            "Epoch 521: loss on final training batch: 0.6686\n",
            "Epoch 521: accuracy on validation set: 0.5429\n",
            "Epoch 521: accuracy on training set: 0.5480\n",
            "Epoch 521: loss on validation set: 0.6770\n",
            "Epoch 522: loss on final training batch: 0.6686\n",
            "Epoch 522: accuracy on validation set: 0.5429\n",
            "Epoch 522: accuracy on training set: 0.5480\n",
            "Epoch 522: loss on validation set: 0.6770\n",
            "Epoch 523: loss on final training batch: 0.6686\n",
            "Epoch 523: accuracy on validation set: 0.5427\n",
            "Epoch 523: accuracy on training set: 0.5480\n",
            "Epoch 523: loss on validation set: 0.6770\n",
            "Epoch 524: loss on final training batch: 0.6686\n",
            "Epoch 524: accuracy on validation set: 0.5427\n",
            "Epoch 524: accuracy on training set: 0.5481\n",
            "Epoch 524: loss on validation set: 0.6770\n",
            "Epoch 525: loss on final training batch: 0.6686\n",
            "Epoch 525: accuracy on validation set: 0.5427\n",
            "Epoch 525: accuracy on training set: 0.5481\n",
            "Epoch 525: loss on validation set: 0.6770\n",
            "Epoch 526: loss on final training batch: 0.6685\n",
            "Epoch 526: accuracy on validation set: 0.5427\n",
            "Epoch 526: accuracy on training set: 0.5481\n",
            "Epoch 526: loss on validation set: 0.6770\n",
            "Epoch 527: loss on final training batch: 0.6685\n",
            "Epoch 527: accuracy on validation set: 0.5429\n",
            "Epoch 527: accuracy on training set: 0.5482\n",
            "Epoch 527: loss on validation set: 0.6770\n",
            "Epoch 528: loss on final training batch: 0.6685\n",
            "Epoch 528: accuracy on validation set: 0.5431\n",
            "Epoch 528: accuracy on training set: 0.5482\n",
            "Epoch 528: loss on validation set: 0.6770\n",
            "Epoch 529: loss on final training batch: 0.6685\n",
            "Epoch 529: accuracy on validation set: 0.5433\n",
            "Epoch 529: accuracy on training set: 0.5482\n",
            "Epoch 529: loss on validation set: 0.6770\n",
            "Epoch 530: loss on final training batch: 0.6685\n",
            "Epoch 530: accuracy on validation set: 0.5431\n",
            "Epoch 530: accuracy on training set: 0.5483\n",
            "Epoch 530: loss on validation set: 0.6770\n",
            "Epoch 531: loss on final training batch: 0.6685\n",
            "Epoch 531: accuracy on validation set: 0.5431\n",
            "Epoch 531: accuracy on training set: 0.5483\n",
            "Epoch 531: loss on validation set: 0.6770\n",
            "Epoch 532: loss on final training batch: 0.6685\n",
            "Epoch 532: accuracy on validation set: 0.5433\n",
            "Epoch 532: accuracy on training set: 0.5483\n",
            "Epoch 532: loss on validation set: 0.6770\n",
            "Epoch 533: loss on final training batch: 0.6684\n",
            "Epoch 533: accuracy on validation set: 0.5435\n",
            "Epoch 533: accuracy on training set: 0.5482\n",
            "Epoch 533: loss on validation set: 0.6770\n",
            "Epoch 534: loss on final training batch: 0.6684\n",
            "Epoch 534: accuracy on validation set: 0.5437\n",
            "Epoch 534: accuracy on training set: 0.5482\n",
            "Epoch 534: loss on validation set: 0.6770\n",
            "Epoch 535: loss on final training batch: 0.6684\n",
            "Epoch 535: accuracy on validation set: 0.5440\n",
            "Epoch 535: accuracy on training set: 0.5482\n",
            "Epoch 535: loss on validation set: 0.6770\n",
            "Epoch 536: loss on final training batch: 0.6684\n",
            "Epoch 536: accuracy on validation set: 0.5440\n",
            "Epoch 536: accuracy on training set: 0.5482\n",
            "Epoch 536: loss on validation set: 0.6770\n",
            "Epoch 537: loss on final training batch: 0.6684\n",
            "Epoch 537: accuracy on validation set: 0.5442\n",
            "Epoch 537: accuracy on training set: 0.5483\n",
            "Epoch 537: loss on validation set: 0.6770\n",
            "Epoch 538: loss on final training batch: 0.6684\n",
            "Epoch 538: accuracy on validation set: 0.5442\n",
            "Epoch 538: accuracy on training set: 0.5483\n",
            "Epoch 538: loss on validation set: 0.6770\n",
            "Epoch 539: loss on final training batch: 0.6684\n",
            "Epoch 539: accuracy on validation set: 0.5442\n",
            "Epoch 539: accuracy on training set: 0.5483\n",
            "Epoch 539: loss on validation set: 0.6770\n",
            "Epoch 540: loss on final training batch: 0.6684\n",
            "Epoch 540: accuracy on validation set: 0.5442\n",
            "Epoch 540: accuracy on training set: 0.5484\n",
            "Epoch 540: loss on validation set: 0.6770\n",
            "Epoch 541: loss on final training batch: 0.6683\n",
            "Epoch 541: accuracy on validation set: 0.5437\n",
            "Epoch 541: accuracy on training set: 0.5484\n",
            "Epoch 541: loss on validation set: 0.6770\n",
            "Epoch 542: loss on final training batch: 0.6683\n",
            "Epoch 542: accuracy on validation set: 0.5437\n",
            "Epoch 542: accuracy on training set: 0.5484\n",
            "Epoch 542: loss on validation set: 0.6770\n",
            "Epoch 543: loss on final training batch: 0.6683\n",
            "Epoch 543: accuracy on validation set: 0.5437\n",
            "Epoch 543: accuracy on training set: 0.5483\n",
            "Epoch 543: loss on validation set: 0.6770\n",
            "Epoch 544: loss on final training batch: 0.6683\n",
            "Epoch 544: accuracy on validation set: 0.5435\n",
            "Epoch 544: accuracy on training set: 0.5483\n",
            "Epoch 544: loss on validation set: 0.6770\n",
            "Epoch 545: loss on final training batch: 0.6683\n",
            "Epoch 545: accuracy on validation set: 0.5437\n",
            "Epoch 545: accuracy on training set: 0.5484\n",
            "Epoch 545: loss on validation set: 0.6770\n",
            "Epoch 546: loss on final training batch: 0.6683\n",
            "Epoch 546: accuracy on validation set: 0.5435\n",
            "Epoch 546: accuracy on training set: 0.5485\n",
            "Epoch 546: loss on validation set: 0.6770\n",
            "Epoch 547: loss on final training batch: 0.6683\n",
            "Epoch 547: accuracy on validation set: 0.5435\n",
            "Epoch 547: accuracy on training set: 0.5485\n",
            "Epoch 547: loss on validation set: 0.6770\n",
            "Epoch 548: loss on final training batch: 0.6683\n",
            "Epoch 548: accuracy on validation set: 0.5435\n",
            "Epoch 548: accuracy on training set: 0.5486\n",
            "Epoch 548: loss on validation set: 0.6770\n",
            "Epoch 549: loss on final training batch: 0.6683\n",
            "Epoch 549: accuracy on validation set: 0.5435\n",
            "Epoch 549: accuracy on training set: 0.5486\n",
            "Epoch 549: loss on validation set: 0.6770\n",
            "Epoch 550: loss on final training batch: 0.6682\n",
            "Epoch 550: accuracy on validation set: 0.5433\n",
            "Epoch 550: accuracy on training set: 0.5486\n",
            "Epoch 550: loss on validation set: 0.6770\n",
            "Epoch 551: loss on final training batch: 0.6682\n",
            "Epoch 551: accuracy on validation set: 0.5437\n",
            "Epoch 551: accuracy on training set: 0.5487\n",
            "Epoch 551: loss on validation set: 0.6770\n",
            "Epoch 552: loss on final training batch: 0.6682\n",
            "Epoch 552: accuracy on validation set: 0.5437\n",
            "Epoch 552: accuracy on training set: 0.5487\n",
            "Epoch 552: loss on validation set: 0.6770\n",
            "Epoch 553: loss on final training batch: 0.6682\n",
            "Epoch 553: accuracy on validation set: 0.5440\n",
            "Epoch 553: accuracy on training set: 0.5487\n",
            "Epoch 553: loss on validation set: 0.6770\n",
            "Epoch 554: loss on final training batch: 0.6682\n",
            "Epoch 554: accuracy on validation set: 0.5440\n",
            "Epoch 554: accuracy on training set: 0.5487\n",
            "Epoch 554: loss on validation set: 0.6770\n",
            "Epoch 555: loss on final training batch: 0.6682\n",
            "Epoch 555: accuracy on validation set: 0.5440\n",
            "Epoch 555: accuracy on training set: 0.5486\n",
            "Epoch 555: loss on validation set: 0.6770\n",
            "Epoch 556: loss on final training batch: 0.6682\n",
            "Epoch 556: accuracy on validation set: 0.5442\n",
            "Epoch 556: accuracy on training set: 0.5487\n",
            "Epoch 556: loss on validation set: 0.6770\n",
            "Epoch 557: loss on final training batch: 0.6682\n",
            "Epoch 557: accuracy on validation set: 0.5442\n",
            "Epoch 557: accuracy on training set: 0.5488\n",
            "Epoch 557: loss on validation set: 0.6770\n",
            "Epoch 558: loss on final training batch: 0.6682\n",
            "Epoch 558: accuracy on validation set: 0.5442\n",
            "Epoch 558: accuracy on training set: 0.5488\n",
            "Epoch 558: loss on validation set: 0.6770\n",
            "Epoch 559: loss on final training batch: 0.6681\n",
            "Epoch 559: accuracy on validation set: 0.5442\n",
            "Epoch 559: accuracy on training set: 0.5488\n",
            "Epoch 559: loss on validation set: 0.6770\n",
            "Epoch 560: loss on final training batch: 0.6681\n",
            "Epoch 560: accuracy on validation set: 0.5442\n",
            "Epoch 560: accuracy on training set: 0.5488\n",
            "Epoch 560: loss on validation set: 0.6770\n",
            "Epoch 561: loss on final training batch: 0.6681\n",
            "Epoch 561: accuracy on validation set: 0.5442\n",
            "Epoch 561: accuracy on training set: 0.5488\n",
            "Epoch 561: loss on validation set: 0.6770\n",
            "Epoch 562: loss on final training batch: 0.6681\n",
            "Epoch 562: accuracy on validation set: 0.5442\n",
            "Epoch 562: accuracy on training set: 0.5487\n",
            "Epoch 562: loss on validation set: 0.6770\n",
            "Epoch 563: loss on final training batch: 0.6681\n",
            "Epoch 563: accuracy on validation set: 0.5442\n",
            "Epoch 563: accuracy on training set: 0.5486\n",
            "Epoch 563: loss on validation set: 0.6770\n",
            "Epoch 564: loss on final training batch: 0.6681\n",
            "Epoch 564: accuracy on validation set: 0.5442\n",
            "Epoch 564: accuracy on training set: 0.5486\n",
            "Epoch 564: loss on validation set: 0.6770\n",
            "Epoch 565: loss on final training batch: 0.6681\n",
            "Epoch 565: accuracy on validation set: 0.5442\n",
            "Epoch 565: accuracy on training set: 0.5485\n",
            "Epoch 565: loss on validation set: 0.6770\n",
            "Epoch 566: loss on final training batch: 0.6681\n",
            "Epoch 566: accuracy on validation set: 0.5440\n",
            "Epoch 566: accuracy on training set: 0.5485\n",
            "Epoch 566: loss on validation set: 0.6770\n",
            "Epoch 567: loss on final training batch: 0.6680\n",
            "Epoch 567: accuracy on validation set: 0.5440\n",
            "Epoch 567: accuracy on training set: 0.5485\n",
            "Epoch 567: loss on validation set: 0.6770\n",
            "Epoch 568: loss on final training batch: 0.6680\n",
            "Epoch 568: accuracy on validation set: 0.5442\n",
            "Epoch 568: accuracy on training set: 0.5485\n",
            "Epoch 568: loss on validation set: 0.6770\n",
            "Epoch 569: loss on final training batch: 0.6680\n",
            "Epoch 569: accuracy on validation set: 0.5442\n",
            "Epoch 569: accuracy on training set: 0.5484\n",
            "Epoch 569: loss on validation set: 0.6770\n",
            "Epoch 570: loss on final training batch: 0.6680\n",
            "Epoch 570: accuracy on validation set: 0.5442\n",
            "Epoch 570: accuracy on training set: 0.5484\n",
            "Epoch 570: loss on validation set: 0.6770\n",
            "Epoch 571: loss on final training batch: 0.6680\n",
            "Epoch 571: accuracy on validation set: 0.5442\n",
            "Epoch 571: accuracy on training set: 0.5484\n",
            "Epoch 571: loss on validation set: 0.6770\n",
            "Epoch 572: loss on final training batch: 0.6680\n",
            "Epoch 572: accuracy on validation set: 0.5444\n",
            "Epoch 572: accuracy on training set: 0.5484\n",
            "Epoch 572: loss on validation set: 0.6770\n",
            "Epoch 573: loss on final training batch: 0.6680\n",
            "Epoch 573: accuracy on validation set: 0.5448\n",
            "Epoch 573: accuracy on training set: 0.5485\n",
            "Epoch 573: loss on validation set: 0.6770\n",
            "Epoch 574: loss on final training batch: 0.6680\n",
            "Epoch 574: accuracy on validation set: 0.5448\n",
            "Epoch 574: accuracy on training set: 0.5485\n",
            "Epoch 574: loss on validation set: 0.6770\n",
            "Epoch 575: loss on final training batch: 0.6680\n",
            "Epoch 575: accuracy on validation set: 0.5448\n",
            "Epoch 575: accuracy on training set: 0.5485\n",
            "Epoch 575: loss on validation set: 0.6770\n",
            "Epoch 576: loss on final training batch: 0.6679\n",
            "Epoch 576: accuracy on validation set: 0.5452\n",
            "Epoch 576: accuracy on training set: 0.5485\n",
            "Epoch 576: loss on validation set: 0.6770\n",
            "Epoch 577: loss on final training batch: 0.6679\n",
            "Epoch 577: accuracy on validation set: 0.5452\n",
            "Epoch 577: accuracy on training set: 0.5485\n",
            "Epoch 577: loss on validation set: 0.6770\n",
            "Epoch 578: loss on final training batch: 0.6679\n",
            "Epoch 578: accuracy on validation set: 0.5452\n",
            "Epoch 578: accuracy on training set: 0.5486\n",
            "Epoch 578: loss on validation set: 0.6770\n",
            "Epoch 579: loss on final training batch: 0.6679\n",
            "Epoch 579: accuracy on validation set: 0.5452\n",
            "Epoch 579: accuracy on training set: 0.5487\n",
            "Epoch 579: loss on validation set: 0.6770\n",
            "Epoch 580: loss on final training batch: 0.6679\n",
            "Epoch 580: accuracy on validation set: 0.5454\n",
            "Epoch 580: accuracy on training set: 0.5487\n",
            "Epoch 580: loss on validation set: 0.6770\n",
            "Epoch 581: loss on final training batch: 0.6679\n",
            "Epoch 581: accuracy on validation set: 0.5454\n",
            "Epoch 581: accuracy on training set: 0.5487\n",
            "Epoch 581: loss on validation set: 0.6770\n",
            "Epoch 582: loss on final training batch: 0.6679\n",
            "Epoch 582: accuracy on validation set: 0.5454\n",
            "Epoch 582: accuracy on training set: 0.5488\n",
            "Epoch 582: loss on validation set: 0.6770\n",
            "Epoch 583: loss on final training batch: 0.6679\n",
            "Epoch 583: accuracy on validation set: 0.5456\n",
            "Epoch 583: accuracy on training set: 0.5489\n",
            "Epoch 583: loss on validation set: 0.6770\n",
            "Epoch 584: loss on final training batch: 0.6678\n",
            "Epoch 584: accuracy on validation set: 0.5458\n",
            "Epoch 584: accuracy on training set: 0.5488\n",
            "Epoch 584: loss on validation set: 0.6770\n",
            "Epoch 585: loss on final training batch: 0.6678\n",
            "Epoch 585: accuracy on validation set: 0.5458\n",
            "Epoch 585: accuracy on training set: 0.5489\n",
            "Epoch 585: loss on validation set: 0.6770\n",
            "Epoch 586: loss on final training batch: 0.6678\n",
            "Epoch 586: accuracy on validation set: 0.5460\n",
            "Epoch 586: accuracy on training set: 0.5488\n",
            "Epoch 586: loss on validation set: 0.6770\n",
            "Epoch 587: loss on final training batch: 0.6678\n",
            "Epoch 587: accuracy on validation set: 0.5460\n",
            "Epoch 587: accuracy on training set: 0.5487\n",
            "Epoch 587: loss on validation set: 0.6770\n",
            "Epoch 588: loss on final training batch: 0.6678\n",
            "Epoch 588: accuracy on validation set: 0.5460\n",
            "Epoch 588: accuracy on training set: 0.5486\n",
            "Epoch 588: loss on validation set: 0.6770\n",
            "Epoch 589: loss on final training batch: 0.6678\n",
            "Epoch 589: accuracy on validation set: 0.5460\n",
            "Epoch 589: accuracy on training set: 0.5487\n",
            "Epoch 589: loss on validation set: 0.6770\n",
            "Epoch 590: loss on final training batch: 0.6678\n",
            "Epoch 590: accuracy on validation set: 0.5460\n",
            "Epoch 590: accuracy on training set: 0.5487\n",
            "Epoch 590: loss on validation set: 0.6770\n",
            "Epoch 591: loss on final training batch: 0.6678\n",
            "Epoch 591: accuracy on validation set: 0.5460\n",
            "Epoch 591: accuracy on training set: 0.5486\n",
            "Epoch 591: loss on validation set: 0.6770\n",
            "Epoch 592: loss on final training batch: 0.6677\n",
            "Epoch 592: accuracy on validation set: 0.5460\n",
            "Epoch 592: accuracy on training set: 0.5487\n",
            "Epoch 592: loss on validation set: 0.6770\n",
            "Epoch 593: loss on final training batch: 0.6677\n",
            "Epoch 593: accuracy on validation set: 0.5458\n",
            "Epoch 593: accuracy on training set: 0.5486\n",
            "Epoch 593: loss on validation set: 0.6770\n",
            "Epoch 594: loss on final training batch: 0.6677\n",
            "Epoch 594: accuracy on validation set: 0.5458\n",
            "Epoch 594: accuracy on training set: 0.5488\n",
            "Epoch 594: loss on validation set: 0.6770\n",
            "Epoch 595: loss on final training batch: 0.6677\n",
            "Epoch 595: accuracy on validation set: 0.5456\n",
            "Epoch 595: accuracy on training set: 0.5488\n",
            "Epoch 595: loss on validation set: 0.6770\n",
            "Epoch 596: loss on final training batch: 0.6677\n",
            "Epoch 596: accuracy on validation set: 0.5454\n",
            "Epoch 596: accuracy on training set: 0.5487\n",
            "Epoch 596: loss on validation set: 0.6770\n",
            "Epoch 597: loss on final training batch: 0.6677\n",
            "Epoch 597: accuracy on validation set: 0.5454\n",
            "Epoch 597: accuracy on training set: 0.5488\n",
            "Epoch 597: loss on validation set: 0.6770\n",
            "Epoch 598: loss on final training batch: 0.6677\n",
            "Epoch 598: accuracy on validation set: 0.5452\n",
            "Epoch 598: accuracy on training set: 0.5488\n",
            "Epoch 598: loss on validation set: 0.6770\n",
            "Epoch 599: loss on final training batch: 0.6677\n",
            "Epoch 599: accuracy on validation set: 0.5454\n",
            "Epoch 599: accuracy on training set: 0.5488\n",
            "Epoch 599: loss on validation set: 0.6770\n",
            "Epoch 600: loss on final training batch: 0.6677\n",
            "Epoch 600: accuracy on validation set: 0.5454\n",
            "Epoch 600: accuracy on training set: 0.5488\n",
            "Epoch 600: loss on validation set: 0.6770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test accuracy on test set \n",
        "dire_X =  torch.index_select(X_test, 1, torch.LongTensor([*range(138,276)]))\n",
        "dire_X = torch.cat((dire_X,torch.index_select(X_test, 1, torch.LongTensor([*range(0,138)]))),1).to(device)\n",
        "dire_pred = (model(dire_X) >= 0).float()\n",
        "rad_pred = (model(X_test.to(device)) >= 0).float()\n",
        "\n",
        "\n",
        "overall_prob = (((rad_pred + (1 - dire_pred))/2) > 0.5).float()\n",
        "acc = torch.mean((overall_prob.to(device) == y_test.to(device)).float())\n",
        "print(\"test accuracy \",acc.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gWpC4thin0v",
        "outputId": "a5a8c031-442b-4e35-f635-dc8c8ff9df78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy  0.5387499928474426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training model 2 on match data from OpenDota API, the following hyperparameters provided the best results. An early stop mechanism was also added, which breaks the loop when the validation loss increases multiple times in a row:\n",
        "\n",
        "\n",
        "\n",
        "*  Learning rate = 1.7e-4\n",
        "*  Optimizer = Adam\n",
        "*  weight decay (L2 regularization) = 2.4e-3\n",
        "*  Batchsize = 1000\n",
        "*  Epochs = 500\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L7E1VT31gHW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skorch import NeuralNetClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#reset training/test sets\n",
        "\n",
        "#sklearn train test split\n",
        "\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_val_trn,y_data, test_size = 0.2, shuffle= True)\n",
        "\n",
        "#split train into train/validation set\n",
        "\n",
        "X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(X_train,y_train, test_size = 0.15, shuffle= True)\n",
        "\n",
        "X_train = torch.tensor(X_train,dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train,dtype=torch.float32)\n",
        "\n",
        "X_val = torch.tensor(X_val,dtype=torch.float32)\n",
        "\n",
        "y_val = torch.tensor(y_val,dtype=torch.float32)\n",
        "\n",
        "X_test = torch.tensor(X_test,dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test,dtype=torch.float32)\n",
        "\n",
        "#lists for matplot graphing\n",
        "new_model2_val_acc = []\n",
        "new_model2_train_acc = []\n",
        "new_model2_val_loss = []\n",
        "new_model2_train_loss = []\n",
        "epochs_2 = []\n",
        "\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(276,128),\n",
        "    torch.nn.Dropout(),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(128,64),\n",
        "    torch.nn.Dropout(),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(64,16),\n",
        "    torch.nn.Dropout(),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(16,1)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "if torch.cuda.is_available(): \n",
        " dev = \"cuda:0\" \n",
        "else: \n",
        " dev = \"cpu\" \n",
        "device = torch.device(dev)\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "#loss function and optimizer\n",
        "loss = torch.nn.BCEWithLogitsLoss()\n",
        "optim = torch.optim.Adam(model.parameters(),lr=1.7e-4, weight_decay=2.4e-3)\n",
        "\n",
        "\n",
        "#epoch number\n",
        "num_epoch = 300\n",
        "next_epoch = 1\n",
        "batch_size = 1000\n",
        "\n",
        "\n",
        "valid_loss = 100000000000\n",
        "loss_flag = False\n",
        "\n",
        "#training loop\n",
        "for epoch in range(next_epoch, next_epoch+num_epoch):\n",
        "\n",
        "    #set model into training mode\n",
        "    model.train()\n",
        "    \n",
        "    \n",
        "    # Make an entire pass (an 'epoch') over the training data in batch_size chunks\n",
        "    for i in range(0, len(X_train), batch_size):        \n",
        "        X = X_train[i:i+batch_size].to(device)     # Slice out a mini-batch of features\n",
        "        y = y_train[i:i+batch_size].to(device)     # Slice out a mini-batch of targets\n",
        "        \n",
        "        \n",
        "        # Make predictions (final-layer activations)\n",
        "        y_pred = model(X)                   \n",
        "        \n",
        "        l = loss(y_pred, y)                 # Compute loss with respect to predictions\n",
        "        \n",
        "        model.zero_grad()                   # Reset all gradient accumulators to zero\n",
        "        l.backward()                        # Compute gradient of loss with backprop\n",
        "        optim.step()                    # Use the gradients to take a step with Adam.\n",
        "        \n",
        "    print(\"Epoch %2d: loss on final training batch: %.4f\" % (epoch, l.item()))\n",
        "    \n",
        "    #set model in eval mode for accuracy/loss calculations\n",
        "    model.eval()\n",
        "\n",
        "    #create dire query\n",
        "    \n",
        "    #validation set calculations\n",
        "    dire_X =  torch.index_select(X_val, 1, torch.LongTensor([*range(138,276)]))\n",
        "    dire_X = torch.cat((dire_X,torch.index_select(X_val, 1, torch.LongTensor([*range(0,138)]))),1).to(device)\n",
        "\n",
        "    dire_pred = (model(dire_X) >= 0).float()\n",
        "    \n",
        "    \n",
        "    rad_pred = (model(X_val.to(device)) >= 0).float()\n",
        "    \n",
        "    #calculation of overall probability\n",
        "    overall_prob = (((rad_pred + (1 - dire_pred))/2) > 0.5).float()\n",
        "    \n",
        "    val_acc = torch.mean((overall_prob.to('cpu') == y_val.to('cpu')).float())\n",
        "\n",
        "    #training set calculations\n",
        "    dire_X_train =  torch.index_select(X_train, 1, torch.LongTensor([*range(138,276)]))\n",
        "    dire_X_train = torch.cat((dire_X_train,torch.index_select(X_train, 1, torch.LongTensor([*range(0,138)]))),1).to(device)\n",
        "\n",
        "    dire_pred = (model(dire_X_train) >= 0).float()\n",
        "    \n",
        "    rad_pred = (model(X_train.to(device)) >= 0).float()\n",
        "    \n",
        "\n",
        "    overall_prob = (((rad_pred + (1 - dire_pred))/2) > 0.5).float()\n",
        "    \n",
        "    train_acc = torch.mean((overall_prob.to('cpu') == y_train.to('cpu')).float())\n",
        "    \n",
        "    print(\"Epoch %2d: accuracy on validation set: %.4f\" % (epoch, val_acc))\n",
        "    print(\"Epoch %2d: accuracy on training set: %.4f\" % (epoch, train_acc))\n",
        "    \n",
        "    print(\"Epoch %2d: loss on validation set: %.4f\" % (epoch, loss(model(X_val.to(device)), y_val.to(device))))\n",
        "    new_val_loss = loss(model(X_val.to(device)), y_val.to(device))\n",
        "\n",
        "    #append info for matplot graphs\n",
        "    new_model2_val_acc.append(val_acc)\n",
        "    new_model2_train_acc.append(train_acc)\n",
        "    new_model2_val_loss.append(new_val_loss.item())\n",
        "    new_model2_train_loss.append(l.item())\n",
        "    epochs_2.append(epoch)\n",
        "\n",
        "    #early stopping if loss increase 5 times in a row\n",
        "    if new_val_loss >= valid_loss:\n",
        "       loss_count += 1\n",
        "       if loss_count > 5:\n",
        "          break\n",
        "    else:\n",
        "      loss_count = 0\n",
        "\n",
        "    valid_loss = new_val_loss\n",
        "    \n",
        "   \n",
        "\n",
        "next_epoch = epoch+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F067OZJCfmhs",
        "outputId": "534220e5-e88a-451e-9561-70f91a093722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1: loss on final training batch: 0.6871\n",
            "Epoch  1: accuracy on validation set: 0.4910\n",
            "Epoch  1: accuracy on training set: 0.4932\n",
            "Epoch  1: loss on validation set: 0.6969\n",
            "Epoch  2: loss on final training batch: 0.6883\n",
            "Epoch  2: accuracy on validation set: 0.4910\n",
            "Epoch  2: accuracy on training set: 0.4932\n",
            "Epoch  2: loss on validation set: 0.6959\n",
            "Epoch  3: loss on final training batch: 0.6919\n",
            "Epoch  3: accuracy on validation set: 0.4910\n",
            "Epoch  3: accuracy on training set: 0.4932\n",
            "Epoch  3: loss on validation set: 0.6951\n",
            "Epoch  4: loss on final training batch: 0.6862\n",
            "Epoch  4: accuracy on validation set: 0.4910\n",
            "Epoch  4: accuracy on training set: 0.4932\n",
            "Epoch  4: loss on validation set: 0.6946\n",
            "Epoch  5: loss on final training batch: 0.6928\n",
            "Epoch  5: accuracy on validation set: 0.4910\n",
            "Epoch  5: accuracy on training set: 0.4932\n",
            "Epoch  5: loss on validation set: 0.6942\n",
            "Epoch  6: loss on final training batch: 0.6860\n",
            "Epoch  6: accuracy on validation set: 0.4910\n",
            "Epoch  6: accuracy on training set: 0.4932\n",
            "Epoch  6: loss on validation set: 0.6938\n",
            "Epoch  7: loss on final training batch: 0.6868\n",
            "Epoch  7: accuracy on validation set: 0.4910\n",
            "Epoch  7: accuracy on training set: 0.4932\n",
            "Epoch  7: loss on validation set: 0.6934\n",
            "Epoch  8: loss on final training batch: 0.6929\n",
            "Epoch  8: accuracy on validation set: 0.4910\n",
            "Epoch  8: accuracy on training set: 0.4932\n",
            "Epoch  8: loss on validation set: 0.6932\n",
            "Epoch  9: loss on final training batch: 0.6947\n",
            "Epoch  9: accuracy on validation set: 0.4910\n",
            "Epoch  9: accuracy on training set: 0.4932\n",
            "Epoch  9: loss on validation set: 0.6931\n",
            "Epoch 10: loss on final training batch: 0.6894\n",
            "Epoch 10: accuracy on validation set: 0.4919\n",
            "Epoch 10: accuracy on training set: 0.4940\n",
            "Epoch 10: loss on validation set: 0.6929\n",
            "Epoch 11: loss on final training batch: 0.6897\n",
            "Epoch 11: accuracy on validation set: 0.4956\n",
            "Epoch 11: accuracy on training set: 0.4968\n",
            "Epoch 11: loss on validation set: 0.6928\n",
            "Epoch 12: loss on final training batch: 0.6902\n",
            "Epoch 12: accuracy on validation set: 0.5069\n",
            "Epoch 12: accuracy on training set: 0.5062\n",
            "Epoch 12: loss on validation set: 0.6926\n",
            "Epoch 13: loss on final training batch: 0.6939\n",
            "Epoch 13: accuracy on validation set: 0.5177\n",
            "Epoch 13: accuracy on training set: 0.5213\n",
            "Epoch 13: loss on validation set: 0.6925\n",
            "Epoch 14: loss on final training batch: 0.6914\n",
            "Epoch 14: accuracy on validation set: 0.5310\n",
            "Epoch 14: accuracy on training set: 0.5356\n",
            "Epoch 14: loss on validation set: 0.6924\n",
            "Epoch 15: loss on final training batch: 0.6938\n",
            "Epoch 15: accuracy on validation set: 0.5346\n",
            "Epoch 15: accuracy on training set: 0.5465\n",
            "Epoch 15: loss on validation set: 0.6922\n",
            "Epoch 16: loss on final training batch: 0.6925\n",
            "Epoch 16: accuracy on validation set: 0.5362\n",
            "Epoch 16: accuracy on training set: 0.5504\n",
            "Epoch 16: loss on validation set: 0.6920\n",
            "Epoch 17: loss on final training batch: 0.6928\n",
            "Epoch 17: accuracy on validation set: 0.5352\n",
            "Epoch 17: accuracy on training set: 0.5468\n",
            "Epoch 17: loss on validation set: 0.6917\n",
            "Epoch 18: loss on final training batch: 0.6948\n",
            "Epoch 18: accuracy on validation set: 0.5267\n",
            "Epoch 18: accuracy on training set: 0.5370\n",
            "Epoch 18: loss on validation set: 0.6914\n",
            "Epoch 19: loss on final training batch: 0.6891\n",
            "Epoch 19: accuracy on validation set: 0.5275\n",
            "Epoch 19: accuracy on training set: 0.5381\n",
            "Epoch 19: loss on validation set: 0.6911\n",
            "Epoch 20: loss on final training batch: 0.6881\n",
            "Epoch 20: accuracy on validation set: 0.5283\n",
            "Epoch 20: accuracy on training set: 0.5324\n",
            "Epoch 20: loss on validation set: 0.6906\n",
            "Epoch 21: loss on final training batch: 0.6871\n",
            "Epoch 21: accuracy on validation set: 0.5252\n",
            "Epoch 21: accuracy on training set: 0.5326\n",
            "Epoch 21: loss on validation set: 0.6900\n",
            "Epoch 22: loss on final training batch: 0.6863\n",
            "Epoch 22: accuracy on validation set: 0.5242\n",
            "Epoch 22: accuracy on training set: 0.5314\n",
            "Epoch 22: loss on validation set: 0.6893\n",
            "Epoch 23: loss on final training batch: 0.6885\n",
            "Epoch 23: accuracy on validation set: 0.5198\n",
            "Epoch 23: accuracy on training set: 0.5273\n",
            "Epoch 23: loss on validation set: 0.6885\n",
            "Epoch 24: loss on final training batch: 0.6847\n",
            "Epoch 24: accuracy on validation set: 0.5233\n",
            "Epoch 24: accuracy on training set: 0.5294\n",
            "Epoch 24: loss on validation set: 0.6877\n",
            "Epoch 25: loss on final training batch: 0.6895\n",
            "Epoch 25: accuracy on validation set: 0.5210\n",
            "Epoch 25: accuracy on training set: 0.5282\n",
            "Epoch 25: loss on validation set: 0.6867\n",
            "Epoch 26: loss on final training batch: 0.6745\n",
            "Epoch 26: accuracy on validation set: 0.5246\n",
            "Epoch 26: accuracy on training set: 0.5333\n",
            "Epoch 26: loss on validation set: 0.6859\n",
            "Epoch 27: loss on final training batch: 0.6788\n",
            "Epoch 27: accuracy on validation set: 0.5254\n",
            "Epoch 27: accuracy on training set: 0.5335\n",
            "Epoch 27: loss on validation set: 0.6850\n",
            "Epoch 28: loss on final training batch: 0.6815\n",
            "Epoch 28: accuracy on validation set: 0.5246\n",
            "Epoch 28: accuracy on training set: 0.5343\n",
            "Epoch 28: loss on validation set: 0.6842\n",
            "Epoch 29: loss on final training batch: 0.6796\n",
            "Epoch 29: accuracy on validation set: 0.5288\n",
            "Epoch 29: accuracy on training set: 0.5397\n",
            "Epoch 29: loss on validation set: 0.6836\n",
            "Epoch 30: loss on final training batch: 0.6764\n",
            "Epoch 30: accuracy on validation set: 0.5281\n",
            "Epoch 30: accuracy on training set: 0.5374\n",
            "Epoch 30: loss on validation set: 0.6830\n",
            "Epoch 31: loss on final training batch: 0.6671\n",
            "Epoch 31: accuracy on validation set: 0.5298\n",
            "Epoch 31: accuracy on training set: 0.5396\n",
            "Epoch 31: loss on validation set: 0.6828\n",
            "Epoch 32: loss on final training batch: 0.6662\n",
            "Epoch 32: accuracy on validation set: 0.5285\n",
            "Epoch 32: accuracy on training set: 0.5403\n",
            "Epoch 32: loss on validation set: 0.6824\n",
            "Epoch 33: loss on final training batch: 0.6658\n",
            "Epoch 33: accuracy on validation set: 0.5294\n",
            "Epoch 33: accuracy on training set: 0.5404\n",
            "Epoch 33: loss on validation set: 0.6822\n",
            "Epoch 34: loss on final training batch: 0.6640\n",
            "Epoch 34: accuracy on validation set: 0.5250\n",
            "Epoch 34: accuracy on training set: 0.5397\n",
            "Epoch 34: loss on validation set: 0.6818\n",
            "Epoch 35: loss on final training batch: 0.6626\n",
            "Epoch 35: accuracy on validation set: 0.5273\n",
            "Epoch 35: accuracy on training set: 0.5418\n",
            "Epoch 35: loss on validation set: 0.6816\n",
            "Epoch 36: loss on final training batch: 0.6568\n",
            "Epoch 36: accuracy on validation set: 0.5263\n",
            "Epoch 36: accuracy on training set: 0.5400\n",
            "Epoch 36: loss on validation set: 0.6815\n",
            "Epoch 37: loss on final training batch: 0.6615\n",
            "Epoch 37: accuracy on validation set: 0.5300\n",
            "Epoch 37: accuracy on training set: 0.5425\n",
            "Epoch 37: loss on validation set: 0.6815\n",
            "Epoch 38: loss on final training batch: 0.6611\n",
            "Epoch 38: accuracy on validation set: 0.5269\n",
            "Epoch 38: accuracy on training set: 0.5404\n",
            "Epoch 38: loss on validation set: 0.6812\n",
            "Epoch 39: loss on final training batch: 0.6576\n",
            "Epoch 39: accuracy on validation set: 0.5275\n",
            "Epoch 39: accuracy on training set: 0.5411\n",
            "Epoch 39: loss on validation set: 0.6811\n",
            "Epoch 40: loss on final training batch: 0.6610\n",
            "Epoch 40: accuracy on validation set: 0.5246\n",
            "Epoch 40: accuracy on training set: 0.5440\n",
            "Epoch 40: loss on validation set: 0.6812\n",
            "Epoch 41: loss on final training batch: 0.6622\n",
            "Epoch 41: accuracy on validation set: 0.5285\n",
            "Epoch 41: accuracy on training set: 0.5439\n",
            "Epoch 41: loss on validation set: 0.6810\n",
            "Epoch 42: loss on final training batch: 0.6642\n",
            "Epoch 42: accuracy on validation set: 0.5275\n",
            "Epoch 42: accuracy on training set: 0.5424\n",
            "Epoch 42: loss on validation set: 0.6809\n",
            "Epoch 43: loss on final training batch: 0.6567\n",
            "Epoch 43: accuracy on validation set: 0.5258\n",
            "Epoch 43: accuracy on training set: 0.5415\n",
            "Epoch 43: loss on validation set: 0.6808\n",
            "Epoch 44: loss on final training batch: 0.6618\n",
            "Epoch 44: accuracy on validation set: 0.5279\n",
            "Epoch 44: accuracy on training set: 0.5433\n",
            "Epoch 44: loss on validation set: 0.6808\n",
            "Epoch 45: loss on final training batch: 0.6624\n",
            "Epoch 45: accuracy on validation set: 0.5275\n",
            "Epoch 45: accuracy on training set: 0.5432\n",
            "Epoch 45: loss on validation set: 0.6807\n",
            "Epoch 46: loss on final training batch: 0.6542\n",
            "Epoch 46: accuracy on validation set: 0.5288\n",
            "Epoch 46: accuracy on training set: 0.5434\n",
            "Epoch 46: loss on validation set: 0.6807\n",
            "Epoch 47: loss on final training batch: 0.6592\n",
            "Epoch 47: accuracy on validation set: 0.5312\n",
            "Epoch 47: accuracy on training set: 0.5432\n",
            "Epoch 47: loss on validation set: 0.6806\n",
            "Epoch 48: loss on final training batch: 0.6627\n",
            "Epoch 48: accuracy on validation set: 0.5288\n",
            "Epoch 48: accuracy on training set: 0.5419\n",
            "Epoch 48: loss on validation set: 0.6806\n",
            "Epoch 49: loss on final training batch: 0.6584\n",
            "Epoch 49: accuracy on validation set: 0.5312\n",
            "Epoch 49: accuracy on training set: 0.5452\n",
            "Epoch 49: loss on validation set: 0.6807\n",
            "Epoch 50: loss on final training batch: 0.6515\n",
            "Epoch 50: accuracy on validation set: 0.5323\n",
            "Epoch 50: accuracy on training set: 0.5449\n",
            "Epoch 50: loss on validation set: 0.6806\n",
            "Epoch 51: loss on final training batch: 0.6650\n",
            "Epoch 51: accuracy on validation set: 0.5296\n",
            "Epoch 51: accuracy on training set: 0.5419\n",
            "Epoch 51: loss on validation set: 0.6806\n",
            "Epoch 52: loss on final training batch: 0.6542\n",
            "Epoch 52: accuracy on validation set: 0.5312\n",
            "Epoch 52: accuracy on training set: 0.5439\n",
            "Epoch 52: loss on validation set: 0.6807\n",
            "Epoch 53: loss on final training batch: 0.6519\n",
            "Epoch 53: accuracy on validation set: 0.5300\n",
            "Epoch 53: accuracy on training set: 0.5426\n",
            "Epoch 53: loss on validation set: 0.6805\n",
            "Epoch 54: loss on final training batch: 0.6577\n",
            "Epoch 54: accuracy on validation set: 0.5298\n",
            "Epoch 54: accuracy on training set: 0.5444\n",
            "Epoch 54: loss on validation set: 0.6805\n",
            "Epoch 55: loss on final training batch: 0.6500\n",
            "Epoch 55: accuracy on validation set: 0.5298\n",
            "Epoch 55: accuracy on training set: 0.5433\n",
            "Epoch 55: loss on validation set: 0.6804\n",
            "Epoch 56: loss on final training batch: 0.6521\n",
            "Epoch 56: accuracy on validation set: 0.5302\n",
            "Epoch 56: accuracy on training set: 0.5451\n",
            "Epoch 56: loss on validation set: 0.6804\n",
            "Epoch 57: loss on final training batch: 0.6493\n",
            "Epoch 57: accuracy on validation set: 0.5285\n",
            "Epoch 57: accuracy on training set: 0.5450\n",
            "Epoch 57: loss on validation set: 0.6805\n",
            "Epoch 58: loss on final training batch: 0.6514\n",
            "Epoch 58: accuracy on validation set: 0.5294\n",
            "Epoch 58: accuracy on training set: 0.5440\n",
            "Epoch 58: loss on validation set: 0.6804\n",
            "Epoch 59: loss on final training batch: 0.6520\n",
            "Epoch 59: accuracy on validation set: 0.5288\n",
            "Epoch 59: accuracy on training set: 0.5457\n",
            "Epoch 59: loss on validation set: 0.6805\n",
            "Epoch 60: loss on final training batch: 0.6439\n",
            "Epoch 60: accuracy on validation set: 0.5294\n",
            "Epoch 60: accuracy on training set: 0.5442\n",
            "Epoch 60: loss on validation set: 0.6804\n",
            "Epoch 61: loss on final training batch: 0.6525\n",
            "Epoch 61: accuracy on validation set: 0.5283\n",
            "Epoch 61: accuracy on training set: 0.5453\n",
            "Epoch 61: loss on validation set: 0.6804\n",
            "Epoch 62: loss on final training batch: 0.6592\n",
            "Epoch 62: accuracy on validation set: 0.5283\n",
            "Epoch 62: accuracy on training set: 0.5453\n",
            "Epoch 62: loss on validation set: 0.6803\n",
            "Epoch 63: loss on final training batch: 0.6522\n",
            "Epoch 63: accuracy on validation set: 0.5285\n",
            "Epoch 63: accuracy on training set: 0.5437\n",
            "Epoch 63: loss on validation set: 0.6803\n",
            "Epoch 64: loss on final training batch: 0.6554\n",
            "Epoch 64: accuracy on validation set: 0.5271\n",
            "Epoch 64: accuracy on training set: 0.5442\n",
            "Epoch 64: loss on validation set: 0.6803\n",
            "Epoch 65: loss on final training batch: 0.6544\n",
            "Epoch 65: accuracy on validation set: 0.5269\n",
            "Epoch 65: accuracy on training set: 0.5448\n",
            "Epoch 65: loss on validation set: 0.6803\n",
            "Epoch 66: loss on final training batch: 0.6450\n",
            "Epoch 66: accuracy on validation set: 0.5273\n",
            "Epoch 66: accuracy on training set: 0.5451\n",
            "Epoch 66: loss on validation set: 0.6803\n",
            "Epoch 67: loss on final training batch: 0.6508\n",
            "Epoch 67: accuracy on validation set: 0.5285\n",
            "Epoch 67: accuracy on training set: 0.5472\n",
            "Epoch 67: loss on validation set: 0.6803\n",
            "Epoch 68: loss on final training batch: 0.6427\n",
            "Epoch 68: accuracy on validation set: 0.5290\n",
            "Epoch 68: accuracy on training set: 0.5444\n",
            "Epoch 68: loss on validation set: 0.6802\n",
            "Epoch 69: loss on final training batch: 0.6381\n",
            "Epoch 69: accuracy on validation set: 0.5279\n",
            "Epoch 69: accuracy on training set: 0.5444\n",
            "Epoch 69: loss on validation set: 0.6802\n",
            "Epoch 70: loss on final training batch: 0.6418\n",
            "Epoch 70: accuracy on validation set: 0.5275\n",
            "Epoch 70: accuracy on training set: 0.5450\n",
            "Epoch 70: loss on validation set: 0.6801\n",
            "Epoch 71: loss on final training batch: 0.6478\n",
            "Epoch 71: accuracy on validation set: 0.5288\n",
            "Epoch 71: accuracy on training set: 0.5457\n",
            "Epoch 71: loss on validation set: 0.6802\n",
            "Epoch 72: loss on final training batch: 0.6430\n",
            "Epoch 72: accuracy on validation set: 0.5292\n",
            "Epoch 72: accuracy on training set: 0.5460\n",
            "Epoch 72: loss on validation set: 0.6802\n",
            "Epoch 73: loss on final training batch: 0.6426\n",
            "Epoch 73: accuracy on validation set: 0.5292\n",
            "Epoch 73: accuracy on training set: 0.5465\n",
            "Epoch 73: loss on validation set: 0.6802\n",
            "Epoch 74: loss on final training batch: 0.6473\n",
            "Epoch 74: accuracy on validation set: 0.5298\n",
            "Epoch 74: accuracy on training set: 0.5464\n",
            "Epoch 74: loss on validation set: 0.6802\n",
            "Epoch 75: loss on final training batch: 0.6406\n",
            "Epoch 75: accuracy on validation set: 0.5281\n",
            "Epoch 75: accuracy on training set: 0.5473\n",
            "Epoch 75: loss on validation set: 0.6801\n",
            "Epoch 76: loss on final training batch: 0.6309\n",
            "Epoch 76: accuracy on validation set: 0.5267\n",
            "Epoch 76: accuracy on training set: 0.5471\n",
            "Epoch 76: loss on validation set: 0.6800\n",
            "Epoch 77: loss on final training batch: 0.6483\n",
            "Epoch 77: accuracy on validation set: 0.5273\n",
            "Epoch 77: accuracy on training set: 0.5456\n",
            "Epoch 77: loss on validation set: 0.6800\n",
            "Epoch 78: loss on final training batch: 0.6419\n",
            "Epoch 78: accuracy on validation set: 0.5258\n",
            "Epoch 78: accuracy on training set: 0.5463\n",
            "Epoch 78: loss on validation set: 0.6801\n",
            "Epoch 79: loss on final training batch: 0.6441\n",
            "Epoch 79: accuracy on validation set: 0.5258\n",
            "Epoch 79: accuracy on training set: 0.5461\n",
            "Epoch 79: loss on validation set: 0.6801\n",
            "Epoch 80: loss on final training batch: 0.6339\n",
            "Epoch 80: accuracy on validation set: 0.5263\n",
            "Epoch 80: accuracy on training set: 0.5473\n",
            "Epoch 80: loss on validation set: 0.6800\n",
            "Epoch 81: loss on final training batch: 0.6359\n",
            "Epoch 81: accuracy on validation set: 0.5267\n",
            "Epoch 81: accuracy on training set: 0.5475\n",
            "Epoch 81: loss on validation set: 0.6801\n",
            "Epoch 82: loss on final training batch: 0.6379\n",
            "Epoch 82: accuracy on validation set: 0.5288\n",
            "Epoch 82: accuracy on training set: 0.5489\n",
            "Epoch 82: loss on validation set: 0.6801\n",
            "Epoch 83: loss on final training batch: 0.6372\n",
            "Epoch 83: accuracy on validation set: 0.5281\n",
            "Epoch 83: accuracy on training set: 0.5477\n",
            "Epoch 83: loss on validation set: 0.6800\n",
            "Epoch 84: loss on final training batch: 0.6404\n",
            "Epoch 84: accuracy on validation set: 0.5298\n",
            "Epoch 84: accuracy on training set: 0.5485\n",
            "Epoch 84: loss on validation set: 0.6799\n",
            "Epoch 85: loss on final training batch: 0.6428\n",
            "Epoch 85: accuracy on validation set: 0.5273\n",
            "Epoch 85: accuracy on training set: 0.5486\n",
            "Epoch 85: loss on validation set: 0.6799\n",
            "Epoch 86: loss on final training batch: 0.6424\n",
            "Epoch 86: accuracy on validation set: 0.5294\n",
            "Epoch 86: accuracy on training set: 0.5482\n",
            "Epoch 86: loss on validation set: 0.6798\n",
            "Epoch 87: loss on final training batch: 0.6257\n",
            "Epoch 87: accuracy on validation set: 0.5296\n",
            "Epoch 87: accuracy on training set: 0.5485\n",
            "Epoch 87: loss on validation set: 0.6798\n",
            "Epoch 88: loss on final training batch: 0.6347\n",
            "Epoch 88: accuracy on validation set: 0.5302\n",
            "Epoch 88: accuracy on training set: 0.5484\n",
            "Epoch 88: loss on validation set: 0.6798\n",
            "Epoch 89: loss on final training batch: 0.6364\n",
            "Epoch 89: accuracy on validation set: 0.5296\n",
            "Epoch 89: accuracy on training set: 0.5491\n",
            "Epoch 89: loss on validation set: 0.6796\n",
            "Epoch 90: loss on final training batch: 0.6379\n",
            "Epoch 90: accuracy on validation set: 0.5302\n",
            "Epoch 90: accuracy on training set: 0.5493\n",
            "Epoch 90: loss on validation set: 0.6796\n",
            "Epoch 91: loss on final training batch: 0.6252\n",
            "Epoch 91: accuracy on validation set: 0.5292\n",
            "Epoch 91: accuracy on training set: 0.5501\n",
            "Epoch 91: loss on validation set: 0.6798\n",
            "Epoch 92: loss on final training batch: 0.6312\n",
            "Epoch 92: accuracy on validation set: 0.5271\n",
            "Epoch 92: accuracy on training set: 0.5515\n",
            "Epoch 92: loss on validation set: 0.6797\n",
            "Epoch 93: loss on final training batch: 0.6314\n",
            "Epoch 93: accuracy on validation set: 0.5302\n",
            "Epoch 93: accuracy on training set: 0.5530\n",
            "Epoch 93: loss on validation set: 0.6797\n",
            "Epoch 94: loss on final training batch: 0.6288\n",
            "Epoch 94: accuracy on validation set: 0.5283\n",
            "Epoch 94: accuracy on training set: 0.5533\n",
            "Epoch 94: loss on validation set: 0.6798\n",
            "Epoch 95: loss on final training batch: 0.6395\n",
            "Epoch 95: accuracy on validation set: 0.5288\n",
            "Epoch 95: accuracy on training set: 0.5529\n",
            "Epoch 95: loss on validation set: 0.6797\n",
            "Epoch 96: loss on final training batch: 0.6150\n",
            "Epoch 96: accuracy on validation set: 0.5296\n",
            "Epoch 96: accuracy on training set: 0.5535\n",
            "Epoch 96: loss on validation set: 0.6797\n",
            "Epoch 97: loss on final training batch: 0.6131\n",
            "Epoch 97: accuracy on validation set: 0.5290\n",
            "Epoch 97: accuracy on training set: 0.5532\n",
            "Epoch 97: loss on validation set: 0.6798\n",
            "Epoch 98: loss on final training batch: 0.6250\n",
            "Epoch 98: accuracy on validation set: 0.5281\n",
            "Epoch 98: accuracy on training set: 0.5539\n",
            "Epoch 98: loss on validation set: 0.6797\n",
            "Epoch 99: loss on final training batch: 0.6222\n",
            "Epoch 99: accuracy on validation set: 0.5275\n",
            "Epoch 99: accuracy on training set: 0.5546\n",
            "Epoch 99: loss on validation set: 0.6797\n",
            "Epoch 100: loss on final training batch: 0.6269\n",
            "Epoch 100: accuracy on validation set: 0.5260\n",
            "Epoch 100: accuracy on training set: 0.5552\n",
            "Epoch 100: loss on validation set: 0.6797\n",
            "Epoch 101: loss on final training batch: 0.6116\n",
            "Epoch 101: accuracy on validation set: 0.5238\n",
            "Epoch 101: accuracy on training set: 0.5556\n",
            "Epoch 101: loss on validation set: 0.6798\n",
            "Epoch 102: loss on final training batch: 0.6179\n",
            "Epoch 102: accuracy on validation set: 0.5260\n",
            "Epoch 102: accuracy on training set: 0.5573\n",
            "Epoch 102: loss on validation set: 0.6798\n",
            "Epoch 103: loss on final training batch: 0.6186\n",
            "Epoch 103: accuracy on validation set: 0.5273\n",
            "Epoch 103: accuracy on training set: 0.5576\n",
            "Epoch 103: loss on validation set: 0.6799\n",
            "Epoch 104: loss on final training batch: 0.6282\n",
            "Epoch 104: accuracy on validation set: 0.5252\n",
            "Epoch 104: accuracy on training set: 0.5579\n",
            "Epoch 104: loss on validation set: 0.6800\n",
            "Epoch 105: loss on final training batch: 0.6210\n",
            "Epoch 105: accuracy on validation set: 0.5256\n",
            "Epoch 105: accuracy on training set: 0.5589\n",
            "Epoch 105: loss on validation set: 0.6802\n",
            "Epoch 106: loss on final training batch: 0.6169\n",
            "Epoch 106: accuracy on validation set: 0.5273\n",
            "Epoch 106: accuracy on training set: 0.5586\n",
            "Epoch 106: loss on validation set: 0.6802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test accuracy on test set \n",
        "dire_X =  torch.index_select(X_test, 1, torch.LongTensor([*range(138,276)]))\n",
        "dire_X = torch.cat((dire_X,torch.index_select(X_test, 1, torch.LongTensor([*range(0,138)]))),1).to(device)\n",
        "dire_pred = (model(dire_X) >= 0).float()\n",
        "rad_pred = (model(X_test.to(device)) >= 0).float()\n",
        "\n",
        "\n",
        "overall_prob = (((rad_pred + (1 - dire_pred))/2) > 0.5).float()\n",
        "acc = torch.mean((overall_prob.to(device) == y_test.to(device)).float())\n",
        "print(\"test accuracy \",acc.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmpheTgYiYft",
        "outputId": "d52f419d-b72d-42d8-dd6d-be97903816e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy  0.5398749709129333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating feature vector for old match data"
      ],
      "metadata": {
        "id": "wC1xCaoLPVm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#adding match data from old match\n",
        "\n",
        "data = np.loadtxt('DotabuddiesData/oldmatchdata.csv',skiprows=1,delimiter=',')\n",
        "X_data = np.array(data[:,1:]).astype(np.int32)\n",
        "y_data = np.array(data[:,:1]).astype(np.int32)\n",
        "\n",
        "#turn all data into feature vector\n",
        "#feature vector creation\n",
        "X_val_old = torch.zeros((50000,113*2),dtype=torch.float32)\n",
        "j = 0\n",
        "for d in X_data:\n",
        "    for i in range(len(d)):\n",
        "        if(i < len(d)/2):\n",
        "            h = d[i]\n",
        "            X_val_old[j][h] += 1\n",
        "            \n",
        "            \n",
        "        else:\n",
        "            h = d[i]\n",
        "            X_val_old[j][h+113] += 1\n",
        "      \n",
        "    j += 1"
      ],
      "metadata": {
        "id": "0xOy2_CvN6NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the training and test split, then a further split of the training data for the validation set. "
      ],
      "metadata": {
        "id": "A_EL9nfdPda7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sklearn train test split\n",
        "\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_val_old,y_data, test_size = 0.2, shuffle= True)\n",
        "\n",
        "#split train into train/validation set\n",
        "\n",
        "X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(X_train,y_train, test_size = 0.15, shuffle= True)\n",
        "\n",
        "X_train = torch.tensor(X_train,dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train,dtype=torch.float32)\n",
        "\n",
        "X_val = torch.tensor(X_val,dtype=torch.float32)\n",
        "\n",
        "y_val = torch.tensor(y_val,dtype=torch.float32)\n",
        "\n",
        "X_test = torch.tensor(X_test,dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test,dtype=torch.float32)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8e-n1RnN52L",
        "outputId": "fe0896a8-d65e-44ec-fec8-6a56eda3d03d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-112-7fb08412e55d>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_train = torch.tensor(X_train,dtype=torch.float32)\n",
            "<ipython-input-112-7fb08412e55d>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_val = torch.tensor(X_val,dtype=torch.float32)\n",
            "<ipython-input-112-7fb08412e55d>:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_test = torch.tensor(X_test,dtype=torch.float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the old match data through model 1\n",
        "The following hyperparameters tested provided the best results, An early stop mechanism was also added, which breaks the loop when the validation loss increases multiple times in a row::\n",
        "\n",
        "*   Learning rate = 2.7e-5\n",
        "*   Optimizer = Adam\n",
        "*   Weight decay = 1.5e-3\n",
        "*   Batchsize = 625\n",
        "*   Epochs = 250\n",
        "\n"
      ],
      "metadata": {
        "id": "oit2JBNdamY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skorch import NeuralNetClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#lists for matplot graphing\n",
        "old_model1_val_acc = []\n",
        "old_model1_train_acc = []\n",
        "old_model1_val_loss = []\n",
        "old_model1_train_loss = []\n",
        "epochs_3 = []\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "   torch.nn.Linear(226,16),\n",
        "   torch.nn.ReLU(),\n",
        "   torch.nn.Linear(16,1)\n",
        ")\n",
        "\n",
        "\n",
        "if torch.cuda.is_available(): \n",
        " dev = \"cuda:0\" \n",
        "else: \n",
        " dev = \"cpu\" \n",
        "device = torch.device(dev)\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "#loss function and optimizer\n",
        "loss = torch.nn.BCEWithLogitsLoss()\n",
        "optim = torch.optim.Adam(model.parameters(),lr=2.7e-5, weight_decay=1.5e-3)\n",
        "\n",
        "#epoch number\n",
        "num_epoch = 250\n",
        "next_epoch = 1\n",
        "batch_size = 625\n",
        "\n",
        "#epoch 500 batch size 1000\n",
        "\n",
        "valid_loss = 100000000000\n",
        "loss_flag = False\n",
        "\n",
        "loss_count = 0\n",
        "\n",
        "#training loop\n",
        "for epoch in range(next_epoch, next_epoch+num_epoch):\n",
        "    #set model in training mode\n",
        "    model.train()\n",
        "    \n",
        "    \n",
        "    # Make an entire pass (an 'epoch') over the training data in batch_size chunks\n",
        "    for i in range(0, len(X_train), batch_size):        \n",
        "        X = X_train[i:i+batch_size].to(device)     # Slice out a mini-batch of features\n",
        "        y = y_train[i:i+batch_size].to(device)     # Slice out a mini-batch of targets\n",
        "        \n",
        "        \n",
        "        # Make predictions (final-layer activations)\n",
        "        y_pred = model(X)                   \n",
        "        \n",
        "        l = loss(y_pred, y)                 # Compute loss with respect to predictions\n",
        "        model.zero_grad()                   # Reset all gradients to zero \n",
        "        l.backward()                        # Compute gradient of loss with backprop\n",
        "        optim.step()                    # Use the gradients to take a step with Adam.\n",
        "        \n",
        "    print(\"Epoch %2d: loss on final training batch: %.4f\" % (epoch, l.item()))\n",
        "    \n",
        "\n",
        "    #set in eval mode\n",
        "    model.eval()\n",
        "\n",
        "    #create dire query\n",
        "    \n",
        "    #validation set calculations\n",
        "    dire_X =  torch.index_select(X_val, 1, torch.LongTensor([*range(113,226)]))\n",
        "    dire_X = torch.cat((dire_X,torch.index_select(X_val, 1, torch.LongTensor([*range(0,113)]))),1).to(device)\n",
        "\n",
        "    \n",
        "    dire_pred = (model(dire_X) >= 0).float()\n",
        "\n",
        "   \n",
        "    \n",
        "    rad_pred = (model(X_val.to(device)) >= 0).float()\n",
        "\n",
        "    \n",
        "    \n",
        "    #calculation of overall probability\n",
        "    overall_prob = (((rad_pred + (1 - dire_pred))/2) > 0.5).float()\n",
        "    \n",
        "    val_acc = torch.mean((overall_prob.to('cpu') == y_val.to('cpu')).float())\n",
        "\n",
        "    #training set calculations\n",
        "    dire_X_train =  torch.index_select(X_train, 1, torch.LongTensor([*range(113,226)]))\n",
        "    dire_X_train = torch.cat((dire_X_train,torch.index_select(X_train, 1, torch.LongTensor([*range(0,113)]))),1).to(device)\n",
        "\n",
        "    dire_pred = (model(dire_X_train) >= 0).float()\n",
        "    \n",
        "    rad_pred = (model(X_train.to(device)) >= 0).float()\n",
        "    \n",
        "\n",
        "    overall_prob = (((rad_pred + (1 - dire_pred))/2) > 0.5).float()\n",
        "    \n",
        "    train_acc = torch.mean((overall_prob.to('cpu') == y_train.to('cpu')).float())\n",
        "    \n",
        "    print(\"Epoch %2d: accuracy on validation set: %.4f\" % (epoch, val_acc))\n",
        "    print(\"Epoch %2d: accuracy on training set: %.4f\" % (epoch, train_acc))\n",
        "    \n",
        "    print(\"Epoch %2d: loss on validation set: %.4f\" % (epoch, loss(model(X_val.to(device)), y_val.to(device))))\n",
        "    new_val_loss = loss(model(X_val.to(device)), y_val.to(device))\n",
        "\n",
        "    #append data for matplot lib\n",
        "    old_model1_val_acc.append(val_acc)\n",
        "    old_model1_train_acc.append(train_acc)\n",
        "    old_model1_val_loss.append(new_val_loss.item())\n",
        "    old_model1_train_loss.append(l.item())\n",
        "    epochs_3.append(epoch)\n",
        "\n",
        "    #early stopping if loss increase 7 times in a row\n",
        "    if new_val_loss > valid_loss:\n",
        "       loss_count += 1\n",
        "       if loss_count > 7:\n",
        "          break\n",
        "    else:\n",
        "      loss_count = 0\n",
        "\n",
        " \n",
        "    valid_loss = new_val_loss\n",
        "    \n",
        "    \n",
        "   \n",
        "\n",
        "next_epoch = epoch+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0NiEH4MO21H",
        "outputId": "77f750f4-3053-42dc-d7c9-9b399cb49c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1: loss on final training batch: 0.6898\n",
            "Epoch  1: accuracy on validation set: 0.4878\n",
            "Epoch  1: accuracy on training set: 0.4762\n",
            "Epoch  1: loss on validation set: 0.6942\n",
            "Epoch  2: loss on final training batch: 0.6896\n",
            "Epoch  2: accuracy on validation set: 0.4883\n",
            "Epoch  2: accuracy on training set: 0.4764\n",
            "Epoch  2: loss on validation set: 0.6939\n",
            "Epoch  3: loss on final training batch: 0.6893\n",
            "Epoch  3: accuracy on validation set: 0.4880\n",
            "Epoch  3: accuracy on training set: 0.4765\n",
            "Epoch  3: loss on validation set: 0.6936\n",
            "Epoch  4: loss on final training batch: 0.6891\n",
            "Epoch  4: accuracy on validation set: 0.4882\n",
            "Epoch  4: accuracy on training set: 0.4766\n",
            "Epoch  4: loss on validation set: 0.6934\n",
            "Epoch  5: loss on final training batch: 0.6888\n",
            "Epoch  5: accuracy on validation set: 0.4888\n",
            "Epoch  5: accuracy on training set: 0.4768\n",
            "Epoch  5: loss on validation set: 0.6931\n",
            "Epoch  6: loss on final training batch: 0.6886\n",
            "Epoch  6: accuracy on validation set: 0.4895\n",
            "Epoch  6: accuracy on training set: 0.4771\n",
            "Epoch  6: loss on validation set: 0.6928\n",
            "Epoch  7: loss on final training batch: 0.6883\n",
            "Epoch  7: accuracy on validation set: 0.4890\n",
            "Epoch  7: accuracy on training set: 0.4776\n",
            "Epoch  7: loss on validation set: 0.6926\n",
            "Epoch  8: loss on final training batch: 0.6881\n",
            "Epoch  8: accuracy on validation set: 0.4895\n",
            "Epoch  8: accuracy on training set: 0.4784\n",
            "Epoch  8: loss on validation set: 0.6923\n",
            "Epoch  9: loss on final training batch: 0.6878\n",
            "Epoch  9: accuracy on validation set: 0.4898\n",
            "Epoch  9: accuracy on training set: 0.4791\n",
            "Epoch  9: loss on validation set: 0.6920\n",
            "Epoch 10: loss on final training batch: 0.6876\n",
            "Epoch 10: accuracy on validation set: 0.4908\n",
            "Epoch 10: accuracy on training set: 0.4796\n",
            "Epoch 10: loss on validation set: 0.6917\n",
            "Epoch 11: loss on final training batch: 0.6873\n",
            "Epoch 11: accuracy on validation set: 0.4913\n",
            "Epoch 11: accuracy on training set: 0.4804\n",
            "Epoch 11: loss on validation set: 0.6915\n",
            "Epoch 12: loss on final training batch: 0.6870\n",
            "Epoch 12: accuracy on validation set: 0.4920\n",
            "Epoch 12: accuracy on training set: 0.4814\n",
            "Epoch 12: loss on validation set: 0.6912\n",
            "Epoch 13: loss on final training batch: 0.6867\n",
            "Epoch 13: accuracy on validation set: 0.4932\n",
            "Epoch 13: accuracy on training set: 0.4829\n",
            "Epoch 13: loss on validation set: 0.6909\n",
            "Epoch 14: loss on final training batch: 0.6864\n",
            "Epoch 14: accuracy on validation set: 0.4950\n",
            "Epoch 14: accuracy on training set: 0.4852\n",
            "Epoch 14: loss on validation set: 0.6906\n",
            "Epoch 15: loss on final training batch: 0.6861\n",
            "Epoch 15: accuracy on validation set: 0.4973\n",
            "Epoch 15: accuracy on training set: 0.4870\n",
            "Epoch 15: loss on validation set: 0.6903\n",
            "Epoch 16: loss on final training batch: 0.6858\n",
            "Epoch 16: accuracy on validation set: 0.4985\n",
            "Epoch 16: accuracy on training set: 0.4894\n",
            "Epoch 16: loss on validation set: 0.6900\n",
            "Epoch 17: loss on final training batch: 0.6855\n",
            "Epoch 17: accuracy on validation set: 0.5007\n",
            "Epoch 17: accuracy on training set: 0.4916\n",
            "Epoch 17: loss on validation set: 0.6897\n",
            "Epoch 18: loss on final training batch: 0.6852\n",
            "Epoch 18: accuracy on validation set: 0.5025\n",
            "Epoch 18: accuracy on training set: 0.4940\n",
            "Epoch 18: loss on validation set: 0.6894\n",
            "Epoch 19: loss on final training batch: 0.6848\n",
            "Epoch 19: accuracy on validation set: 0.5060\n",
            "Epoch 19: accuracy on training set: 0.4966\n",
            "Epoch 19: loss on validation set: 0.6891\n",
            "Epoch 20: loss on final training batch: 0.6845\n",
            "Epoch 20: accuracy on validation set: 0.5092\n",
            "Epoch 20: accuracy on training set: 0.4993\n",
            "Epoch 20: loss on validation set: 0.6888\n",
            "Epoch 21: loss on final training batch: 0.6841\n",
            "Epoch 21: accuracy on validation set: 0.5118\n",
            "Epoch 21: accuracy on training set: 0.5032\n",
            "Epoch 21: loss on validation set: 0.6884\n",
            "Epoch 22: loss on final training batch: 0.6837\n",
            "Epoch 22: accuracy on validation set: 0.5158\n",
            "Epoch 22: accuracy on training set: 0.5073\n",
            "Epoch 22: loss on validation set: 0.6881\n",
            "Epoch 23: loss on final training batch: 0.6834\n",
            "Epoch 23: accuracy on validation set: 0.5195\n",
            "Epoch 23: accuracy on training set: 0.5113\n",
            "Epoch 23: loss on validation set: 0.6877\n",
            "Epoch 24: loss on final training batch: 0.6830\n",
            "Epoch 24: accuracy on validation set: 0.5222\n",
            "Epoch 24: accuracy on training set: 0.5157\n",
            "Epoch 24: loss on validation set: 0.6873\n",
            "Epoch 25: loss on final training batch: 0.6826\n",
            "Epoch 25: accuracy on validation set: 0.5252\n",
            "Epoch 25: accuracy on training set: 0.5199\n",
            "Epoch 25: loss on validation set: 0.6869\n",
            "Epoch 26: loss on final training batch: 0.6822\n",
            "Epoch 26: accuracy on validation set: 0.5273\n",
            "Epoch 26: accuracy on training set: 0.5225\n",
            "Epoch 26: loss on validation set: 0.6866\n",
            "Epoch 27: loss on final training batch: 0.6818\n",
            "Epoch 27: accuracy on validation set: 0.5323\n",
            "Epoch 27: accuracy on training set: 0.5262\n",
            "Epoch 27: loss on validation set: 0.6862\n",
            "Epoch 28: loss on final training batch: 0.6814\n",
            "Epoch 28: accuracy on validation set: 0.5362\n",
            "Epoch 28: accuracy on training set: 0.5299\n",
            "Epoch 28: loss on validation set: 0.6858\n",
            "Epoch 29: loss on final training batch: 0.6810\n",
            "Epoch 29: accuracy on validation set: 0.5385\n",
            "Epoch 29: accuracy on training set: 0.5333\n",
            "Epoch 29: loss on validation set: 0.6854\n",
            "Epoch 30: loss on final training batch: 0.6806\n",
            "Epoch 30: accuracy on validation set: 0.5400\n",
            "Epoch 30: accuracy on training set: 0.5365\n",
            "Epoch 30: loss on validation set: 0.6849\n",
            "Epoch 31: loss on final training batch: 0.6802\n",
            "Epoch 31: accuracy on validation set: 0.5435\n",
            "Epoch 31: accuracy on training set: 0.5397\n",
            "Epoch 31: loss on validation set: 0.6845\n",
            "Epoch 32: loss on final training batch: 0.6797\n",
            "Epoch 32: accuracy on validation set: 0.5475\n",
            "Epoch 32: accuracy on training set: 0.5429\n",
            "Epoch 32: loss on validation set: 0.6841\n",
            "Epoch 33: loss on final training batch: 0.6793\n",
            "Epoch 33: accuracy on validation set: 0.5500\n",
            "Epoch 33: accuracy on training set: 0.5460\n",
            "Epoch 33: loss on validation set: 0.6837\n",
            "Epoch 34: loss on final training batch: 0.6788\n",
            "Epoch 34: accuracy on validation set: 0.5515\n",
            "Epoch 34: accuracy on training set: 0.5483\n",
            "Epoch 34: loss on validation set: 0.6832\n",
            "Epoch 35: loss on final training batch: 0.6784\n",
            "Epoch 35: accuracy on validation set: 0.5532\n",
            "Epoch 35: accuracy on training set: 0.5509\n",
            "Epoch 35: loss on validation set: 0.6828\n",
            "Epoch 36: loss on final training batch: 0.6779\n",
            "Epoch 36: accuracy on validation set: 0.5542\n",
            "Epoch 36: accuracy on training set: 0.5538\n",
            "Epoch 36: loss on validation set: 0.6824\n",
            "Epoch 37: loss on final training batch: 0.6775\n",
            "Epoch 37: accuracy on validation set: 0.5578\n",
            "Epoch 37: accuracy on training set: 0.5554\n",
            "Epoch 37: loss on validation set: 0.6819\n",
            "Epoch 38: loss on final training batch: 0.6770\n",
            "Epoch 38: accuracy on validation set: 0.5605\n",
            "Epoch 38: accuracy on training set: 0.5574\n",
            "Epoch 38: loss on validation set: 0.6815\n",
            "Epoch 39: loss on final training batch: 0.6765\n",
            "Epoch 39: accuracy on validation set: 0.5637\n",
            "Epoch 39: accuracy on training set: 0.5585\n",
            "Epoch 39: loss on validation set: 0.6811\n",
            "Epoch 40: loss on final training batch: 0.6761\n",
            "Epoch 40: accuracy on validation set: 0.5667\n",
            "Epoch 40: accuracy on training set: 0.5606\n",
            "Epoch 40: loss on validation set: 0.6806\n",
            "Epoch 41: loss on final training batch: 0.6756\n",
            "Epoch 41: accuracy on validation set: 0.5675\n",
            "Epoch 41: accuracy on training set: 0.5626\n",
            "Epoch 41: loss on validation set: 0.6802\n",
            "Epoch 42: loss on final training batch: 0.6752\n",
            "Epoch 42: accuracy on validation set: 0.5705\n",
            "Epoch 42: accuracy on training set: 0.5645\n",
            "Epoch 42: loss on validation set: 0.6798\n",
            "Epoch 43: loss on final training batch: 0.6747\n",
            "Epoch 43: accuracy on validation set: 0.5708\n",
            "Epoch 43: accuracy on training set: 0.5664\n",
            "Epoch 43: loss on validation set: 0.6794\n",
            "Epoch 44: loss on final training batch: 0.6743\n",
            "Epoch 44: accuracy on validation set: 0.5718\n",
            "Epoch 44: accuracy on training set: 0.5681\n",
            "Epoch 44: loss on validation set: 0.6790\n",
            "Epoch 45: loss on final training batch: 0.6738\n",
            "Epoch 45: accuracy on validation set: 0.5728\n",
            "Epoch 45: accuracy on training set: 0.5693\n",
            "Epoch 45: loss on validation set: 0.6786\n",
            "Epoch 46: loss on final training batch: 0.6734\n",
            "Epoch 46: accuracy on validation set: 0.5742\n",
            "Epoch 46: accuracy on training set: 0.5707\n",
            "Epoch 46: loss on validation set: 0.6782\n",
            "Epoch 47: loss on final training batch: 0.6729\n",
            "Epoch 47: accuracy on validation set: 0.5748\n",
            "Epoch 47: accuracy on training set: 0.5718\n",
            "Epoch 47: loss on validation set: 0.6778\n",
            "Epoch 48: loss on final training batch: 0.6725\n",
            "Epoch 48: accuracy on validation set: 0.5763\n",
            "Epoch 48: accuracy on training set: 0.5725\n",
            "Epoch 48: loss on validation set: 0.6774\n",
            "Epoch 49: loss on final training batch: 0.6721\n",
            "Epoch 49: accuracy on validation set: 0.5763\n",
            "Epoch 49: accuracy on training set: 0.5729\n",
            "Epoch 49: loss on validation set: 0.6770\n",
            "Epoch 50: loss on final training batch: 0.6717\n",
            "Epoch 50: accuracy on validation set: 0.5788\n",
            "Epoch 50: accuracy on training set: 0.5730\n",
            "Epoch 50: loss on validation set: 0.6766\n",
            "Epoch 51: loss on final training batch: 0.6713\n",
            "Epoch 51: accuracy on validation set: 0.5783\n",
            "Epoch 51: accuracy on training set: 0.5738\n",
            "Epoch 51: loss on validation set: 0.6763\n",
            "Epoch 52: loss on final training batch: 0.6709\n",
            "Epoch 52: accuracy on validation set: 0.5793\n",
            "Epoch 52: accuracy on training set: 0.5743\n",
            "Epoch 52: loss on validation set: 0.6759\n",
            "Epoch 53: loss on final training batch: 0.6705\n",
            "Epoch 53: accuracy on validation set: 0.5802\n",
            "Epoch 53: accuracy on training set: 0.5750\n",
            "Epoch 53: loss on validation set: 0.6755\n",
            "Epoch 54: loss on final training batch: 0.6701\n",
            "Epoch 54: accuracy on validation set: 0.5817\n",
            "Epoch 54: accuracy on training set: 0.5757\n",
            "Epoch 54: loss on validation set: 0.6752\n",
            "Epoch 55: loss on final training batch: 0.6697\n",
            "Epoch 55: accuracy on validation set: 0.5820\n",
            "Epoch 55: accuracy on training set: 0.5763\n",
            "Epoch 55: loss on validation set: 0.6749\n",
            "Epoch 56: loss on final training batch: 0.6693\n",
            "Epoch 56: accuracy on validation set: 0.5827\n",
            "Epoch 56: accuracy on training set: 0.5771\n",
            "Epoch 56: loss on validation set: 0.6745\n",
            "Epoch 57: loss on final training batch: 0.6690\n",
            "Epoch 57: accuracy on validation set: 0.5840\n",
            "Epoch 57: accuracy on training set: 0.5779\n",
            "Epoch 57: loss on validation set: 0.6742\n",
            "Epoch 58: loss on final training batch: 0.6686\n",
            "Epoch 58: accuracy on validation set: 0.5838\n",
            "Epoch 58: accuracy on training set: 0.5786\n",
            "Epoch 58: loss on validation set: 0.6739\n",
            "Epoch 59: loss on final training batch: 0.6683\n",
            "Epoch 59: accuracy on validation set: 0.5847\n",
            "Epoch 59: accuracy on training set: 0.5795\n",
            "Epoch 59: loss on validation set: 0.6736\n",
            "Epoch 60: loss on final training batch: 0.6680\n",
            "Epoch 60: accuracy on validation set: 0.5857\n",
            "Epoch 60: accuracy on training set: 0.5798\n",
            "Epoch 60: loss on validation set: 0.6733\n",
            "Epoch 61: loss on final training batch: 0.6676\n",
            "Epoch 61: accuracy on validation set: 0.5857\n",
            "Epoch 61: accuracy on training set: 0.5805\n",
            "Epoch 61: loss on validation set: 0.6730\n",
            "Epoch 62: loss on final training batch: 0.6673\n",
            "Epoch 62: accuracy on validation set: 0.5852\n",
            "Epoch 62: accuracy on training set: 0.5808\n",
            "Epoch 62: loss on validation set: 0.6727\n",
            "Epoch 63: loss on final training batch: 0.6670\n",
            "Epoch 63: accuracy on validation set: 0.5847\n",
            "Epoch 63: accuracy on training set: 0.5806\n",
            "Epoch 63: loss on validation set: 0.6724\n",
            "Epoch 64: loss on final training batch: 0.6667\n",
            "Epoch 64: accuracy on validation set: 0.5850\n",
            "Epoch 64: accuracy on training set: 0.5810\n",
            "Epoch 64: loss on validation set: 0.6722\n",
            "Epoch 65: loss on final training batch: 0.6664\n",
            "Epoch 65: accuracy on validation set: 0.5860\n",
            "Epoch 65: accuracy on training set: 0.5821\n",
            "Epoch 65: loss on validation set: 0.6719\n",
            "Epoch 66: loss on final training batch: 0.6661\n",
            "Epoch 66: accuracy on validation set: 0.5863\n",
            "Epoch 66: accuracy on training set: 0.5825\n",
            "Epoch 66: loss on validation set: 0.6717\n",
            "Epoch 67: loss on final training batch: 0.6658\n",
            "Epoch 67: accuracy on validation set: 0.5870\n",
            "Epoch 67: accuracy on training set: 0.5829\n",
            "Epoch 67: loss on validation set: 0.6714\n",
            "Epoch 68: loss on final training batch: 0.6656\n",
            "Epoch 68: accuracy on validation set: 0.5890\n",
            "Epoch 68: accuracy on training set: 0.5831\n",
            "Epoch 68: loss on validation set: 0.6712\n",
            "Epoch 69: loss on final training batch: 0.6653\n",
            "Epoch 69: accuracy on validation set: 0.5893\n",
            "Epoch 69: accuracy on training set: 0.5833\n",
            "Epoch 69: loss on validation set: 0.6710\n",
            "Epoch 70: loss on final training batch: 0.6650\n",
            "Epoch 70: accuracy on validation set: 0.5890\n",
            "Epoch 70: accuracy on training set: 0.5836\n",
            "Epoch 70: loss on validation set: 0.6707\n",
            "Epoch 71: loss on final training batch: 0.6648\n",
            "Epoch 71: accuracy on validation set: 0.5902\n",
            "Epoch 71: accuracy on training set: 0.5836\n",
            "Epoch 71: loss on validation set: 0.6705\n",
            "Epoch 72: loss on final training batch: 0.6645\n",
            "Epoch 72: accuracy on validation set: 0.5908\n",
            "Epoch 72: accuracy on training set: 0.5839\n",
            "Epoch 72: loss on validation set: 0.6703\n",
            "Epoch 73: loss on final training batch: 0.6643\n",
            "Epoch 73: accuracy on validation set: 0.5907\n",
            "Epoch 73: accuracy on training set: 0.5841\n",
            "Epoch 73: loss on validation set: 0.6701\n",
            "Epoch 74: loss on final training batch: 0.6640\n",
            "Epoch 74: accuracy on validation set: 0.5908\n",
            "Epoch 74: accuracy on training set: 0.5842\n",
            "Epoch 74: loss on validation set: 0.6699\n",
            "Epoch 75: loss on final training batch: 0.6638\n",
            "Epoch 75: accuracy on validation set: 0.5903\n",
            "Epoch 75: accuracy on training set: 0.5843\n",
            "Epoch 75: loss on validation set: 0.6697\n",
            "Epoch 76: loss on final training batch: 0.6635\n",
            "Epoch 76: accuracy on validation set: 0.5908\n",
            "Epoch 76: accuracy on training set: 0.5846\n",
            "Epoch 76: loss on validation set: 0.6695\n",
            "Epoch 77: loss on final training batch: 0.6633\n",
            "Epoch 77: accuracy on validation set: 0.5913\n",
            "Epoch 77: accuracy on training set: 0.5844\n",
            "Epoch 77: loss on validation set: 0.6693\n",
            "Epoch 78: loss on final training batch: 0.6631\n",
            "Epoch 78: accuracy on validation set: 0.5915\n",
            "Epoch 78: accuracy on training set: 0.5850\n",
            "Epoch 78: loss on validation set: 0.6691\n",
            "Epoch 79: loss on final training batch: 0.6629\n",
            "Epoch 79: accuracy on validation set: 0.5915\n",
            "Epoch 79: accuracy on training set: 0.5850\n",
            "Epoch 79: loss on validation set: 0.6690\n",
            "Epoch 80: loss on final training batch: 0.6627\n",
            "Epoch 80: accuracy on validation set: 0.5927\n",
            "Epoch 80: accuracy on training set: 0.5851\n",
            "Epoch 80: loss on validation set: 0.6688\n",
            "Epoch 81: loss on final training batch: 0.6625\n",
            "Epoch 81: accuracy on validation set: 0.5925\n",
            "Epoch 81: accuracy on training set: 0.5855\n",
            "Epoch 81: loss on validation set: 0.6686\n",
            "Epoch 82: loss on final training batch: 0.6622\n",
            "Epoch 82: accuracy on validation set: 0.5920\n",
            "Epoch 82: accuracy on training set: 0.5858\n",
            "Epoch 82: loss on validation set: 0.6685\n",
            "Epoch 83: loss on final training batch: 0.6620\n",
            "Epoch 83: accuracy on validation set: 0.5925\n",
            "Epoch 83: accuracy on training set: 0.5855\n",
            "Epoch 83: loss on validation set: 0.6683\n",
            "Epoch 84: loss on final training batch: 0.6619\n",
            "Epoch 84: accuracy on validation set: 0.5932\n",
            "Epoch 84: accuracy on training set: 0.5855\n",
            "Epoch 84: loss on validation set: 0.6682\n",
            "Epoch 85: loss on final training batch: 0.6617\n",
            "Epoch 85: accuracy on validation set: 0.5932\n",
            "Epoch 85: accuracy on training set: 0.5856\n",
            "Epoch 85: loss on validation set: 0.6681\n",
            "Epoch 86: loss on final training batch: 0.6615\n",
            "Epoch 86: accuracy on validation set: 0.5937\n",
            "Epoch 86: accuracy on training set: 0.5858\n",
            "Epoch 86: loss on validation set: 0.6679\n",
            "Epoch 87: loss on final training batch: 0.6613\n",
            "Epoch 87: accuracy on validation set: 0.5937\n",
            "Epoch 87: accuracy on training set: 0.5858\n",
            "Epoch 87: loss on validation set: 0.6678\n",
            "Epoch 88: loss on final training batch: 0.6611\n",
            "Epoch 88: accuracy on validation set: 0.5933\n",
            "Epoch 88: accuracy on training set: 0.5862\n",
            "Epoch 88: loss on validation set: 0.6677\n",
            "Epoch 89: loss on final training batch: 0.6609\n",
            "Epoch 89: accuracy on validation set: 0.5933\n",
            "Epoch 89: accuracy on training set: 0.5865\n",
            "Epoch 89: loss on validation set: 0.6675\n",
            "Epoch 90: loss on final training batch: 0.6608\n",
            "Epoch 90: accuracy on validation set: 0.5930\n",
            "Epoch 90: accuracy on training set: 0.5865\n",
            "Epoch 90: loss on validation set: 0.6674\n",
            "Epoch 91: loss on final training batch: 0.6606\n",
            "Epoch 91: accuracy on validation set: 0.5932\n",
            "Epoch 91: accuracy on training set: 0.5866\n",
            "Epoch 91: loss on validation set: 0.6673\n",
            "Epoch 92: loss on final training batch: 0.6604\n",
            "Epoch 92: accuracy on validation set: 0.5927\n",
            "Epoch 92: accuracy on training set: 0.5869\n",
            "Epoch 92: loss on validation set: 0.6672\n",
            "Epoch 93: loss on final training batch: 0.6603\n",
            "Epoch 93: accuracy on validation set: 0.5933\n",
            "Epoch 93: accuracy on training set: 0.5867\n",
            "Epoch 93: loss on validation set: 0.6671\n",
            "Epoch 94: loss on final training batch: 0.6601\n",
            "Epoch 94: accuracy on validation set: 0.5933\n",
            "Epoch 94: accuracy on training set: 0.5868\n",
            "Epoch 94: loss on validation set: 0.6670\n",
            "Epoch 95: loss on final training batch: 0.6600\n",
            "Epoch 95: accuracy on validation set: 0.5927\n",
            "Epoch 95: accuracy on training set: 0.5869\n",
            "Epoch 95: loss on validation set: 0.6669\n",
            "Epoch 96: loss on final training batch: 0.6598\n",
            "Epoch 96: accuracy on validation set: 0.5933\n",
            "Epoch 96: accuracy on training set: 0.5869\n",
            "Epoch 96: loss on validation set: 0.6668\n",
            "Epoch 97: loss on final training batch: 0.6597\n",
            "Epoch 97: accuracy on validation set: 0.5937\n",
            "Epoch 97: accuracy on training set: 0.5873\n",
            "Epoch 97: loss on validation set: 0.6667\n",
            "Epoch 98: loss on final training batch: 0.6595\n",
            "Epoch 98: accuracy on validation set: 0.5937\n",
            "Epoch 98: accuracy on training set: 0.5876\n",
            "Epoch 98: loss on validation set: 0.6666\n",
            "Epoch 99: loss on final training batch: 0.6594\n",
            "Epoch 99: accuracy on validation set: 0.5938\n",
            "Epoch 99: accuracy on training set: 0.5877\n",
            "Epoch 99: loss on validation set: 0.6665\n",
            "Epoch 100: loss on final training batch: 0.6592\n",
            "Epoch 100: accuracy on validation set: 0.5937\n",
            "Epoch 100: accuracy on training set: 0.5878\n",
            "Epoch 100: loss on validation set: 0.6664\n",
            "Epoch 101: loss on final training batch: 0.6591\n",
            "Epoch 101: accuracy on validation set: 0.5935\n",
            "Epoch 101: accuracy on training set: 0.5878\n",
            "Epoch 101: loss on validation set: 0.6663\n",
            "Epoch 102: loss on final training batch: 0.6590\n",
            "Epoch 102: accuracy on validation set: 0.5940\n",
            "Epoch 102: accuracy on training set: 0.5880\n",
            "Epoch 102: loss on validation set: 0.6662\n",
            "Epoch 103: loss on final training batch: 0.6589\n",
            "Epoch 103: accuracy on validation set: 0.5937\n",
            "Epoch 103: accuracy on training set: 0.5881\n",
            "Epoch 103: loss on validation set: 0.6662\n",
            "Epoch 104: loss on final training batch: 0.6587\n",
            "Epoch 104: accuracy on validation set: 0.5937\n",
            "Epoch 104: accuracy on training set: 0.5881\n",
            "Epoch 104: loss on validation set: 0.6661\n",
            "Epoch 105: loss on final training batch: 0.6586\n",
            "Epoch 105: accuracy on validation set: 0.5933\n",
            "Epoch 105: accuracy on training set: 0.5882\n",
            "Epoch 105: loss on validation set: 0.6660\n",
            "Epoch 106: loss on final training batch: 0.6585\n",
            "Epoch 106: accuracy on validation set: 0.5937\n",
            "Epoch 106: accuracy on training set: 0.5884\n",
            "Epoch 106: loss on validation set: 0.6659\n",
            "Epoch 107: loss on final training batch: 0.6584\n",
            "Epoch 107: accuracy on validation set: 0.5933\n",
            "Epoch 107: accuracy on training set: 0.5886\n",
            "Epoch 107: loss on validation set: 0.6659\n",
            "Epoch 108: loss on final training batch: 0.6582\n",
            "Epoch 108: accuracy on validation set: 0.5933\n",
            "Epoch 108: accuracy on training set: 0.5886\n",
            "Epoch 108: loss on validation set: 0.6658\n",
            "Epoch 109: loss on final training batch: 0.6581\n",
            "Epoch 109: accuracy on validation set: 0.5933\n",
            "Epoch 109: accuracy on training set: 0.5888\n",
            "Epoch 109: loss on validation set: 0.6657\n",
            "Epoch 110: loss on final training batch: 0.6580\n",
            "Epoch 110: accuracy on validation set: 0.5937\n",
            "Epoch 110: accuracy on training set: 0.5888\n",
            "Epoch 110: loss on validation set: 0.6657\n",
            "Epoch 111: loss on final training batch: 0.6579\n",
            "Epoch 111: accuracy on validation set: 0.5938\n",
            "Epoch 111: accuracy on training set: 0.5888\n",
            "Epoch 111: loss on validation set: 0.6656\n",
            "Epoch 112: loss on final training batch: 0.6578\n",
            "Epoch 112: accuracy on validation set: 0.5942\n",
            "Epoch 112: accuracy on training set: 0.5891\n",
            "Epoch 112: loss on validation set: 0.6655\n",
            "Epoch 113: loss on final training batch: 0.6577\n",
            "Epoch 113: accuracy on validation set: 0.5943\n",
            "Epoch 113: accuracy on training set: 0.5890\n",
            "Epoch 113: loss on validation set: 0.6655\n",
            "Epoch 114: loss on final training batch: 0.6576\n",
            "Epoch 114: accuracy on validation set: 0.5947\n",
            "Epoch 114: accuracy on training set: 0.5891\n",
            "Epoch 114: loss on validation set: 0.6654\n",
            "Epoch 115: loss on final training batch: 0.6575\n",
            "Epoch 115: accuracy on validation set: 0.5950\n",
            "Epoch 115: accuracy on training set: 0.5890\n",
            "Epoch 115: loss on validation set: 0.6654\n",
            "Epoch 116: loss on final training batch: 0.6574\n",
            "Epoch 116: accuracy on validation set: 0.5955\n",
            "Epoch 116: accuracy on training set: 0.5891\n",
            "Epoch 116: loss on validation set: 0.6653\n",
            "Epoch 117: loss on final training batch: 0.6573\n",
            "Epoch 117: accuracy on validation set: 0.5957\n",
            "Epoch 117: accuracy on training set: 0.5894\n",
            "Epoch 117: loss on validation set: 0.6653\n",
            "Epoch 118: loss on final training batch: 0.6572\n",
            "Epoch 118: accuracy on validation set: 0.5958\n",
            "Epoch 118: accuracy on training set: 0.5894\n",
            "Epoch 118: loss on validation set: 0.6652\n",
            "Epoch 119: loss on final training batch: 0.6571\n",
            "Epoch 119: accuracy on validation set: 0.5960\n",
            "Epoch 119: accuracy on training set: 0.5893\n",
            "Epoch 119: loss on validation set: 0.6652\n",
            "Epoch 120: loss on final training batch: 0.6570\n",
            "Epoch 120: accuracy on validation set: 0.5957\n",
            "Epoch 120: accuracy on training set: 0.5895\n",
            "Epoch 120: loss on validation set: 0.6651\n",
            "Epoch 121: loss on final training batch: 0.6569\n",
            "Epoch 121: accuracy on validation set: 0.5957\n",
            "Epoch 121: accuracy on training set: 0.5896\n",
            "Epoch 121: loss on validation set: 0.6651\n",
            "Epoch 122: loss on final training batch: 0.6569\n",
            "Epoch 122: accuracy on validation set: 0.5958\n",
            "Epoch 122: accuracy on training set: 0.5896\n",
            "Epoch 122: loss on validation set: 0.6650\n",
            "Epoch 123: loss on final training batch: 0.6568\n",
            "Epoch 123: accuracy on validation set: 0.5957\n",
            "Epoch 123: accuracy on training set: 0.5898\n",
            "Epoch 123: loss on validation set: 0.6650\n",
            "Epoch 124: loss on final training batch: 0.6567\n",
            "Epoch 124: accuracy on validation set: 0.5955\n",
            "Epoch 124: accuracy on training set: 0.5898\n",
            "Epoch 124: loss on validation set: 0.6650\n",
            "Epoch 125: loss on final training batch: 0.6566\n",
            "Epoch 125: accuracy on validation set: 0.5955\n",
            "Epoch 125: accuracy on training set: 0.5898\n",
            "Epoch 125: loss on validation set: 0.6649\n",
            "Epoch 126: loss on final training batch: 0.6565\n",
            "Epoch 126: accuracy on validation set: 0.5960\n",
            "Epoch 126: accuracy on training set: 0.5898\n",
            "Epoch 126: loss on validation set: 0.6649\n",
            "Epoch 127: loss on final training batch: 0.6564\n",
            "Epoch 127: accuracy on validation set: 0.5962\n",
            "Epoch 127: accuracy on training set: 0.5900\n",
            "Epoch 127: loss on validation set: 0.6648\n",
            "Epoch 128: loss on final training batch: 0.6564\n",
            "Epoch 128: accuracy on validation set: 0.5960\n",
            "Epoch 128: accuracy on training set: 0.5900\n",
            "Epoch 128: loss on validation set: 0.6648\n",
            "Epoch 129: loss on final training batch: 0.6563\n",
            "Epoch 129: accuracy on validation set: 0.5963\n",
            "Epoch 129: accuracy on training set: 0.5901\n",
            "Epoch 129: loss on validation set: 0.6648\n",
            "Epoch 130: loss on final training batch: 0.6562\n",
            "Epoch 130: accuracy on validation set: 0.5968\n",
            "Epoch 130: accuracy on training set: 0.5900\n",
            "Epoch 130: loss on validation set: 0.6647\n",
            "Epoch 131: loss on final training batch: 0.6561\n",
            "Epoch 131: accuracy on validation set: 0.5970\n",
            "Epoch 131: accuracy on training set: 0.5901\n",
            "Epoch 131: loss on validation set: 0.6647\n",
            "Epoch 132: loss on final training batch: 0.6561\n",
            "Epoch 132: accuracy on validation set: 0.5973\n",
            "Epoch 132: accuracy on training set: 0.5902\n",
            "Epoch 132: loss on validation set: 0.6647\n",
            "Epoch 133: loss on final training batch: 0.6560\n",
            "Epoch 133: accuracy on validation set: 0.5977\n",
            "Epoch 133: accuracy on training set: 0.5902\n",
            "Epoch 133: loss on validation set: 0.6646\n",
            "Epoch 134: loss on final training batch: 0.6559\n",
            "Epoch 134: accuracy on validation set: 0.5978\n",
            "Epoch 134: accuracy on training set: 0.5902\n",
            "Epoch 134: loss on validation set: 0.6646\n",
            "Epoch 135: loss on final training batch: 0.6559\n",
            "Epoch 135: accuracy on validation set: 0.5980\n",
            "Epoch 135: accuracy on training set: 0.5902\n",
            "Epoch 135: loss on validation set: 0.6646\n",
            "Epoch 136: loss on final training batch: 0.6558\n",
            "Epoch 136: accuracy on validation set: 0.5980\n",
            "Epoch 136: accuracy on training set: 0.5902\n",
            "Epoch 136: loss on validation set: 0.6645\n",
            "Epoch 137: loss on final training batch: 0.6557\n",
            "Epoch 137: accuracy on validation set: 0.5982\n",
            "Epoch 137: accuracy on training set: 0.5902\n",
            "Epoch 137: loss on validation set: 0.6645\n",
            "Epoch 138: loss on final training batch: 0.6557\n",
            "Epoch 138: accuracy on validation set: 0.5978\n",
            "Epoch 138: accuracy on training set: 0.5903\n",
            "Epoch 138: loss on validation set: 0.6645\n",
            "Epoch 139: loss on final training batch: 0.6556\n",
            "Epoch 139: accuracy on validation set: 0.5975\n",
            "Epoch 139: accuracy on training set: 0.5901\n",
            "Epoch 139: loss on validation set: 0.6645\n",
            "Epoch 140: loss on final training batch: 0.6555\n",
            "Epoch 140: accuracy on validation set: 0.5978\n",
            "Epoch 140: accuracy on training set: 0.5901\n",
            "Epoch 140: loss on validation set: 0.6644\n",
            "Epoch 141: loss on final training batch: 0.6555\n",
            "Epoch 141: accuracy on validation set: 0.5982\n",
            "Epoch 141: accuracy on training set: 0.5900\n",
            "Epoch 141: loss on validation set: 0.6644\n",
            "Epoch 142: loss on final training batch: 0.6554\n",
            "Epoch 142: accuracy on validation set: 0.5980\n",
            "Epoch 142: accuracy on training set: 0.5900\n",
            "Epoch 142: loss on validation set: 0.6644\n",
            "Epoch 143: loss on final training batch: 0.6554\n",
            "Epoch 143: accuracy on validation set: 0.5983\n",
            "Epoch 143: accuracy on training set: 0.5899\n",
            "Epoch 143: loss on validation set: 0.6644\n",
            "Epoch 144: loss on final training batch: 0.6553\n",
            "Epoch 144: accuracy on validation set: 0.5983\n",
            "Epoch 144: accuracy on training set: 0.5900\n",
            "Epoch 144: loss on validation set: 0.6643\n",
            "Epoch 145: loss on final training batch: 0.6553\n",
            "Epoch 145: accuracy on validation set: 0.5980\n",
            "Epoch 145: accuracy on training set: 0.5899\n",
            "Epoch 145: loss on validation set: 0.6643\n",
            "Epoch 146: loss on final training batch: 0.6552\n",
            "Epoch 146: accuracy on validation set: 0.5983\n",
            "Epoch 146: accuracy on training set: 0.5901\n",
            "Epoch 146: loss on validation set: 0.6643\n",
            "Epoch 147: loss on final training batch: 0.6551\n",
            "Epoch 147: accuracy on validation set: 0.5987\n",
            "Epoch 147: accuracy on training set: 0.5901\n",
            "Epoch 147: loss on validation set: 0.6643\n",
            "Epoch 148: loss on final training batch: 0.6551\n",
            "Epoch 148: accuracy on validation set: 0.5985\n",
            "Epoch 148: accuracy on training set: 0.5903\n",
            "Epoch 148: loss on validation set: 0.6643\n",
            "Epoch 149: loss on final training batch: 0.6550\n",
            "Epoch 149: accuracy on validation set: 0.5987\n",
            "Epoch 149: accuracy on training set: 0.5903\n",
            "Epoch 149: loss on validation set: 0.6642\n",
            "Epoch 150: loss on final training batch: 0.6550\n",
            "Epoch 150: accuracy on validation set: 0.5990\n",
            "Epoch 150: accuracy on training set: 0.5904\n",
            "Epoch 150: loss on validation set: 0.6642\n",
            "Epoch 151: loss on final training batch: 0.6549\n",
            "Epoch 151: accuracy on validation set: 0.5992\n",
            "Epoch 151: accuracy on training set: 0.5904\n",
            "Epoch 151: loss on validation set: 0.6642\n",
            "Epoch 152: loss on final training batch: 0.6549\n",
            "Epoch 152: accuracy on validation set: 0.5992\n",
            "Epoch 152: accuracy on training set: 0.5904\n",
            "Epoch 152: loss on validation set: 0.6642\n",
            "Epoch 153: loss on final training batch: 0.6548\n",
            "Epoch 153: accuracy on validation set: 0.5990\n",
            "Epoch 153: accuracy on training set: 0.5902\n",
            "Epoch 153: loss on validation set: 0.6642\n",
            "Epoch 154: loss on final training batch: 0.6548\n",
            "Epoch 154: accuracy on validation set: 0.5990\n",
            "Epoch 154: accuracy on training set: 0.5902\n",
            "Epoch 154: loss on validation set: 0.6641\n",
            "Epoch 155: loss on final training batch: 0.6547\n",
            "Epoch 155: accuracy on validation set: 0.5988\n",
            "Epoch 155: accuracy on training set: 0.5902\n",
            "Epoch 155: loss on validation set: 0.6641\n",
            "Epoch 156: loss on final training batch: 0.6547\n",
            "Epoch 156: accuracy on validation set: 0.5988\n",
            "Epoch 156: accuracy on training set: 0.5901\n",
            "Epoch 156: loss on validation set: 0.6641\n",
            "Epoch 157: loss on final training batch: 0.6546\n",
            "Epoch 157: accuracy on validation set: 0.5988\n",
            "Epoch 157: accuracy on training set: 0.5901\n",
            "Epoch 157: loss on validation set: 0.6641\n",
            "Epoch 158: loss on final training batch: 0.6546\n",
            "Epoch 158: accuracy on validation set: 0.5987\n",
            "Epoch 158: accuracy on training set: 0.5901\n",
            "Epoch 158: loss on validation set: 0.6641\n",
            "Epoch 159: loss on final training batch: 0.6545\n",
            "Epoch 159: accuracy on validation set: 0.5988\n",
            "Epoch 159: accuracy on training set: 0.5900\n",
            "Epoch 159: loss on validation set: 0.6641\n",
            "Epoch 160: loss on final training batch: 0.6545\n",
            "Epoch 160: accuracy on validation set: 0.5988\n",
            "Epoch 160: accuracy on training set: 0.5900\n",
            "Epoch 160: loss on validation set: 0.6640\n",
            "Epoch 161: loss on final training batch: 0.6545\n",
            "Epoch 161: accuracy on validation set: 0.5993\n",
            "Epoch 161: accuracy on training set: 0.5899\n",
            "Epoch 161: loss on validation set: 0.6640\n",
            "Epoch 162: loss on final training batch: 0.6544\n",
            "Epoch 162: accuracy on validation set: 0.5998\n",
            "Epoch 162: accuracy on training set: 0.5900\n",
            "Epoch 162: loss on validation set: 0.6640\n",
            "Epoch 163: loss on final training batch: 0.6544\n",
            "Epoch 163: accuracy on validation set: 0.6000\n",
            "Epoch 163: accuracy on training set: 0.5899\n",
            "Epoch 163: loss on validation set: 0.6640\n",
            "Epoch 164: loss on final training batch: 0.6543\n",
            "Epoch 164: accuracy on validation set: 0.5997\n",
            "Epoch 164: accuracy on training set: 0.5898\n",
            "Epoch 164: loss on validation set: 0.6640\n",
            "Epoch 165: loss on final training batch: 0.6543\n",
            "Epoch 165: accuracy on validation set: 0.5998\n",
            "Epoch 165: accuracy on training set: 0.5900\n",
            "Epoch 165: loss on validation set: 0.6640\n",
            "Epoch 166: loss on final training batch: 0.6542\n",
            "Epoch 166: accuracy on validation set: 0.5998\n",
            "Epoch 166: accuracy on training set: 0.5899\n",
            "Epoch 166: loss on validation set: 0.6640\n",
            "Epoch 167: loss on final training batch: 0.6542\n",
            "Epoch 167: accuracy on validation set: 0.6000\n",
            "Epoch 167: accuracy on training set: 0.5899\n",
            "Epoch 167: loss on validation set: 0.6640\n",
            "Epoch 168: loss on final training batch: 0.6542\n",
            "Epoch 168: accuracy on validation set: 0.5998\n",
            "Epoch 168: accuracy on training set: 0.5900\n",
            "Epoch 168: loss on validation set: 0.6639\n",
            "Epoch 169: loss on final training batch: 0.6541\n",
            "Epoch 169: accuracy on validation set: 0.6000\n",
            "Epoch 169: accuracy on training set: 0.5900\n",
            "Epoch 169: loss on validation set: 0.6639\n",
            "Epoch 170: loss on final training batch: 0.6541\n",
            "Epoch 170: accuracy on validation set: 0.5997\n",
            "Epoch 170: accuracy on training set: 0.5899\n",
            "Epoch 170: loss on validation set: 0.6639\n",
            "Epoch 171: loss on final training batch: 0.6541\n",
            "Epoch 171: accuracy on validation set: 0.5997\n",
            "Epoch 171: accuracy on training set: 0.5901\n",
            "Epoch 171: loss on validation set: 0.6639\n",
            "Epoch 172: loss on final training batch: 0.6540\n",
            "Epoch 172: accuracy on validation set: 0.5995\n",
            "Epoch 172: accuracy on training set: 0.5902\n",
            "Epoch 172: loss on validation set: 0.6639\n",
            "Epoch 173: loss on final training batch: 0.6540\n",
            "Epoch 173: accuracy on validation set: 0.5997\n",
            "Epoch 173: accuracy on training set: 0.5902\n",
            "Epoch 173: loss on validation set: 0.6639\n",
            "Epoch 174: loss on final training batch: 0.6539\n",
            "Epoch 174: accuracy on validation set: 0.5997\n",
            "Epoch 174: accuracy on training set: 0.5901\n",
            "Epoch 174: loss on validation set: 0.6639\n",
            "Epoch 175: loss on final training batch: 0.6539\n",
            "Epoch 175: accuracy on validation set: 0.5995\n",
            "Epoch 175: accuracy on training set: 0.5901\n",
            "Epoch 175: loss on validation set: 0.6639\n",
            "Epoch 176: loss on final training batch: 0.6539\n",
            "Epoch 176: accuracy on validation set: 0.5995\n",
            "Epoch 176: accuracy on training set: 0.5901\n",
            "Epoch 176: loss on validation set: 0.6638\n",
            "Epoch 177: loss on final training batch: 0.6538\n",
            "Epoch 177: accuracy on validation set: 0.5997\n",
            "Epoch 177: accuracy on training set: 0.5903\n",
            "Epoch 177: loss on validation set: 0.6638\n",
            "Epoch 178: loss on final training batch: 0.6538\n",
            "Epoch 178: accuracy on validation set: 0.6000\n",
            "Epoch 178: accuracy on training set: 0.5901\n",
            "Epoch 178: loss on validation set: 0.6638\n",
            "Epoch 179: loss on final training batch: 0.6538\n",
            "Epoch 179: accuracy on validation set: 0.6007\n",
            "Epoch 179: accuracy on training set: 0.5903\n",
            "Epoch 179: loss on validation set: 0.6638\n",
            "Epoch 180: loss on final training batch: 0.6537\n",
            "Epoch 180: accuracy on validation set: 0.6007\n",
            "Epoch 180: accuracy on training set: 0.5904\n",
            "Epoch 180: loss on validation set: 0.6638\n",
            "Epoch 181: loss on final training batch: 0.6537\n",
            "Epoch 181: accuracy on validation set: 0.6005\n",
            "Epoch 181: accuracy on training set: 0.5904\n",
            "Epoch 181: loss on validation set: 0.6638\n",
            "Epoch 182: loss on final training batch: 0.6537\n",
            "Epoch 182: accuracy on validation set: 0.6007\n",
            "Epoch 182: accuracy on training set: 0.5905\n",
            "Epoch 182: loss on validation set: 0.6638\n",
            "Epoch 183: loss on final training batch: 0.6536\n",
            "Epoch 183: accuracy on validation set: 0.6007\n",
            "Epoch 183: accuracy on training set: 0.5906\n",
            "Epoch 183: loss on validation set: 0.6638\n",
            "Epoch 184: loss on final training batch: 0.6536\n",
            "Epoch 184: accuracy on validation set: 0.6003\n",
            "Epoch 184: accuracy on training set: 0.5906\n",
            "Epoch 184: loss on validation set: 0.6638\n",
            "Epoch 185: loss on final training batch: 0.6536\n",
            "Epoch 185: accuracy on validation set: 0.6000\n",
            "Epoch 185: accuracy on training set: 0.5906\n",
            "Epoch 185: loss on validation set: 0.6638\n",
            "Epoch 186: loss on final training batch: 0.6535\n",
            "Epoch 186: accuracy on validation set: 0.5998\n",
            "Epoch 186: accuracy on training set: 0.5906\n",
            "Epoch 186: loss on validation set: 0.6637\n",
            "Epoch 187: loss on final training batch: 0.6535\n",
            "Epoch 187: accuracy on validation set: 0.5998\n",
            "Epoch 187: accuracy on training set: 0.5907\n",
            "Epoch 187: loss on validation set: 0.6637\n",
            "Epoch 188: loss on final training batch: 0.6535\n",
            "Epoch 188: accuracy on validation set: 0.5997\n",
            "Epoch 188: accuracy on training set: 0.5908\n",
            "Epoch 188: loss on validation set: 0.6637\n",
            "Epoch 189: loss on final training batch: 0.6535\n",
            "Epoch 189: accuracy on validation set: 0.5997\n",
            "Epoch 189: accuracy on training set: 0.5909\n",
            "Epoch 189: loss on validation set: 0.6637\n",
            "Epoch 190: loss on final training batch: 0.6534\n",
            "Epoch 190: accuracy on validation set: 0.5998\n",
            "Epoch 190: accuracy on training set: 0.5909\n",
            "Epoch 190: loss on validation set: 0.6637\n",
            "Epoch 191: loss on final training batch: 0.6534\n",
            "Epoch 191: accuracy on validation set: 0.5998\n",
            "Epoch 191: accuracy on training set: 0.5909\n",
            "Epoch 191: loss on validation set: 0.6637\n",
            "Epoch 192: loss on final training batch: 0.6534\n",
            "Epoch 192: accuracy on validation set: 0.5998\n",
            "Epoch 192: accuracy on training set: 0.5911\n",
            "Epoch 192: loss on validation set: 0.6637\n",
            "Epoch 193: loss on final training batch: 0.6533\n",
            "Epoch 193: accuracy on validation set: 0.5997\n",
            "Epoch 193: accuracy on training set: 0.5911\n",
            "Epoch 193: loss on validation set: 0.6637\n",
            "Epoch 194: loss on final training batch: 0.6533\n",
            "Epoch 194: accuracy on validation set: 0.5998\n",
            "Epoch 194: accuracy on training set: 0.5912\n",
            "Epoch 194: loss on validation set: 0.6637\n",
            "Epoch 195: loss on final training batch: 0.6533\n",
            "Epoch 195: accuracy on validation set: 0.6000\n",
            "Epoch 195: accuracy on training set: 0.5912\n",
            "Epoch 195: loss on validation set: 0.6637\n",
            "Epoch 196: loss on final training batch: 0.6533\n",
            "Epoch 196: accuracy on validation set: 0.6002\n",
            "Epoch 196: accuracy on training set: 0.5911\n",
            "Epoch 196: loss on validation set: 0.6637\n",
            "Epoch 197: loss on final training batch: 0.6532\n",
            "Epoch 197: accuracy on validation set: 0.6000\n",
            "Epoch 197: accuracy on training set: 0.5913\n",
            "Epoch 197: loss on validation set: 0.6637\n",
            "Epoch 198: loss on final training batch: 0.6532\n",
            "Epoch 198: accuracy on validation set: 0.6002\n",
            "Epoch 198: accuracy on training set: 0.5913\n",
            "Epoch 198: loss on validation set: 0.6637\n",
            "Epoch 199: loss on final training batch: 0.6532\n",
            "Epoch 199: accuracy on validation set: 0.6002\n",
            "Epoch 199: accuracy on training set: 0.5914\n",
            "Epoch 199: loss on validation set: 0.6637\n",
            "Epoch 200: loss on final training batch: 0.6531\n",
            "Epoch 200: accuracy on validation set: 0.5998\n",
            "Epoch 200: accuracy on training set: 0.5913\n",
            "Epoch 200: loss on validation set: 0.6636\n",
            "Epoch 201: loss on final training batch: 0.6531\n",
            "Epoch 201: accuracy on validation set: 0.6000\n",
            "Epoch 201: accuracy on training set: 0.5915\n",
            "Epoch 201: loss on validation set: 0.6636\n",
            "Epoch 202: loss on final training batch: 0.6531\n",
            "Epoch 202: accuracy on validation set: 0.6000\n",
            "Epoch 202: accuracy on training set: 0.5914\n",
            "Epoch 202: loss on validation set: 0.6636\n",
            "Epoch 203: loss on final training batch: 0.6531\n",
            "Epoch 203: accuracy on validation set: 0.6000\n",
            "Epoch 203: accuracy on training set: 0.5914\n",
            "Epoch 203: loss on validation set: 0.6636\n",
            "Epoch 204: loss on final training batch: 0.6530\n",
            "Epoch 204: accuracy on validation set: 0.5998\n",
            "Epoch 204: accuracy on training set: 0.5913\n",
            "Epoch 204: loss on validation set: 0.6636\n",
            "Epoch 205: loss on final training batch: 0.6530\n",
            "Epoch 205: accuracy on validation set: 0.5998\n",
            "Epoch 205: accuracy on training set: 0.5913\n",
            "Epoch 205: loss on validation set: 0.6636\n",
            "Epoch 206: loss on final training batch: 0.6530\n",
            "Epoch 206: accuracy on validation set: 0.6002\n",
            "Epoch 206: accuracy on training set: 0.5914\n",
            "Epoch 206: loss on validation set: 0.6636\n",
            "Epoch 207: loss on final training batch: 0.6530\n",
            "Epoch 207: accuracy on validation set: 0.6002\n",
            "Epoch 207: accuracy on training set: 0.5914\n",
            "Epoch 207: loss on validation set: 0.6636\n",
            "Epoch 208: loss on final training batch: 0.6529\n",
            "Epoch 208: accuracy on validation set: 0.6003\n",
            "Epoch 208: accuracy on training set: 0.5914\n",
            "Epoch 208: loss on validation set: 0.6636\n",
            "Epoch 209: loss on final training batch: 0.6529\n",
            "Epoch 209: accuracy on validation set: 0.6003\n",
            "Epoch 209: accuracy on training set: 0.5915\n",
            "Epoch 209: loss on validation set: 0.6636\n",
            "Epoch 210: loss on final training batch: 0.6529\n",
            "Epoch 210: accuracy on validation set: 0.6005\n",
            "Epoch 210: accuracy on training set: 0.5916\n",
            "Epoch 210: loss on validation set: 0.6636\n",
            "Epoch 211: loss on final training batch: 0.6529\n",
            "Epoch 211: accuracy on validation set: 0.6007\n",
            "Epoch 211: accuracy on training set: 0.5917\n",
            "Epoch 211: loss on validation set: 0.6636\n",
            "Epoch 212: loss on final training batch: 0.6528\n",
            "Epoch 212: accuracy on validation set: 0.6010\n",
            "Epoch 212: accuracy on training set: 0.5916\n",
            "Epoch 212: loss on validation set: 0.6636\n",
            "Epoch 213: loss on final training batch: 0.6528\n",
            "Epoch 213: accuracy on validation set: 0.6010\n",
            "Epoch 213: accuracy on training set: 0.5917\n",
            "Epoch 213: loss on validation set: 0.6636\n",
            "Epoch 214: loss on final training batch: 0.6528\n",
            "Epoch 214: accuracy on validation set: 0.6010\n",
            "Epoch 214: accuracy on training set: 0.5916\n",
            "Epoch 214: loss on validation set: 0.6636\n",
            "Epoch 215: loss on final training batch: 0.6528\n",
            "Epoch 215: accuracy on validation set: 0.6010\n",
            "Epoch 215: accuracy on training set: 0.5915\n",
            "Epoch 215: loss on validation set: 0.6636\n",
            "Epoch 216: loss on final training batch: 0.6527\n",
            "Epoch 216: accuracy on validation set: 0.6010\n",
            "Epoch 216: accuracy on training set: 0.5916\n",
            "Epoch 216: loss on validation set: 0.6636\n",
            "Epoch 217: loss on final training batch: 0.6527\n",
            "Epoch 217: accuracy on validation set: 0.6010\n",
            "Epoch 217: accuracy on training set: 0.5916\n",
            "Epoch 217: loss on validation set: 0.6636\n",
            "Epoch 218: loss on final training batch: 0.6527\n",
            "Epoch 218: accuracy on validation set: 0.6012\n",
            "Epoch 218: accuracy on training set: 0.5918\n",
            "Epoch 218: loss on validation set: 0.6635\n",
            "Epoch 219: loss on final training batch: 0.6527\n",
            "Epoch 219: accuracy on validation set: 0.6012\n",
            "Epoch 219: accuracy on training set: 0.5917\n",
            "Epoch 219: loss on validation set: 0.6635\n",
            "Epoch 220: loss on final training batch: 0.6526\n",
            "Epoch 220: accuracy on validation set: 0.6012\n",
            "Epoch 220: accuracy on training set: 0.5917\n",
            "Epoch 220: loss on validation set: 0.6635\n",
            "Epoch 221: loss on final training batch: 0.6526\n",
            "Epoch 221: accuracy on validation set: 0.6012\n",
            "Epoch 221: accuracy on training set: 0.5916\n",
            "Epoch 221: loss on validation set: 0.6635\n",
            "Epoch 222: loss on final training batch: 0.6526\n",
            "Epoch 222: accuracy on validation set: 0.6012\n",
            "Epoch 222: accuracy on training set: 0.5917\n",
            "Epoch 222: loss on validation set: 0.6635\n",
            "Epoch 223: loss on final training batch: 0.6526\n",
            "Epoch 223: accuracy on validation set: 0.6013\n",
            "Epoch 223: accuracy on training set: 0.5916\n",
            "Epoch 223: loss on validation set: 0.6635\n",
            "Epoch 224: loss on final training batch: 0.6526\n",
            "Epoch 224: accuracy on validation set: 0.6015\n",
            "Epoch 224: accuracy on training set: 0.5916\n",
            "Epoch 224: loss on validation set: 0.6635\n",
            "Epoch 225: loss on final training batch: 0.6525\n",
            "Epoch 225: accuracy on validation set: 0.6015\n",
            "Epoch 225: accuracy on training set: 0.5916\n",
            "Epoch 225: loss on validation set: 0.6635\n",
            "Epoch 226: loss on final training batch: 0.6525\n",
            "Epoch 226: accuracy on validation set: 0.6012\n",
            "Epoch 226: accuracy on training set: 0.5916\n",
            "Epoch 226: loss on validation set: 0.6635\n",
            "Epoch 227: loss on final training batch: 0.6525\n",
            "Epoch 227: accuracy on validation set: 0.6012\n",
            "Epoch 227: accuracy on training set: 0.5916\n",
            "Epoch 227: loss on validation set: 0.6635\n",
            "Epoch 228: loss on final training batch: 0.6525\n",
            "Epoch 228: accuracy on validation set: 0.6012\n",
            "Epoch 228: accuracy on training set: 0.5916\n",
            "Epoch 228: loss on validation set: 0.6635\n",
            "Epoch 229: loss on final training batch: 0.6525\n",
            "Epoch 229: accuracy on validation set: 0.6010\n",
            "Epoch 229: accuracy on training set: 0.5916\n",
            "Epoch 229: loss on validation set: 0.6635\n",
            "Epoch 230: loss on final training batch: 0.6524\n",
            "Epoch 230: accuracy on validation set: 0.6010\n",
            "Epoch 230: accuracy on training set: 0.5915\n",
            "Epoch 230: loss on validation set: 0.6635\n",
            "Epoch 231: loss on final training batch: 0.6524\n",
            "Epoch 231: accuracy on validation set: 0.6008\n",
            "Epoch 231: accuracy on training set: 0.5915\n",
            "Epoch 231: loss on validation set: 0.6635\n",
            "Epoch 232: loss on final training batch: 0.6524\n",
            "Epoch 232: accuracy on validation set: 0.6007\n",
            "Epoch 232: accuracy on training set: 0.5916\n",
            "Epoch 232: loss on validation set: 0.6635\n",
            "Epoch 233: loss on final training batch: 0.6524\n",
            "Epoch 233: accuracy on validation set: 0.6005\n",
            "Epoch 233: accuracy on training set: 0.5916\n",
            "Epoch 233: loss on validation set: 0.6635\n",
            "Epoch 234: loss on final training batch: 0.6523\n",
            "Epoch 234: accuracy on validation set: 0.6007\n",
            "Epoch 234: accuracy on training set: 0.5915\n",
            "Epoch 234: loss on validation set: 0.6635\n",
            "Epoch 235: loss on final training batch: 0.6523\n",
            "Epoch 235: accuracy on validation set: 0.6005\n",
            "Epoch 235: accuracy on training set: 0.5915\n",
            "Epoch 235: loss on validation set: 0.6635\n",
            "Epoch 236: loss on final training batch: 0.6523\n",
            "Epoch 236: accuracy on validation set: 0.6005\n",
            "Epoch 236: accuracy on training set: 0.5915\n",
            "Epoch 236: loss on validation set: 0.6635\n",
            "Epoch 237: loss on final training batch: 0.6523\n",
            "Epoch 237: accuracy on validation set: 0.6003\n",
            "Epoch 237: accuracy on training set: 0.5916\n",
            "Epoch 237: loss on validation set: 0.6635\n",
            "Epoch 238: loss on final training batch: 0.6523\n",
            "Epoch 238: accuracy on validation set: 0.6005\n",
            "Epoch 238: accuracy on training set: 0.5915\n",
            "Epoch 238: loss on validation set: 0.6635\n",
            "Epoch 239: loss on final training batch: 0.6522\n",
            "Epoch 239: accuracy on validation set: 0.6005\n",
            "Epoch 239: accuracy on training set: 0.5916\n",
            "Epoch 239: loss on validation set: 0.6635\n",
            "Epoch 240: loss on final training batch: 0.6522\n",
            "Epoch 240: accuracy on validation set: 0.6005\n",
            "Epoch 240: accuracy on training set: 0.5916\n",
            "Epoch 240: loss on validation set: 0.6635\n",
            "Epoch 241: loss on final training batch: 0.6522\n",
            "Epoch 241: accuracy on validation set: 0.6003\n",
            "Epoch 241: accuracy on training set: 0.5916\n",
            "Epoch 241: loss on validation set: 0.6635\n",
            "Epoch 242: loss on final training batch: 0.6522\n",
            "Epoch 242: accuracy on validation set: 0.6003\n",
            "Epoch 242: accuracy on training set: 0.5916\n",
            "Epoch 242: loss on validation set: 0.6635\n",
            "Epoch 243: loss on final training batch: 0.6522\n",
            "Epoch 243: accuracy on validation set: 0.6003\n",
            "Epoch 243: accuracy on training set: 0.5916\n",
            "Epoch 243: loss on validation set: 0.6635\n",
            "Epoch 244: loss on final training batch: 0.6522\n",
            "Epoch 244: accuracy on validation set: 0.6005\n",
            "Epoch 244: accuracy on training set: 0.5916\n",
            "Epoch 244: loss on validation set: 0.6635\n",
            "Epoch 245: loss on final training batch: 0.6521\n",
            "Epoch 245: accuracy on validation set: 0.6007\n",
            "Epoch 245: accuracy on training set: 0.5916\n",
            "Epoch 245: loss on validation set: 0.6634\n",
            "Epoch 246: loss on final training batch: 0.6521\n",
            "Epoch 246: accuracy on validation set: 0.6007\n",
            "Epoch 246: accuracy on training set: 0.5914\n",
            "Epoch 246: loss on validation set: 0.6634\n",
            "Epoch 247: loss on final training batch: 0.6521\n",
            "Epoch 247: accuracy on validation set: 0.6007\n",
            "Epoch 247: accuracy on training set: 0.5914\n",
            "Epoch 247: loss on validation set: 0.6634\n",
            "Epoch 248: loss on final training batch: 0.6521\n",
            "Epoch 248: accuracy on validation set: 0.6007\n",
            "Epoch 248: accuracy on training set: 0.5914\n",
            "Epoch 248: loss on validation set: 0.6634\n",
            "Epoch 249: loss on final training batch: 0.6521\n",
            "Epoch 249: accuracy on validation set: 0.6007\n",
            "Epoch 249: accuracy on training set: 0.5913\n",
            "Epoch 249: loss on validation set: 0.6634\n",
            "Epoch 250: loss on final training batch: 0.6520\n",
            "Epoch 250: accuracy on validation set: 0.6007\n",
            "Epoch 250: accuracy on training set: 0.5912\n",
            "Epoch 250: loss on validation set: 0.6634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test accuracy on test set \n",
        "dire_X =  torch.index_select(X_test, 1, torch.LongTensor([*range(113,226)]))\n",
        "dire_X = torch.cat((dire_X,torch.index_select(X_test, 1, torch.LongTensor([*range(0,113)]))),1).to(device)\n",
        "dire_pred = (model(dire_X) >= 0).float()\n",
        "rad_pred = (model(X_test.to(device)) >= 0).float()\n",
        "\n",
        "#calulate as display accuracy with overall prob calc\n",
        "overall_prob = (((rad_pred + (1 - dire_pred))/2) > 0.5).float()\n",
        "acc = torch.mean((overall_prob.to(device) == y_test.to(device)).float())\n",
        "print(\"test accuracy\", acc.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CULZHpsasuSM",
        "outputId": "18a6dff9-625a-47f2-d2d9-84a0ebb922bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy 0.6010000109672546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the old match data through model 3\n",
        "The following hyperparameters tested provided the best results, An early stop mechanism was also added, which breaks the loop when the validation loss increases multiple times in a row:\n",
        "\n",
        "\n",
        "*   Learning rate = 1.6e-4\n",
        "*   Optimizer = Adam\n",
        "*   Batchsize = 625 \n",
        "*   Weight decay = 2.6e-3\n",
        "*   Epochs = 250\n"
      ],
      "metadata": {
        "id": "F9OZQo4CaIJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skorch import NeuralNetClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "\n",
        "#lists for matplot graphing\n",
        "old_model3_val_acc = []\n",
        "old_model3_train_acc = []\n",
        "old_model3_val_loss = []\n",
        "old_model3_train_loss = []\n",
        "epochs_4 = []\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(226,113),\n",
        "    torch.nn.BatchNorm1d(113),\n",
        "    torch.nn.Dropout(),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(113,60),\n",
        "    torch.nn.Dropout(),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(60,16),\n",
        "    torch.nn.Dropout(),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(16,1)\n",
        "   \n",
        ")\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "#loss function and optimizer\n",
        "loss = torch.nn.BCEWithLogitsLoss()\n",
        "optim = torch.optim.Adam(model.parameters(),lr=1.6e-4, weight_decay=2.6e-3)\n",
        "\n",
        "\n",
        "#epoch number\n",
        "num_epoch = 250\n",
        "next_epoch = 1\n",
        "batch_size = 625\n",
        "\n",
        "#epoch 500 batch size 1000\n",
        "\n",
        "valid_loss = 100000000000\n",
        "loss_flag = False\n",
        "\n",
        "loss_count = 0\n",
        "\n",
        "#training loop\n",
        "for epoch in range(next_epoch, next_epoch+num_epoch):\n",
        "\n",
        "    #set model in training mode\n",
        "    model.train()\n",
        "    \n",
        "    \n",
        "    # Make an entire pass (an 'epoch') over the training data in batch_size chunks\n",
        "    for i in range(0, len(X_train), batch_size):        \n",
        "        X = X_train[i:i+batch_size].to(device)     # Slice out a mini-batch of features\n",
        "        y = y_train[i:i+batch_size].to(device)     # Slice out a mini-batch of targets\n",
        "        \n",
        "        \n",
        "\n",
        "        # Make predictions (final-layer activations)\n",
        "        y_pred = model(X)                   \n",
        "        \n",
        "        l = loss(y_pred, y)                 # Compute loss with respect to predictions\n",
        "        model.zero_grad()                   # Reset all gradients to zero \n",
        "        l.backward()                        # Compute gradient of loss with backprop\n",
        "        optim.step()                    # Use the gradients to take a step with Adam.\n",
        "        \n",
        "    print(\"Epoch %2d: loss on final training batch: %.4f\" % (epoch, l.item()))\n",
        "    \n",
        "    #set model in eval mode for accuracy/loss calculations\n",
        "    model.eval()\n",
        "\n",
        "    #create dire query\n",
        "    \n",
        "    #validation set calculations\n",
        "    dire_X =  torch.index_select(X_val, 1, torch.LongTensor([*range(113,226)]))\n",
        "    dire_X = torch.cat((dire_X,torch.index_select(X_val, 1, torch.LongTensor([*range(0,113)]))),1).to(device)\n",
        "\n",
        "    \n",
        "    dire_pred = (model(dire_X) >= 0).float()\n",
        "\n",
        "   \n",
        "    \n",
        "    rad_pred = (model(X_val.to(device)) >= 0).float()\n",
        "\n",
        "    \n",
        "    \n",
        "    #calculation of overall probability\n",
        "    overall_prob = (((rad_pred + (1 - dire_pred))/2) > 0.5).float()\n",
        "    \n",
        "    val_acc = torch.mean((overall_prob.to('cpu') == y_val.to('cpu')).float())\n",
        "\n",
        "    #training set calculations\n",
        "    dire_X_train =  torch.index_select(X_train, 1, torch.LongTensor([*range(113,226)]))\n",
        "    dire_X_train = torch.cat((dire_X_train,torch.index_select(X_train, 1, torch.LongTensor([*range(0,113)]))),1).to(device)\n",
        "\n",
        "    dire_pred = (model(dire_X_train) >= 0).float()\n",
        "    \n",
        "    rad_pred = (model(X_train.to(device)) >= 0).float()\n",
        "    \n",
        "\n",
        "    overall_prob = (((rad_pred + (1 - dire_pred))/2) > 0.5).float()\n",
        "    \n",
        "    train_acc = torch.mean((overall_prob.to('cpu') == y_train.to('cpu')).float())\n",
        "    \n",
        "    print(\"Epoch %2d: accuracy on validation set: %.4f\" % (epoch, val_acc))\n",
        "    print(\"Epoch %2d: accuracy on training set: %.4f\" % (epoch, train_acc))\n",
        "    \n",
        "    print(\"Epoch %2d: loss on validation set: %.4f\" % (epoch, loss(model(X_val.to(device)), y_val.to(device))))\n",
        "    new_val_loss = loss(model(X_val.to(device)), y_val.to(device))\n",
        "\n",
        "    old_model3_val_acc.append(val_acc)\n",
        "    old_model3_train_acc.append(train_acc)\n",
        "    old_model3_val_loss.append(new_val_loss.item())\n",
        "    old_model3_train_loss.append(l.item())\n",
        "    epochs_4.append(epoch)\n",
        "\n",
        "   #early stopping if loss increase 7 times in a row\n",
        "    if new_val_loss > valid_loss:\n",
        "       loss_count += 1\n",
        "       if loss_count > 7:\n",
        "          break\n",
        "    else:\n",
        "      loss_count = 0\n",
        "\n",
        "       \n",
        " \n",
        "    valid_loss = new_val_loss\n",
        "    \n",
        "    \n",
        "   \n",
        "\n",
        "next_epoch = epoch+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0wRIuzsO-rj",
        "outputId": "9c4f253f-aef0-4d4c-ac0b-44a5f9319a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-116-cd7468a14d86>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_train = torch.tensor(X_train,dtype=torch.float32)\n",
            "<ipython-input-116-cd7468a14d86>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_val = torch.tensor(X_val,dtype=torch.float32)\n",
            "<ipython-input-116-cd7468a14d86>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_test = torch.tensor(X_test,dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1: loss on final training batch: 0.7024\n",
            "Epoch  1: accuracy on validation set: 0.4852\n",
            "Epoch  1: accuracy on training set: 0.4830\n",
            "Epoch  1: loss on validation set: 0.6932\n",
            "Epoch  2: loss on final training batch: 0.6915\n",
            "Epoch  2: accuracy on validation set: 0.4853\n",
            "Epoch  2: accuracy on training set: 0.4832\n",
            "Epoch  2: loss on validation set: 0.6924\n",
            "Epoch  3: loss on final training batch: 0.6934\n",
            "Epoch  3: accuracy on validation set: 0.4857\n",
            "Epoch  3: accuracy on training set: 0.4837\n",
            "Epoch  3: loss on validation set: 0.6918\n",
            "Epoch  4: loss on final training batch: 0.6902\n",
            "Epoch  4: accuracy on validation set: 0.4860\n",
            "Epoch  4: accuracy on training set: 0.4851\n",
            "Epoch  4: loss on validation set: 0.6910\n",
            "Epoch  5: loss on final training batch: 0.6950\n",
            "Epoch  5: accuracy on validation set: 0.4910\n",
            "Epoch  5: accuracy on training set: 0.4908\n",
            "Epoch  5: loss on validation set: 0.6902\n",
            "Epoch  6: loss on final training batch: 0.6914\n",
            "Epoch  6: accuracy on validation set: 0.5052\n",
            "Epoch  6: accuracy on training set: 0.5041\n",
            "Epoch  6: loss on validation set: 0.6891\n",
            "Epoch  7: loss on final training batch: 0.6889\n",
            "Epoch  7: accuracy on validation set: 0.5405\n",
            "Epoch  7: accuracy on training set: 0.5352\n",
            "Epoch  7: loss on validation set: 0.6873\n",
            "Epoch  8: loss on final training batch: 0.6920\n",
            "Epoch  8: accuracy on validation set: 0.5585\n",
            "Epoch  8: accuracy on training set: 0.5559\n",
            "Epoch  8: loss on validation set: 0.6851\n",
            "Epoch  9: loss on final training batch: 0.6828\n",
            "Epoch  9: accuracy on validation set: 0.5678\n",
            "Epoch  9: accuracy on training set: 0.5726\n",
            "Epoch  9: loss on validation set: 0.6822\n",
            "Epoch 10: loss on final training batch: 0.6765\n",
            "Epoch 10: accuracy on validation set: 0.5783\n",
            "Epoch 10: accuracy on training set: 0.5801\n",
            "Epoch 10: loss on validation set: 0.6789\n",
            "Epoch 11: loss on final training batch: 0.6686\n",
            "Epoch 11: accuracy on validation set: 0.5825\n",
            "Epoch 11: accuracy on training set: 0.5867\n",
            "Epoch 11: loss on validation set: 0.6755\n",
            "Epoch 12: loss on final training batch: 0.6788\n",
            "Epoch 12: accuracy on validation set: 0.5882\n",
            "Epoch 12: accuracy on training set: 0.5899\n",
            "Epoch 12: loss on validation set: 0.6725\n",
            "Epoch 13: loss on final training batch: 0.6589\n",
            "Epoch 13: accuracy on validation set: 0.5890\n",
            "Epoch 13: accuracy on training set: 0.5915\n",
            "Epoch 13: loss on validation set: 0.6702\n",
            "Epoch 14: loss on final training batch: 0.6640\n",
            "Epoch 14: accuracy on validation set: 0.5927\n",
            "Epoch 14: accuracy on training set: 0.5951\n",
            "Epoch 14: loss on validation set: 0.6687\n",
            "Epoch 15: loss on final training batch: 0.6587\n",
            "Epoch 15: accuracy on validation set: 0.5958\n",
            "Epoch 15: accuracy on training set: 0.5961\n",
            "Epoch 15: loss on validation set: 0.6677\n",
            "Epoch 16: loss on final training batch: 0.6587\n",
            "Epoch 16: accuracy on validation set: 0.5958\n",
            "Epoch 16: accuracy on training set: 0.5997\n",
            "Epoch 16: loss on validation set: 0.6669\n",
            "Epoch 17: loss on final training batch: 0.6437\n",
            "Epoch 17: accuracy on validation set: 0.5962\n",
            "Epoch 17: accuracy on training set: 0.5992\n",
            "Epoch 17: loss on validation set: 0.6663\n",
            "Epoch 18: loss on final training batch: 0.6566\n",
            "Epoch 18: accuracy on validation set: 0.5960\n",
            "Epoch 18: accuracy on training set: 0.6009\n",
            "Epoch 18: loss on validation set: 0.6656\n",
            "Epoch 19: loss on final training batch: 0.6281\n",
            "Epoch 19: accuracy on validation set: 0.5960\n",
            "Epoch 19: accuracy on training set: 0.6033\n",
            "Epoch 19: loss on validation set: 0.6653\n",
            "Epoch 20: loss on final training batch: 0.6252\n",
            "Epoch 20: accuracy on validation set: 0.5955\n",
            "Epoch 20: accuracy on training set: 0.6044\n",
            "Epoch 20: loss on validation set: 0.6650\n",
            "Epoch 21: loss on final training batch: 0.6239\n",
            "Epoch 21: accuracy on validation set: 0.5945\n",
            "Epoch 21: accuracy on training set: 0.6039\n",
            "Epoch 21: loss on validation set: 0.6648\n",
            "Epoch 22: loss on final training batch: 0.6519\n",
            "Epoch 22: accuracy on validation set: 0.5937\n",
            "Epoch 22: accuracy on training set: 0.6051\n",
            "Epoch 22: loss on validation set: 0.6647\n",
            "Epoch 23: loss on final training batch: 0.6347\n",
            "Epoch 23: accuracy on validation set: 0.5952\n",
            "Epoch 23: accuracy on training set: 0.6050\n",
            "Epoch 23: loss on validation set: 0.6646\n",
            "Epoch 24: loss on final training batch: 0.6186\n",
            "Epoch 24: accuracy on validation set: 0.5935\n",
            "Epoch 24: accuracy on training set: 0.6066\n",
            "Epoch 24: loss on validation set: 0.6645\n",
            "Epoch 25: loss on final training batch: 0.6345\n",
            "Epoch 25: accuracy on validation set: 0.5927\n",
            "Epoch 25: accuracy on training set: 0.6072\n",
            "Epoch 25: loss on validation set: 0.6646\n",
            "Epoch 26: loss on final training batch: 0.6530\n",
            "Epoch 26: accuracy on validation set: 0.5935\n",
            "Epoch 26: accuracy on training set: 0.6085\n",
            "Epoch 26: loss on validation set: 0.6644\n",
            "Epoch 27: loss on final training batch: 0.6378\n",
            "Epoch 27: accuracy on validation set: 0.5937\n",
            "Epoch 27: accuracy on training set: 0.6117\n",
            "Epoch 27: loss on validation set: 0.6643\n",
            "Epoch 28: loss on final training batch: 0.6123\n",
            "Epoch 28: accuracy on validation set: 0.5932\n",
            "Epoch 28: accuracy on training set: 0.6124\n",
            "Epoch 28: loss on validation set: 0.6643\n",
            "Epoch 29: loss on final training batch: 0.6059\n",
            "Epoch 29: accuracy on validation set: 0.5932\n",
            "Epoch 29: accuracy on training set: 0.6121\n",
            "Epoch 29: loss on validation set: 0.6646\n",
            "Epoch 30: loss on final training batch: 0.6171\n",
            "Epoch 30: accuracy on validation set: 0.5933\n",
            "Epoch 30: accuracy on training set: 0.6139\n",
            "Epoch 30: loss on validation set: 0.6645\n",
            "Epoch 31: loss on final training batch: 0.6153\n",
            "Epoch 31: accuracy on validation set: 0.5950\n",
            "Epoch 31: accuracy on training set: 0.6162\n",
            "Epoch 31: loss on validation set: 0.6648\n",
            "Epoch 32: loss on final training batch: 0.6143\n",
            "Epoch 32: accuracy on validation set: 0.5957\n",
            "Epoch 32: accuracy on training set: 0.6153\n",
            "Epoch 32: loss on validation set: 0.6645\n",
            "Epoch 33: loss on final training batch: 0.5988\n",
            "Epoch 33: accuracy on validation set: 0.5935\n",
            "Epoch 33: accuracy on training set: 0.6191\n",
            "Epoch 33: loss on validation set: 0.6645\n",
            "Epoch 34: loss on final training batch: 0.6159\n",
            "Epoch 34: accuracy on validation set: 0.5947\n",
            "Epoch 34: accuracy on training set: 0.6185\n",
            "Epoch 34: loss on validation set: 0.6642\n",
            "Epoch 35: loss on final training batch: 0.6151\n",
            "Epoch 35: accuracy on validation set: 0.5947\n",
            "Epoch 35: accuracy on training set: 0.6190\n",
            "Epoch 35: loss on validation set: 0.6642\n",
            "Epoch 36: loss on final training batch: 0.6219\n",
            "Epoch 36: accuracy on validation set: 0.5972\n",
            "Epoch 36: accuracy on training set: 0.6205\n",
            "Epoch 36: loss on validation set: 0.6640\n",
            "Epoch 37: loss on final training batch: 0.5825\n",
            "Epoch 37: accuracy on validation set: 0.5955\n",
            "Epoch 37: accuracy on training set: 0.6227\n",
            "Epoch 37: loss on validation set: 0.6643\n",
            "Epoch 38: loss on final training batch: 0.5957\n",
            "Epoch 38: accuracy on validation set: 0.5955\n",
            "Epoch 38: accuracy on training set: 0.6240\n",
            "Epoch 38: loss on validation set: 0.6642\n",
            "Epoch 39: loss on final training batch: 0.6032\n",
            "Epoch 39: accuracy on validation set: 0.5923\n",
            "Epoch 39: accuracy on training set: 0.6242\n",
            "Epoch 39: loss on validation set: 0.6648\n",
            "Epoch 40: loss on final training batch: 0.5851\n",
            "Epoch 40: accuracy on validation set: 0.5955\n",
            "Epoch 40: accuracy on training set: 0.6281\n",
            "Epoch 40: loss on validation set: 0.6646\n",
            "Epoch 41: loss on final training batch: 0.5819\n",
            "Epoch 41: accuracy on validation set: 0.5937\n",
            "Epoch 41: accuracy on training set: 0.6258\n",
            "Epoch 41: loss on validation set: 0.6654\n",
            "Epoch 42: loss on final training batch: 0.5863\n",
            "Epoch 42: accuracy on validation set: 0.5982\n",
            "Epoch 42: accuracy on training set: 0.6277\n",
            "Epoch 42: loss on validation set: 0.6651\n",
            "Epoch 43: loss on final training batch: 0.5705\n",
            "Epoch 43: accuracy on validation set: 0.5963\n",
            "Epoch 43: accuracy on training set: 0.6338\n",
            "Epoch 43: loss on validation set: 0.6644\n",
            "Epoch 44: loss on final training batch: 0.5760\n",
            "Epoch 44: accuracy on validation set: 0.5917\n",
            "Epoch 44: accuracy on training set: 0.6309\n",
            "Epoch 44: loss on validation set: 0.6648\n",
            "Epoch 45: loss on final training batch: 0.5733\n",
            "Epoch 45: accuracy on validation set: 0.5918\n",
            "Epoch 45: accuracy on training set: 0.6354\n",
            "Epoch 45: loss on validation set: 0.6652\n",
            "Epoch 46: loss on final training batch: 0.5858\n",
            "Epoch 46: accuracy on validation set: 0.5913\n",
            "Epoch 46: accuracy on training set: 0.6335\n",
            "Epoch 46: loss on validation set: 0.6656\n",
            "Epoch 47: loss on final training batch: 0.5666\n",
            "Epoch 47: accuracy on validation set: 0.5912\n",
            "Epoch 47: accuracy on training set: 0.6370\n",
            "Epoch 47: loss on validation set: 0.6658\n",
            "Epoch 48: loss on final training batch: 0.5804\n",
            "Epoch 48: accuracy on validation set: 0.5903\n",
            "Epoch 48: accuracy on training set: 0.6367\n",
            "Epoch 48: loss on validation set: 0.6663\n",
            "Epoch 49: loss on final training batch: 0.5726\n",
            "Epoch 49: accuracy on validation set: 0.5893\n",
            "Epoch 49: accuracy on training set: 0.6364\n",
            "Epoch 49: loss on validation set: 0.6659\n",
            "Epoch 50: loss on final training batch: 0.5762\n",
            "Epoch 50: accuracy on validation set: 0.5895\n",
            "Epoch 50: accuracy on training set: 0.6399\n",
            "Epoch 50: loss on validation set: 0.6657\n",
            "Epoch 51: loss on final training batch: 0.5804\n",
            "Epoch 51: accuracy on validation set: 0.5917\n",
            "Epoch 51: accuracy on training set: 0.6431\n",
            "Epoch 51: loss on validation set: 0.6660\n",
            "Epoch 52: loss on final training batch: 0.5483\n",
            "Epoch 52: accuracy on validation set: 0.5898\n",
            "Epoch 52: accuracy on training set: 0.6413\n",
            "Epoch 52: loss on validation set: 0.6669\n",
            "Epoch 53: loss on final training batch: 0.5702\n",
            "Epoch 53: accuracy on validation set: 0.5928\n",
            "Epoch 53: accuracy on training set: 0.6392\n",
            "Epoch 53: loss on validation set: 0.6674\n",
            "Epoch 54: loss on final training batch: 0.5511\n",
            "Epoch 54: accuracy on validation set: 0.5893\n",
            "Epoch 54: accuracy on training set: 0.6438\n",
            "Epoch 54: loss on validation set: 0.6674\n",
            "Epoch 55: loss on final training batch: 0.5461\n",
            "Epoch 55: accuracy on validation set: 0.5958\n",
            "Epoch 55: accuracy on training set: 0.6448\n",
            "Epoch 55: loss on validation set: 0.6669\n",
            "Epoch 56: loss on final training batch: 0.5422\n",
            "Epoch 56: accuracy on validation set: 0.5913\n",
            "Epoch 56: accuracy on training set: 0.6465\n",
            "Epoch 56: loss on validation set: 0.6671\n",
            "Epoch 57: loss on final training batch: 0.5450\n",
            "Epoch 57: accuracy on validation set: 0.5953\n",
            "Epoch 57: accuracy on training set: 0.6495\n",
            "Epoch 57: loss on validation set: 0.6677\n",
            "Epoch 58: loss on final training batch: 0.5420\n",
            "Epoch 58: accuracy on validation set: 0.5930\n",
            "Epoch 58: accuracy on training set: 0.6501\n",
            "Epoch 58: loss on validation set: 0.6681\n",
            "Epoch 59: loss on final training batch: 0.5536\n",
            "Epoch 59: accuracy on validation set: 0.5912\n",
            "Epoch 59: accuracy on training set: 0.6448\n",
            "Epoch 59: loss on validation set: 0.6678\n",
            "Epoch 60: loss on final training batch: 0.5581\n",
            "Epoch 60: accuracy on validation set: 0.5923\n",
            "Epoch 60: accuracy on training set: 0.6529\n",
            "Epoch 60: loss on validation set: 0.6682\n",
            "Epoch 61: loss on final training batch: 0.5204\n",
            "Epoch 61: accuracy on validation set: 0.5918\n",
            "Epoch 61: accuracy on training set: 0.6501\n",
            "Epoch 61: loss on validation set: 0.6686\n",
            "Epoch 62: loss on final training batch: 0.5364\n",
            "Epoch 62: accuracy on validation set: 0.5897\n",
            "Epoch 62: accuracy on training set: 0.6483\n",
            "Epoch 62: loss on validation set: 0.6686\n",
            "Epoch 63: loss on final training batch: 0.5222\n",
            "Epoch 63: accuracy on validation set: 0.5908\n",
            "Epoch 63: accuracy on training set: 0.6509\n",
            "Epoch 63: loss on validation set: 0.6686\n",
            "Epoch 64: loss on final training batch: 0.5312\n",
            "Epoch 64: accuracy on validation set: 0.5945\n",
            "Epoch 64: accuracy on training set: 0.6507\n",
            "Epoch 64: loss on validation set: 0.6690\n",
            "Epoch 65: loss on final training batch: 0.5221\n",
            "Epoch 65: accuracy on validation set: 0.5947\n",
            "Epoch 65: accuracy on training set: 0.6547\n",
            "Epoch 65: loss on validation set: 0.6691\n",
            "Epoch 66: loss on final training batch: 0.5286\n",
            "Epoch 66: accuracy on validation set: 0.5912\n",
            "Epoch 66: accuracy on training set: 0.6542\n",
            "Epoch 66: loss on validation set: 0.6693\n",
            "Epoch 67: loss on final training batch: 0.5544\n",
            "Epoch 67: accuracy on validation set: 0.5932\n",
            "Epoch 67: accuracy on training set: 0.6545\n",
            "Epoch 67: loss on validation set: 0.6693\n",
            "Epoch 68: loss on final training batch: 0.5690\n",
            "Epoch 68: accuracy on validation set: 0.5925\n",
            "Epoch 68: accuracy on training set: 0.6564\n",
            "Epoch 68: loss on validation set: 0.6703\n",
            "Epoch 69: loss on final training batch: 0.5373\n",
            "Epoch 69: accuracy on validation set: 0.5937\n",
            "Epoch 69: accuracy on training set: 0.6603\n",
            "Epoch 69: loss on validation set: 0.6698\n",
            "Epoch 70: loss on final training batch: 0.5002\n",
            "Epoch 70: accuracy on validation set: 0.5945\n",
            "Epoch 70: accuracy on training set: 0.6548\n",
            "Epoch 70: loss on validation set: 0.6709\n",
            "Epoch 71: loss on final training batch: 0.5026\n",
            "Epoch 71: accuracy on validation set: 0.5957\n",
            "Epoch 71: accuracy on training set: 0.6624\n",
            "Epoch 71: loss on validation set: 0.6712\n",
            "Epoch 72: loss on final training batch: 0.5025\n",
            "Epoch 72: accuracy on validation set: 0.5960\n",
            "Epoch 72: accuracy on training set: 0.6600\n",
            "Epoch 72: loss on validation set: 0.6703\n",
            "Epoch 73: loss on final training batch: 0.5086\n",
            "Epoch 73: accuracy on validation set: 0.5927\n",
            "Epoch 73: accuracy on training set: 0.6545\n",
            "Epoch 73: loss on validation set: 0.6716\n",
            "Epoch 74: loss on final training batch: 0.5165\n",
            "Epoch 74: accuracy on validation set: 0.5940\n",
            "Epoch 74: accuracy on training set: 0.6561\n",
            "Epoch 74: loss on validation set: 0.6710\n",
            "Epoch 75: loss on final training batch: 0.5208\n",
            "Epoch 75: accuracy on validation set: 0.5908\n",
            "Epoch 75: accuracy on training set: 0.6570\n",
            "Epoch 75: loss on validation set: 0.6716\n",
            "Epoch 76: loss on final training batch: 0.5129\n",
            "Epoch 76: accuracy on validation set: 0.5903\n",
            "Epoch 76: accuracy on training set: 0.6570\n",
            "Epoch 76: loss on validation set: 0.6724\n",
            "Epoch 77: loss on final training batch: 0.5158\n",
            "Epoch 77: accuracy on validation set: 0.5910\n",
            "Epoch 77: accuracy on training set: 0.6561\n",
            "Epoch 77: loss on validation set: 0.6722\n",
            "Epoch 78: loss on final training batch: 0.5379\n",
            "Epoch 78: accuracy on validation set: 0.5883\n",
            "Epoch 78: accuracy on training set: 0.6567\n",
            "Epoch 78: loss on validation set: 0.6719\n",
            "Epoch 79: loss on final training batch: 0.5211\n",
            "Epoch 79: accuracy on validation set: 0.5887\n",
            "Epoch 79: accuracy on training set: 0.6564\n",
            "Epoch 79: loss on validation set: 0.6733\n",
            "Epoch 80: loss on final training batch: 0.5209\n",
            "Epoch 80: accuracy on validation set: 0.5900\n",
            "Epoch 80: accuracy on training set: 0.6605\n",
            "Epoch 80: loss on validation set: 0.6720\n",
            "Epoch 81: loss on final training batch: 0.5141\n",
            "Epoch 81: accuracy on validation set: 0.5905\n",
            "Epoch 81: accuracy on training set: 0.6583\n",
            "Epoch 81: loss on validation set: 0.6732\n",
            "Epoch 82: loss on final training batch: 0.4878\n",
            "Epoch 82: accuracy on validation set: 0.5935\n",
            "Epoch 82: accuracy on training set: 0.6616\n",
            "Epoch 82: loss on validation set: 0.6734\n",
            "Epoch 83: loss on final training batch: 0.5042\n",
            "Epoch 83: accuracy on validation set: 0.5877\n",
            "Epoch 83: accuracy on training set: 0.6640\n",
            "Epoch 83: loss on validation set: 0.6742\n",
            "Epoch 84: loss on final training batch: 0.5123\n",
            "Epoch 84: accuracy on validation set: 0.5873\n",
            "Epoch 84: accuracy on training set: 0.6621\n",
            "Epoch 84: loss on validation set: 0.6737\n",
            "Epoch 85: loss on final training batch: 0.5113\n",
            "Epoch 85: accuracy on validation set: 0.5892\n",
            "Epoch 85: accuracy on training set: 0.6605\n",
            "Epoch 85: loss on validation set: 0.6733\n",
            "Epoch 86: loss on final training batch: 0.4906\n",
            "Epoch 86: accuracy on validation set: 0.5898\n",
            "Epoch 86: accuracy on training set: 0.6656\n",
            "Epoch 86: loss on validation set: 0.6741\n",
            "Epoch 87: loss on final training batch: 0.5119\n",
            "Epoch 87: accuracy on validation set: 0.5900\n",
            "Epoch 87: accuracy on training set: 0.6604\n",
            "Epoch 87: loss on validation set: 0.6742\n",
            "Epoch 88: loss on final training batch: 0.4686\n",
            "Epoch 88: accuracy on validation set: 0.5880\n",
            "Epoch 88: accuracy on training set: 0.6597\n",
            "Epoch 88: loss on validation set: 0.6741\n",
            "Epoch 89: loss on final training batch: 0.4843\n",
            "Epoch 89: accuracy on validation set: 0.5883\n",
            "Epoch 89: accuracy on training set: 0.6659\n",
            "Epoch 89: loss on validation set: 0.6743\n",
            "Epoch 90: loss on final training batch: 0.5204\n",
            "Epoch 90: accuracy on validation set: 0.5915\n",
            "Epoch 90: accuracy on training set: 0.6640\n",
            "Epoch 90: loss on validation set: 0.6734\n",
            "Epoch 91: loss on final training batch: 0.4744\n",
            "Epoch 91: accuracy on validation set: 0.5898\n",
            "Epoch 91: accuracy on training set: 0.6651\n",
            "Epoch 91: loss on validation set: 0.6738\n",
            "Epoch 92: loss on final training batch: 0.4855\n",
            "Epoch 92: accuracy on validation set: 0.5872\n",
            "Epoch 92: accuracy on training set: 0.6635\n",
            "Epoch 92: loss on validation set: 0.6741\n",
            "Epoch 93: loss on final training batch: 0.4851\n",
            "Epoch 93: accuracy on validation set: 0.5910\n",
            "Epoch 93: accuracy on training set: 0.6640\n",
            "Epoch 93: loss on validation set: 0.6756\n",
            "Epoch 94: loss on final training batch: 0.4817\n",
            "Epoch 94: accuracy on validation set: 0.5967\n",
            "Epoch 94: accuracy on training set: 0.6684\n",
            "Epoch 94: loss on validation set: 0.6749\n",
            "Epoch 95: loss on final training batch: 0.4928\n",
            "Epoch 95: accuracy on validation set: 0.5898\n",
            "Epoch 95: accuracy on training set: 0.6652\n",
            "Epoch 95: loss on validation set: 0.6754\n",
            "Epoch 96: loss on final training batch: 0.4894\n",
            "Epoch 96: accuracy on validation set: 0.5917\n",
            "Epoch 96: accuracy on training set: 0.6637\n",
            "Epoch 96: loss on validation set: 0.6753\n",
            "Epoch 97: loss on final training batch: 0.4987\n",
            "Epoch 97: accuracy on validation set: 0.5910\n",
            "Epoch 97: accuracy on training set: 0.6648\n",
            "Epoch 97: loss on validation set: 0.6760\n",
            "Epoch 98: loss on final training batch: 0.5151\n",
            "Epoch 98: accuracy on validation set: 0.5898\n",
            "Epoch 98: accuracy on training set: 0.6655\n",
            "Epoch 98: loss on validation set: 0.6757\n",
            "Epoch 99: loss on final training batch: 0.4905\n",
            "Epoch 99: accuracy on validation set: 0.5940\n",
            "Epoch 99: accuracy on training set: 0.6681\n",
            "Epoch 99: loss on validation set: 0.6757\n",
            "Epoch 100: loss on final training batch: 0.4961\n",
            "Epoch 100: accuracy on validation set: 0.5928\n",
            "Epoch 100: accuracy on training set: 0.6649\n",
            "Epoch 100: loss on validation set: 0.6774\n",
            "Epoch 101: loss on final training batch: 0.4654\n",
            "Epoch 101: accuracy on validation set: 0.5937\n",
            "Epoch 101: accuracy on training set: 0.6706\n",
            "Epoch 101: loss on validation set: 0.6778\n",
            "Epoch 102: loss on final training batch: 0.4958\n",
            "Epoch 102: accuracy on validation set: 0.5940\n",
            "Epoch 102: accuracy on training set: 0.6677\n",
            "Epoch 102: loss on validation set: 0.6776\n",
            "Epoch 103: loss on final training batch: 0.4669\n",
            "Epoch 103: accuracy on validation set: 0.5928\n",
            "Epoch 103: accuracy on training set: 0.6638\n",
            "Epoch 103: loss on validation set: 0.6779\n",
            "Epoch 104: loss on final training batch: 0.4532\n",
            "Epoch 104: accuracy on validation set: 0.5928\n",
            "Epoch 104: accuracy on training set: 0.6712\n",
            "Epoch 104: loss on validation set: 0.6783\n",
            "Epoch 105: loss on final training batch: 0.4682\n",
            "Epoch 105: accuracy on validation set: 0.5917\n",
            "Epoch 105: accuracy on training set: 0.6686\n",
            "Epoch 105: loss on validation set: 0.6776\n",
            "Epoch 106: loss on final training batch: 0.4921\n",
            "Epoch 106: accuracy on validation set: 0.5953\n",
            "Epoch 106: accuracy on training set: 0.6685\n",
            "Epoch 106: loss on validation set: 0.6778\n",
            "Epoch 107: loss on final training batch: 0.4797\n",
            "Epoch 107: accuracy on validation set: 0.5927\n",
            "Epoch 107: accuracy on training set: 0.6699\n",
            "Epoch 107: loss on validation set: 0.6776\n",
            "Epoch 108: loss on final training batch: 0.4664\n",
            "Epoch 108: accuracy on validation set: 0.5920\n",
            "Epoch 108: accuracy on training set: 0.6700\n",
            "Epoch 108: loss on validation set: 0.6775\n",
            "Epoch 109: loss on final training batch: 0.4778\n",
            "Epoch 109: accuracy on validation set: 0.5902\n",
            "Epoch 109: accuracy on training set: 0.6686\n",
            "Epoch 109: loss on validation set: 0.6782\n",
            "Epoch 110: loss on final training batch: 0.4685\n",
            "Epoch 110: accuracy on validation set: 0.5885\n",
            "Epoch 110: accuracy on training set: 0.6726\n",
            "Epoch 110: loss on validation set: 0.6802\n",
            "Epoch 111: loss on final training batch: 0.4930\n",
            "Epoch 111: accuracy on validation set: 0.5895\n",
            "Epoch 111: accuracy on training set: 0.6662\n",
            "Epoch 111: loss on validation set: 0.6804\n",
            "Epoch 112: loss on final training batch: 0.4746\n",
            "Epoch 112: accuracy on validation set: 0.5890\n",
            "Epoch 112: accuracy on training set: 0.6675\n",
            "Epoch 112: loss on validation set: 0.6805\n",
            "Epoch 113: loss on final training batch: 0.4505\n",
            "Epoch 113: accuracy on validation set: 0.5900\n",
            "Epoch 113: accuracy on training set: 0.6727\n",
            "Epoch 113: loss on validation set: 0.6783\n",
            "Epoch 114: loss on final training batch: 0.4797\n",
            "Epoch 114: accuracy on validation set: 0.5887\n",
            "Epoch 114: accuracy on training set: 0.6677\n",
            "Epoch 114: loss on validation set: 0.6793\n",
            "Epoch 115: loss on final training batch: 0.4648\n",
            "Epoch 115: accuracy on validation set: 0.5882\n",
            "Epoch 115: accuracy on training set: 0.6729\n",
            "Epoch 115: loss on validation set: 0.6793\n",
            "Epoch 116: loss on final training batch: 0.4678\n",
            "Epoch 116: accuracy on validation set: 0.5888\n",
            "Epoch 116: accuracy on training set: 0.6727\n",
            "Epoch 116: loss on validation set: 0.6792\n",
            "Epoch 117: loss on final training batch: 0.4912\n",
            "Epoch 117: accuracy on validation set: 0.5882\n",
            "Epoch 117: accuracy on training set: 0.6711\n",
            "Epoch 117: loss on validation set: 0.6807\n",
            "Epoch 118: loss on final training batch: 0.4640\n",
            "Epoch 118: accuracy on validation set: 0.5888\n",
            "Epoch 118: accuracy on training set: 0.6723\n",
            "Epoch 118: loss on validation set: 0.6803\n",
            "Epoch 119: loss on final training batch: 0.4479\n",
            "Epoch 119: accuracy on validation set: 0.5888\n",
            "Epoch 119: accuracy on training set: 0.6763\n",
            "Epoch 119: loss on validation set: 0.6802\n",
            "Epoch 120: loss on final training batch: 0.4596\n",
            "Epoch 120: accuracy on validation set: 0.5918\n",
            "Epoch 120: accuracy on training set: 0.6728\n",
            "Epoch 120: loss on validation set: 0.6800\n",
            "Epoch 121: loss on final training batch: 0.4570\n",
            "Epoch 121: accuracy on validation set: 0.5892\n",
            "Epoch 121: accuracy on training set: 0.6761\n",
            "Epoch 121: loss on validation set: 0.6804\n",
            "Epoch 122: loss on final training batch: 0.4783\n",
            "Epoch 122: accuracy on validation set: 0.5893\n",
            "Epoch 122: accuracy on training set: 0.6741\n",
            "Epoch 122: loss on validation set: 0.6806\n",
            "Epoch 123: loss on final training batch: 0.4649\n",
            "Epoch 123: accuracy on validation set: 0.5930\n",
            "Epoch 123: accuracy on training set: 0.6710\n",
            "Epoch 123: loss on validation set: 0.6816\n",
            "Epoch 124: loss on final training batch: 0.4733\n",
            "Epoch 124: accuracy on validation set: 0.5930\n",
            "Epoch 124: accuracy on training set: 0.6736\n",
            "Epoch 124: loss on validation set: 0.6809\n",
            "Epoch 125: loss on final training batch: 0.4590\n",
            "Epoch 125: accuracy on validation set: 0.5920\n",
            "Epoch 125: accuracy on training set: 0.6740\n",
            "Epoch 125: loss on validation set: 0.6799\n",
            "Epoch 126: loss on final training batch: 0.4304\n",
            "Epoch 126: accuracy on validation set: 0.5928\n",
            "Epoch 126: accuracy on training set: 0.6731\n",
            "Epoch 126: loss on validation set: 0.6809\n",
            "Epoch 127: loss on final training batch: 0.4461\n",
            "Epoch 127: accuracy on validation set: 0.5927\n",
            "Epoch 127: accuracy on training set: 0.6734\n",
            "Epoch 127: loss on validation set: 0.6814\n",
            "Epoch 128: loss on final training batch: 0.4702\n",
            "Epoch 128: accuracy on validation set: 0.5925\n",
            "Epoch 128: accuracy on training set: 0.6719\n",
            "Epoch 128: loss on validation set: 0.6813\n",
            "Epoch 129: loss on final training batch: 0.4544\n",
            "Epoch 129: accuracy on validation set: 0.5963\n",
            "Epoch 129: accuracy on training set: 0.6799\n",
            "Epoch 129: loss on validation set: 0.6822\n",
            "Epoch 130: loss on final training batch: 0.4583\n",
            "Epoch 130: accuracy on validation set: 0.5922\n",
            "Epoch 130: accuracy on training set: 0.6739\n",
            "Epoch 130: loss on validation set: 0.6824\n",
            "Epoch 131: loss on final training batch: 0.4673\n",
            "Epoch 131: accuracy on validation set: 0.5907\n",
            "Epoch 131: accuracy on training set: 0.6728\n",
            "Epoch 131: loss on validation set: 0.6825\n",
            "Epoch 132: loss on final training batch: 0.4686\n",
            "Epoch 132: accuracy on validation set: 0.5893\n",
            "Epoch 132: accuracy on training set: 0.6761\n",
            "Epoch 132: loss on validation set: 0.6839\n",
            "Epoch 133: loss on final training batch: 0.4342\n",
            "Epoch 133: accuracy on validation set: 0.5905\n",
            "Epoch 133: accuracy on training set: 0.6766\n",
            "Epoch 133: loss on validation set: 0.6842\n",
            "Epoch 134: loss on final training batch: 0.4196\n",
            "Epoch 134: accuracy on validation set: 0.5885\n",
            "Epoch 134: accuracy on training set: 0.6745\n",
            "Epoch 134: loss on validation set: 0.6853\n",
            "Epoch 135: loss on final training batch: 0.4499\n",
            "Epoch 135: accuracy on validation set: 0.5878\n",
            "Epoch 135: accuracy on training set: 0.6783\n",
            "Epoch 135: loss on validation set: 0.6832\n",
            "Epoch 136: loss on final training batch: 0.4437\n",
            "Epoch 136: accuracy on validation set: 0.5870\n",
            "Epoch 136: accuracy on training set: 0.6791\n",
            "Epoch 136: loss on validation set: 0.6837\n",
            "Epoch 137: loss on final training batch: 0.5005\n",
            "Epoch 137: accuracy on validation set: 0.5885\n",
            "Epoch 137: accuracy on training set: 0.6749\n",
            "Epoch 137: loss on validation set: 0.6829\n",
            "Epoch 138: loss on final training batch: 0.4489\n",
            "Epoch 138: accuracy on validation set: 0.5927\n",
            "Epoch 138: accuracy on training set: 0.6736\n",
            "Epoch 138: loss on validation set: 0.6825\n",
            "Epoch 139: loss on final training batch: 0.4397\n",
            "Epoch 139: accuracy on validation set: 0.5935\n",
            "Epoch 139: accuracy on training set: 0.6774\n",
            "Epoch 139: loss on validation set: 0.6823\n",
            "Epoch 140: loss on final training batch: 0.4619\n",
            "Epoch 140: accuracy on validation set: 0.5918\n",
            "Epoch 140: accuracy on training set: 0.6759\n",
            "Epoch 140: loss on validation set: 0.6835\n",
            "Epoch 141: loss on final training batch: 0.4620\n",
            "Epoch 141: accuracy on validation set: 0.5892\n",
            "Epoch 141: accuracy on training set: 0.6774\n",
            "Epoch 141: loss on validation set: 0.6837\n",
            "Epoch 142: loss on final training batch: 0.4284\n",
            "Epoch 142: accuracy on validation set: 0.5918\n",
            "Epoch 142: accuracy on training set: 0.6809\n",
            "Epoch 142: loss on validation set: 0.6832\n",
            "Epoch 143: loss on final training batch: 0.4262\n",
            "Epoch 143: accuracy on validation set: 0.5898\n",
            "Epoch 143: accuracy on training set: 0.6802\n",
            "Epoch 143: loss on validation set: 0.6837\n",
            "Epoch 144: loss on final training batch: 0.4223\n",
            "Epoch 144: accuracy on validation set: 0.5927\n",
            "Epoch 144: accuracy on training set: 0.6743\n",
            "Epoch 144: loss on validation set: 0.6839\n",
            "Epoch 145: loss on final training batch: 0.4446\n",
            "Epoch 145: accuracy on validation set: 0.5915\n",
            "Epoch 145: accuracy on training set: 0.6821\n",
            "Epoch 145: loss on validation set: 0.6852\n",
            "Epoch 146: loss on final training batch: 0.4409\n",
            "Epoch 146: accuracy on validation set: 0.5922\n",
            "Epoch 146: accuracy on training set: 0.6789\n",
            "Epoch 146: loss on validation set: 0.6855\n",
            "Epoch 147: loss on final training batch: 0.4324\n",
            "Epoch 147: accuracy on validation set: 0.5898\n",
            "Epoch 147: accuracy on training set: 0.6762\n",
            "Epoch 147: loss on validation set: 0.6863\n",
            "Epoch 148: loss on final training batch: 0.4347\n",
            "Epoch 148: accuracy on validation set: 0.5902\n",
            "Epoch 148: accuracy on training set: 0.6772\n",
            "Epoch 148: loss on validation set: 0.6859\n",
            "Epoch 149: loss on final training batch: 0.4277\n",
            "Epoch 149: accuracy on validation set: 0.5872\n",
            "Epoch 149: accuracy on training set: 0.6759\n",
            "Epoch 149: loss on validation set: 0.6881\n",
            "Epoch 150: loss on final training batch: 0.4008\n",
            "Epoch 150: accuracy on validation set: 0.5857\n",
            "Epoch 150: accuracy on training set: 0.6825\n",
            "Epoch 150: loss on validation set: 0.6879\n",
            "Epoch 151: loss on final training batch: 0.4191\n",
            "Epoch 151: accuracy on validation set: 0.5868\n",
            "Epoch 151: accuracy on training set: 0.6784\n",
            "Epoch 151: loss on validation set: 0.6885\n",
            "Epoch 152: loss on final training batch: 0.4493\n",
            "Epoch 152: accuracy on validation set: 0.5888\n",
            "Epoch 152: accuracy on training set: 0.6787\n",
            "Epoch 152: loss on validation set: 0.6877\n",
            "Epoch 153: loss on final training batch: 0.4335\n",
            "Epoch 153: accuracy on validation set: 0.5870\n",
            "Epoch 153: accuracy on training set: 0.6838\n",
            "Epoch 153: loss on validation set: 0.6869\n",
            "Epoch 154: loss on final training batch: 0.4418\n",
            "Epoch 154: accuracy on validation set: 0.5843\n",
            "Epoch 154: accuracy on training set: 0.6856\n",
            "Epoch 154: loss on validation set: 0.6884\n",
            "Epoch 155: loss on final training batch: 0.4253\n",
            "Epoch 155: accuracy on validation set: 0.5852\n",
            "Epoch 155: accuracy on training set: 0.6810\n",
            "Epoch 155: loss on validation set: 0.6873\n",
            "Epoch 156: loss on final training batch: 0.4265\n",
            "Epoch 156: accuracy on validation set: 0.5872\n",
            "Epoch 156: accuracy on training set: 0.6830\n",
            "Epoch 156: loss on validation set: 0.6868\n",
            "Epoch 157: loss on final training batch: 0.3935\n",
            "Epoch 157: accuracy on validation set: 0.5840\n",
            "Epoch 157: accuracy on training set: 0.6817\n",
            "Epoch 157: loss on validation set: 0.6875\n",
            "Epoch 158: loss on final training batch: 0.4337\n",
            "Epoch 158: accuracy on validation set: 0.5863\n",
            "Epoch 158: accuracy on training set: 0.6810\n",
            "Epoch 158: loss on validation set: 0.6873\n",
            "Epoch 159: loss on final training batch: 0.4438\n",
            "Epoch 159: accuracy on validation set: 0.5867\n",
            "Epoch 159: accuracy on training set: 0.6814\n",
            "Epoch 159: loss on validation set: 0.6879\n",
            "Epoch 160: loss on final training batch: 0.4130\n",
            "Epoch 160: accuracy on validation set: 0.5853\n",
            "Epoch 160: accuracy on training set: 0.6776\n",
            "Epoch 160: loss on validation set: 0.6897\n",
            "Epoch 161: loss on final training batch: 0.4558\n",
            "Epoch 161: accuracy on validation set: 0.5843\n",
            "Epoch 161: accuracy on training set: 0.6788\n",
            "Epoch 161: loss on validation set: 0.6899\n",
            "Epoch 162: loss on final training batch: 0.4223\n",
            "Epoch 162: accuracy on validation set: 0.5855\n",
            "Epoch 162: accuracy on training set: 0.6825\n",
            "Epoch 162: loss on validation set: 0.6888\n",
            "Epoch 163: loss on final training batch: 0.3954\n",
            "Epoch 163: accuracy on validation set: 0.5820\n",
            "Epoch 163: accuracy on training set: 0.6870\n",
            "Epoch 163: loss on validation set: 0.6893\n",
            "Epoch 164: loss on final training batch: 0.4540\n",
            "Epoch 164: accuracy on validation set: 0.5805\n",
            "Epoch 164: accuracy on training set: 0.6810\n",
            "Epoch 164: loss on validation set: 0.6899\n",
            "Epoch 165: loss on final training batch: 0.4357\n",
            "Epoch 165: accuracy on validation set: 0.5828\n",
            "Epoch 165: accuracy on training set: 0.6871\n",
            "Epoch 165: loss on validation set: 0.6908\n",
            "Epoch 166: loss on final training batch: 0.4471\n",
            "Epoch 166: accuracy on validation set: 0.5840\n",
            "Epoch 166: accuracy on training set: 0.6837\n",
            "Epoch 166: loss on validation set: 0.6914\n",
            "Epoch 167: loss on final training batch: 0.4094\n",
            "Epoch 167: accuracy on validation set: 0.5822\n",
            "Epoch 167: accuracy on training set: 0.6929\n",
            "Epoch 167: loss on validation set: 0.6911\n",
            "Epoch 168: loss on final training batch: 0.4192\n",
            "Epoch 168: accuracy on validation set: 0.5823\n",
            "Epoch 168: accuracy on training set: 0.6833\n",
            "Epoch 168: loss on validation set: 0.6904\n",
            "Epoch 169: loss on final training batch: 0.4280\n",
            "Epoch 169: accuracy on validation set: 0.5847\n",
            "Epoch 169: accuracy on training set: 0.6835\n",
            "Epoch 169: loss on validation set: 0.6906\n",
            "Epoch 170: loss on final training batch: 0.4322\n",
            "Epoch 170: accuracy on validation set: 0.5867\n",
            "Epoch 170: accuracy on training set: 0.6880\n",
            "Epoch 170: loss on validation set: 0.6908\n",
            "Epoch 171: loss on final training batch: 0.4183\n",
            "Epoch 171: accuracy on validation set: 0.5827\n",
            "Epoch 171: accuracy on training set: 0.6862\n",
            "Epoch 171: loss on validation set: 0.6918\n",
            "Epoch 172: loss on final training batch: 0.4205\n",
            "Epoch 172: accuracy on validation set: 0.5843\n",
            "Epoch 172: accuracy on training set: 0.6826\n",
            "Epoch 172: loss on validation set: 0.6914\n",
            "Epoch 173: loss on final training batch: 0.4348\n",
            "Epoch 173: accuracy on validation set: 0.5827\n",
            "Epoch 173: accuracy on training set: 0.6820\n",
            "Epoch 173: loss on validation set: 0.6913\n",
            "Epoch 174: loss on final training batch: 0.4112\n",
            "Epoch 174: accuracy on validation set: 0.5857\n",
            "Epoch 174: accuracy on training set: 0.6860\n",
            "Epoch 174: loss on validation set: 0.6905\n",
            "Epoch 175: loss on final training batch: 0.4196\n",
            "Epoch 175: accuracy on validation set: 0.5852\n",
            "Epoch 175: accuracy on training set: 0.6877\n",
            "Epoch 175: loss on validation set: 0.6913\n",
            "Epoch 176: loss on final training batch: 0.4240\n",
            "Epoch 176: accuracy on validation set: 0.5807\n",
            "Epoch 176: accuracy on training set: 0.6889\n",
            "Epoch 176: loss on validation set: 0.6929\n",
            "Epoch 177: loss on final training batch: 0.4101\n",
            "Epoch 177: accuracy on validation set: 0.5797\n",
            "Epoch 177: accuracy on training set: 0.6845\n",
            "Epoch 177: loss on validation set: 0.6945\n",
            "Epoch 178: loss on final training batch: 0.4384\n",
            "Epoch 178: accuracy on validation set: 0.5828\n",
            "Epoch 178: accuracy on training set: 0.6902\n",
            "Epoch 178: loss on validation set: 0.6944\n",
            "Epoch 179: loss on final training batch: 0.3954\n",
            "Epoch 179: accuracy on validation set: 0.5805\n",
            "Epoch 179: accuracy on training set: 0.6850\n",
            "Epoch 179: loss on validation set: 0.6936\n",
            "Epoch 180: loss on final training batch: 0.4119\n",
            "Epoch 180: accuracy on validation set: 0.5793\n",
            "Epoch 180: accuracy on training set: 0.6919\n",
            "Epoch 180: loss on validation set: 0.6957\n",
            "Epoch 181: loss on final training batch: 0.4118\n",
            "Epoch 181: accuracy on validation set: 0.5817\n",
            "Epoch 181: accuracy on training set: 0.6886\n",
            "Epoch 181: loss on validation set: 0.6940\n",
            "Epoch 182: loss on final training batch: 0.4335\n",
            "Epoch 182: accuracy on validation set: 0.5803\n",
            "Epoch 182: accuracy on training set: 0.6901\n",
            "Epoch 182: loss on validation set: 0.6964\n",
            "Epoch 183: loss on final training batch: 0.4142\n",
            "Epoch 183: accuracy on validation set: 0.5813\n",
            "Epoch 183: accuracy on training set: 0.6848\n",
            "Epoch 183: loss on validation set: 0.6970\n",
            "Epoch 184: loss on final training batch: 0.4305\n",
            "Epoch 184: accuracy on validation set: 0.5812\n",
            "Epoch 184: accuracy on training set: 0.6891\n",
            "Epoch 184: loss on validation set: 0.6976\n",
            "Epoch 185: loss on final training batch: 0.3950\n",
            "Epoch 185: accuracy on validation set: 0.5842\n",
            "Epoch 185: accuracy on training set: 0.6906\n",
            "Epoch 185: loss on validation set: 0.6963\n",
            "Epoch 186: loss on final training batch: 0.4021\n",
            "Epoch 186: accuracy on validation set: 0.5830\n",
            "Epoch 186: accuracy on training set: 0.6908\n",
            "Epoch 186: loss on validation set: 0.6964\n",
            "Epoch 187: loss on final training batch: 0.3964\n",
            "Epoch 187: accuracy on validation set: 0.5828\n",
            "Epoch 187: accuracy on training set: 0.6843\n",
            "Epoch 187: loss on validation set: 0.6961\n",
            "Epoch 188: loss on final training batch: 0.4130\n",
            "Epoch 188: accuracy on validation set: 0.5830\n",
            "Epoch 188: accuracy on training set: 0.6892\n",
            "Epoch 188: loss on validation set: 0.6976\n",
            "Epoch 189: loss on final training batch: 0.4083\n",
            "Epoch 189: accuracy on validation set: 0.5823\n",
            "Epoch 189: accuracy on training set: 0.6876\n",
            "Epoch 189: loss on validation set: 0.6964\n",
            "Epoch 190: loss on final training batch: 0.4202\n",
            "Epoch 190: accuracy on validation set: 0.5820\n",
            "Epoch 190: accuracy on training set: 0.6893\n",
            "Epoch 190: loss on validation set: 0.6960\n",
            "Epoch 191: loss on final training batch: 0.4252\n",
            "Epoch 191: accuracy on validation set: 0.5843\n",
            "Epoch 191: accuracy on training set: 0.6869\n",
            "Epoch 191: loss on validation set: 0.6982\n",
            "Epoch 192: loss on final training batch: 0.3918\n",
            "Epoch 192: accuracy on validation set: 0.5847\n",
            "Epoch 192: accuracy on training set: 0.6893\n",
            "Epoch 192: loss on validation set: 0.6981\n",
            "Epoch 193: loss on final training batch: 0.4303\n",
            "Epoch 193: accuracy on validation set: 0.5808\n",
            "Epoch 193: accuracy on training set: 0.6850\n",
            "Epoch 193: loss on validation set: 0.6989\n",
            "Epoch 194: loss on final training batch: 0.4078\n",
            "Epoch 194: accuracy on validation set: 0.5797\n",
            "Epoch 194: accuracy on training set: 0.6890\n",
            "Epoch 194: loss on validation set: 0.6983\n",
            "Epoch 195: loss on final training batch: 0.4132\n",
            "Epoch 195: accuracy on validation set: 0.5803\n",
            "Epoch 195: accuracy on training set: 0.6904\n",
            "Epoch 195: loss on validation set: 0.6984\n",
            "Epoch 196: loss on final training batch: 0.3987\n",
            "Epoch 196: accuracy on validation set: 0.5790\n",
            "Epoch 196: accuracy on training set: 0.6907\n",
            "Epoch 196: loss on validation set: 0.6986\n",
            "Epoch 197: loss on final training batch: 0.3900\n",
            "Epoch 197: accuracy on validation set: 0.5817\n",
            "Epoch 197: accuracy on training set: 0.6930\n",
            "Epoch 197: loss on validation set: 0.6985\n",
            "Epoch 198: loss on final training batch: 0.4225\n",
            "Epoch 198: accuracy on validation set: 0.5823\n",
            "Epoch 198: accuracy on training set: 0.6911\n",
            "Epoch 198: loss on validation set: 0.6990\n",
            "Epoch 199: loss on final training batch: 0.3956\n",
            "Epoch 199: accuracy on validation set: 0.5843\n",
            "Epoch 199: accuracy on training set: 0.6946\n",
            "Epoch 199: loss on validation set: 0.6987\n",
            "Epoch 200: loss on final training batch: 0.4323\n",
            "Epoch 200: accuracy on validation set: 0.5813\n",
            "Epoch 200: accuracy on training set: 0.6884\n",
            "Epoch 200: loss on validation set: 0.6992\n",
            "Epoch 201: loss on final training batch: 0.4080\n",
            "Epoch 201: accuracy on validation set: 0.5792\n",
            "Epoch 201: accuracy on training set: 0.6873\n",
            "Epoch 201: loss on validation set: 0.7009\n",
            "Epoch 202: loss on final training batch: 0.4201\n",
            "Epoch 202: accuracy on validation set: 0.5775\n",
            "Epoch 202: accuracy on training set: 0.6914\n",
            "Epoch 202: loss on validation set: 0.7012\n",
            "Epoch 203: loss on final training batch: 0.4037\n",
            "Epoch 203: accuracy on validation set: 0.5803\n",
            "Epoch 203: accuracy on training set: 0.6894\n",
            "Epoch 203: loss on validation set: 0.7004\n",
            "Epoch 204: loss on final training batch: 0.4080\n",
            "Epoch 204: accuracy on validation set: 0.5783\n",
            "Epoch 204: accuracy on training set: 0.6947\n",
            "Epoch 204: loss on validation set: 0.7018\n",
            "Epoch 205: loss on final training batch: 0.4155\n",
            "Epoch 205: accuracy on validation set: 0.5782\n",
            "Epoch 205: accuracy on training set: 0.6889\n",
            "Epoch 205: loss on validation set: 0.7013\n",
            "Epoch 206: loss on final training batch: 0.3962\n",
            "Epoch 206: accuracy on validation set: 0.5803\n",
            "Epoch 206: accuracy on training set: 0.6848\n",
            "Epoch 206: loss on validation set: 0.7009\n",
            "Epoch 207: loss on final training batch: 0.4170\n",
            "Epoch 207: accuracy on validation set: 0.5790\n",
            "Epoch 207: accuracy on training set: 0.6924\n",
            "Epoch 207: loss on validation set: 0.7001\n",
            "Epoch 208: loss on final training batch: 0.4008\n",
            "Epoch 208: accuracy on validation set: 0.5803\n",
            "Epoch 208: accuracy on training set: 0.6946\n",
            "Epoch 208: loss on validation set: 0.7025\n",
            "Epoch 209: loss on final training batch: 0.4163\n",
            "Epoch 209: accuracy on validation set: 0.5767\n",
            "Epoch 209: accuracy on training set: 0.6880\n",
            "Epoch 209: loss on validation set: 0.7033\n",
            "Epoch 210: loss on final training batch: 0.4377\n",
            "Epoch 210: accuracy on validation set: 0.5760\n",
            "Epoch 210: accuracy on training set: 0.6919\n",
            "Epoch 210: loss on validation set: 0.7022\n",
            "Epoch 211: loss on final training batch: 0.3829\n",
            "Epoch 211: accuracy on validation set: 0.5777\n",
            "Epoch 211: accuracy on training set: 0.6925\n",
            "Epoch 211: loss on validation set: 0.7026\n",
            "Epoch 212: loss on final training batch: 0.3976\n",
            "Epoch 212: accuracy on validation set: 0.5788\n",
            "Epoch 212: accuracy on training set: 0.6902\n",
            "Epoch 212: loss on validation set: 0.7029\n",
            "Epoch 213: loss on final training batch: 0.3941\n",
            "Epoch 213: accuracy on validation set: 0.5773\n",
            "Epoch 213: accuracy on training set: 0.6899\n",
            "Epoch 213: loss on validation set: 0.7028\n",
            "Epoch 214: loss on final training batch: 0.4071\n",
            "Epoch 214: accuracy on validation set: 0.5778\n",
            "Epoch 214: accuracy on training set: 0.6898\n",
            "Epoch 214: loss on validation set: 0.7028\n",
            "Epoch 215: loss on final training batch: 0.3862\n",
            "Epoch 215: accuracy on validation set: 0.5787\n",
            "Epoch 215: accuracy on training set: 0.6896\n",
            "Epoch 215: loss on validation set: 0.7035\n",
            "Epoch 216: loss on final training batch: 0.4001\n",
            "Epoch 216: accuracy on validation set: 0.5762\n",
            "Epoch 216: accuracy on training set: 0.6904\n",
            "Epoch 216: loss on validation set: 0.7036\n",
            "Epoch 217: loss on final training batch: 0.3848\n",
            "Epoch 217: accuracy on validation set: 0.5770\n",
            "Epoch 217: accuracy on training set: 0.6900\n",
            "Epoch 217: loss on validation set: 0.7042\n",
            "Epoch 218: loss on final training batch: 0.4154\n",
            "Epoch 218: accuracy on validation set: 0.5758\n",
            "Epoch 218: accuracy on training set: 0.6913\n",
            "Epoch 218: loss on validation set: 0.7040\n",
            "Epoch 219: loss on final training batch: 0.4116\n",
            "Epoch 219: accuracy on validation set: 0.5733\n",
            "Epoch 219: accuracy on training set: 0.6889\n",
            "Epoch 219: loss on validation set: 0.7046\n",
            "Epoch 220: loss on final training batch: 0.4112\n",
            "Epoch 220: accuracy on validation set: 0.5758\n",
            "Epoch 220: accuracy on training set: 0.6914\n",
            "Epoch 220: loss on validation set: 0.7050\n",
            "Epoch 221: loss on final training batch: 0.3621\n",
            "Epoch 221: accuracy on validation set: 0.5807\n",
            "Epoch 221: accuracy on training set: 0.6934\n",
            "Epoch 221: loss on validation set: 0.7045\n",
            "Epoch 222: loss on final training batch: 0.4235\n",
            "Epoch 222: accuracy on validation set: 0.5792\n",
            "Epoch 222: accuracy on training set: 0.6964\n",
            "Epoch 222: loss on validation set: 0.7063\n",
            "Epoch 223: loss on final training batch: 0.3684\n",
            "Epoch 223: accuracy on validation set: 0.5768\n",
            "Epoch 223: accuracy on training set: 0.6950\n",
            "Epoch 223: loss on validation set: 0.7062\n",
            "Epoch 224: loss on final training batch: 0.3962\n",
            "Epoch 224: accuracy on validation set: 0.5773\n",
            "Epoch 224: accuracy on training set: 0.6912\n",
            "Epoch 224: loss on validation set: 0.7075\n",
            "Epoch 225: loss on final training batch: 0.3971\n",
            "Epoch 225: accuracy on validation set: 0.5735\n",
            "Epoch 225: accuracy on training set: 0.6988\n",
            "Epoch 225: loss on validation set: 0.7087\n",
            "Epoch 226: loss on final training batch: 0.4266\n",
            "Epoch 226: accuracy on validation set: 0.5805\n",
            "Epoch 226: accuracy on training set: 0.6961\n",
            "Epoch 226: loss on validation set: 0.7081\n",
            "Epoch 227: loss on final training batch: 0.4069\n",
            "Epoch 227: accuracy on validation set: 0.5792\n",
            "Epoch 227: accuracy on training set: 0.6973\n",
            "Epoch 227: loss on validation set: 0.7091\n",
            "Epoch 228: loss on final training batch: 0.3806\n",
            "Epoch 228: accuracy on validation set: 0.5788\n",
            "Epoch 228: accuracy on training set: 0.6884\n",
            "Epoch 228: loss on validation set: 0.7086\n",
            "Epoch 229: loss on final training batch: 0.4157\n",
            "Epoch 229: accuracy on validation set: 0.5758\n",
            "Epoch 229: accuracy on training set: 0.6915\n",
            "Epoch 229: loss on validation set: 0.7095\n",
            "Epoch 230: loss on final training batch: 0.4120\n",
            "Epoch 230: accuracy on validation set: 0.5760\n",
            "Epoch 230: accuracy on training set: 0.6942\n",
            "Epoch 230: loss on validation set: 0.7091\n",
            "Epoch 231: loss on final training batch: 0.3964\n",
            "Epoch 231: accuracy on validation set: 0.5755\n",
            "Epoch 231: accuracy on training set: 0.6942\n",
            "Epoch 231: loss on validation set: 0.7078\n",
            "Epoch 232: loss on final training batch: 0.3998\n",
            "Epoch 232: accuracy on validation set: 0.5773\n",
            "Epoch 232: accuracy on training set: 0.6936\n",
            "Epoch 232: loss on validation set: 0.7067\n",
            "Epoch 233: loss on final training batch: 0.3935\n",
            "Epoch 233: accuracy on validation set: 0.5742\n",
            "Epoch 233: accuracy on training set: 0.6953\n",
            "Epoch 233: loss on validation set: 0.7074\n",
            "Epoch 234: loss on final training batch: 0.3797\n",
            "Epoch 234: accuracy on validation set: 0.5730\n",
            "Epoch 234: accuracy on training set: 0.6985\n",
            "Epoch 234: loss on validation set: 0.7090\n",
            "Epoch 235: loss on final training batch: 0.4059\n",
            "Epoch 235: accuracy on validation set: 0.5765\n",
            "Epoch 235: accuracy on training set: 0.6978\n",
            "Epoch 235: loss on validation set: 0.7081\n",
            "Epoch 236: loss on final training batch: 0.3923\n",
            "Epoch 236: accuracy on validation set: 0.5733\n",
            "Epoch 236: accuracy on training set: 0.6929\n",
            "Epoch 236: loss on validation set: 0.7081\n",
            "Epoch 237: loss on final training batch: 0.4022\n",
            "Epoch 237: accuracy on validation set: 0.5740\n",
            "Epoch 237: accuracy on training set: 0.6956\n",
            "Epoch 237: loss on validation set: 0.7100\n",
            "Epoch 238: loss on final training batch: 0.3814\n",
            "Epoch 238: accuracy on validation set: 0.5742\n",
            "Epoch 238: accuracy on training set: 0.6938\n",
            "Epoch 238: loss on validation set: 0.7103\n",
            "Epoch 239: loss on final training batch: 0.3498\n",
            "Epoch 239: accuracy on validation set: 0.5747\n",
            "Epoch 239: accuracy on training set: 0.6952\n",
            "Epoch 239: loss on validation set: 0.7095\n",
            "Epoch 240: loss on final training batch: 0.3772\n",
            "Epoch 240: accuracy on validation set: 0.5740\n",
            "Epoch 240: accuracy on training set: 0.6959\n",
            "Epoch 240: loss on validation set: 0.7089\n",
            "Epoch 241: loss on final training batch: 0.3917\n",
            "Epoch 241: accuracy on validation set: 0.5727\n",
            "Epoch 241: accuracy on training set: 0.6984\n",
            "Epoch 241: loss on validation set: 0.7104\n",
            "Epoch 242: loss on final training batch: 0.3675\n",
            "Epoch 242: accuracy on validation set: 0.5705\n",
            "Epoch 242: accuracy on training set: 0.6966\n",
            "Epoch 242: loss on validation set: 0.7103\n",
            "Epoch 243: loss on final training batch: 0.3895\n",
            "Epoch 243: accuracy on validation set: 0.5727\n",
            "Epoch 243: accuracy on training set: 0.6982\n",
            "Epoch 243: loss on validation set: 0.7117\n",
            "Epoch 244: loss on final training batch: 0.3913\n",
            "Epoch 244: accuracy on validation set: 0.5722\n",
            "Epoch 244: accuracy on training set: 0.6974\n",
            "Epoch 244: loss on validation set: 0.7106\n",
            "Epoch 245: loss on final training batch: 0.3749\n",
            "Epoch 245: accuracy on validation set: 0.5688\n",
            "Epoch 245: accuracy on training set: 0.6992\n",
            "Epoch 245: loss on validation set: 0.7106\n",
            "Epoch 246: loss on final training batch: 0.4021\n",
            "Epoch 246: accuracy on validation set: 0.5695\n",
            "Epoch 246: accuracy on training set: 0.6997\n",
            "Epoch 246: loss on validation set: 0.7121\n",
            "Epoch 247: loss on final training batch: 0.3978\n",
            "Epoch 247: accuracy on validation set: 0.5733\n",
            "Epoch 247: accuracy on training set: 0.6962\n",
            "Epoch 247: loss on validation set: 0.7114\n",
            "Epoch 248: loss on final training batch: 0.4061\n",
            "Epoch 248: accuracy on validation set: 0.5718\n",
            "Epoch 248: accuracy on training set: 0.6952\n",
            "Epoch 248: loss on validation set: 0.7119\n",
            "Epoch 249: loss on final training batch: 0.3721\n",
            "Epoch 249: accuracy on validation set: 0.5750\n",
            "Epoch 249: accuracy on training set: 0.6989\n",
            "Epoch 249: loss on validation set: 0.7122\n",
            "Epoch 250: loss on final training batch: 0.3581\n",
            "Epoch 250: accuracy on validation set: 0.5712\n",
            "Epoch 250: accuracy on training set: 0.6996\n",
            "Epoch 250: loss on validation set: 0.7123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test accuracy on test set \n",
        "dire_X =  torch.index_select(X_test, 1, torch.LongTensor([*range(113,226)]))\n",
        "dire_X = torch.cat((dire_X,torch.index_select(X_test, 1, torch.LongTensor([*range(0,113)]))),1).to(device)\n",
        "dire_pred = (model(dire_X) >= 0).float()\n",
        "rad_pred = (model(X_test.to(device)) >= 0).float()\n",
        "\n",
        "#calulate as display accuracy with overall prob calc\n",
        "overall_prob = (((rad_pred + (1 - dire_pred))/2) > 0.5).float()\n",
        "acc = torch.mean((overall_prob.to(device) == y_test.to(device)).float())\n",
        "print(\"test accuracy\", acc.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNvnK4nqdwcR",
        "outputId": "be8fab4d-ce15-4e3f-83b3-9bbfb5a5e6e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy 0.5654000043869019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Experimental Results**\n"
      ],
      "metadata": {
        "id": "BRL5KR20QWKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After running the models through both versions of dataset the following accuracy and loss graphs can be made using matplotlib."
      ],
      "metadata": {
        "id": "-S__LR_gznWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "6Xmbjann0GZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plots of accuracy and loss for model 1 on API data:"
      ],
      "metadata": {
        "id": "1oK2NxLd5E05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5));\n",
        "ax1.plot(epochs_1,new_model1_val_loss, label='validation loss')\n",
        "ax1.plot(epochs_1,new_model1_train_loss, label='train loss')\n",
        "ax1.set_title('validation and train loss of model 1 on API data')\n",
        "ax1.legend();\n",
        "\n",
        "ax2.plot(epochs_1,new_model1_val_acc, label='validation accuracy')\n",
        "ax2.plot(epochs_1,new_model1_train_acc, label='train accuracy')\n",
        "ax2.set_title('validation and train accuracy of model 1 on API data')\n",
        "ax2.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "lB2p0RYU4j_u",
        "outputId": "89017015-4c1e-4050-e4cb-be51cd30ed21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Analysis: It can be seen with the graphs that after the 100th epoch the loss tends to separate from eachother, however accuracy of the model of both validation and training sets tends to be similar up until the 200th epoch. The accuracy of this model still needs to be improve in order to produce better predictions. "
      ],
      "metadata": {
        "id": "NFpBbKXp8Qjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plots of accuracy and loss for model 2 on API data:"
      ],
      "metadata": {
        "id": "UYVZtrSV5MJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure();\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5));\n",
        "ax1.plot(epochs_2,new_model2_val_loss, label='validation loss')\n",
        "ax1.plot(epochs_2,new_model2_train_loss, label='train loss')\n",
        "ax1.set_title('validation and train loss of model 2 on API data')\n",
        "ax1.legend();\n",
        "\n",
        "ax2.plot(epochs_2,new_model2_val_acc, label='validation accuracy')\n",
        "ax2.plot(epochs_2,new_model2_train_acc, label='train accuracy')\n",
        "ax2.set_title('validation and train accuracy of model 2 on API data')\n",
        "ax2.legend();\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "39LHPC9p0-Si",
        "outputId": "7a5f6494-f452-47f8-efc3-215261300f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Analysis: It can be seen by the graphs that there is a great decrease in training loss while validation loss stagnates, this is a symptom of overfitting even with the early stopping mechnism being used. However one beneficial insight into a model like this is that there is a gradual improvement to the training accuracy. Meaning that model is able to find trends in the data to make accurate predictions, therefore making it more of a regularization problem to solve.  "
      ],
      "metadata": {
        "id": "zx6_maApAlBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plots of accuracy and loss for model 1 on Kaggle data:"
      ],
      "metadata": {
        "id": "xEWj76rI5Qd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n",
        "ax1.plot(epochs_3,old_model1_val_loss, label='validation loss')\n",
        "ax1.plot(epochs_3,old_model1_train_loss, label='train loss')\n",
        "ax1.set_title('validation and train loss of model 1 on API data')\n",
        "ax1.legend();\n",
        "\n",
        "ax2.plot(epochs_3,old_model1_val_acc, label='validation accuracy')\n",
        "ax2.plot(epochs_3,old_model1_train_acc, label='train accuracy')\n",
        "ax2.set_title('validation and train accuracy of model 1 on API data')\n",
        "ax2.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "62cnPHzi4yKg",
        "outputId": "3540d299-dbc0-40b8-ac8f-b255d9a34cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Analysis: In comparison to the model 1 being used on the API dataset, there is much improvement in both loss and accuracy for the kaggle dataset. Both the validation and training losses trend in the same direction until validation loss stagnates around the 200th epoch. As for accuracy it also trends in the same direction and stabilize around the same time as well. Tuning of the hyperparameter could potential allow this solution to reach better predictions, without adding complexity to the model.  "
      ],
      "metadata": {
        "id": "CLVO9DLGJM3e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plots of accuracy and loss for model 3 on Kaggle data:"
      ],
      "metadata": {
        "id": "iQz_WAk85iEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n",
        "ax1.plot(epochs_4,old_model3_val_loss, label='validation loss')\n",
        "ax1.plot(epochs_4,old_model3_train_loss, label='train loss')\n",
        "ax1.set_title('validation and train loss of model 1 on API data')\n",
        "ax1.legend();\n",
        "\n",
        "ax2.plot(epochs_4,old_model3_val_acc, label='validation accuracy')\n",
        "ax2.plot(epochs_4,old_model3_train_acc, label='train accuracy')\n",
        "ax2.set_title('validation and train accuracy of model 1 on API data')\n",
        "ax2.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "nn_1BTdc4xiq",
        "outputId": "ae6565f8-e98f-4f70-834b-9b9f6f5c8022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Analysis: Once again there is a trend of overfitting within the more complex model, even with the simpler feature vector the Kaggle dataset provides. However in this case both accuracies are rather good even if the model has poor generalization. For a future model thats goal is to correctly predict DOTA2 matches, this one may be the most promising to develop as it as the validation and test accuracy can be improved through more regularization."
      ],
      "metadata": {
        "id": "iEgLN2vaLXtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Table of Models and Their Scores\n",
        "> ![model 1](https://drive.google.com/uc?export=view&id=1tafk8xog7wk-dfgtz5dOF0jh8hJdCGWd) \n",
        "\n",
        "\n",
        "From this table it can seen that the models had better performance on the feature vectors produced from the older match data of the Kaggle dataset. The worst performing model was the complex M2 model taking in a input of data from recent matches from the API, however with the previous anaylsis of the graphs it was more likely to be caused by an overfitting issue. The models ran on the old kaggle data set are the ones that are closest to the results of the Standford Project [1], which furthers the narrative that a problem solution of this nature may be increasing in difficulty as new heroes are added to the game. However these issues may be minimized with the implemenation of improved regularization techniques, and hyperparameter tuning and searching, which will bring the loss and accuracy of the validation sets closer to that of the training set.\n"
      ],
      "metadata": {
        "id": "B6ImS3TcM-6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusions**\n",
        "\n",
        "Summarize what you could and could not conclude based on your experiments. \n",
        "In this section, you can add **text**.\n",
        "\n"
      ],
      "metadata": {
        "id": "b4Jyn3BcQDpf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To summarise from the findings of this project, the proposed goal of a model with a prediction accuracy of 70% was not reached. However, with further developments of the models through regularization technique and hyperparameter tuning, there can still be a promising solution at hand. One conclusion that can be made is that the results of the models, in comparison to each other, reveal a trend, which is that as DOTA2 receives updates, many of which including new heroes, it becomes more difficult to accurately predict match outcomes with hero picks alone. Thus future developments to the feature vector in order for it to include more factors such as bans, and pick order could allow the models to come to a correct decisision more consistently. \n",
        "\n",
        "What cannot be concluded from the work done from this project is the best overall model for such a problem, although it might seem at first that the simpler models would be the way to go, the resulting accuracies produced tend to stagnate rather quickly once past 50%. Thus one could take the approach of the lower performing, higher complexity model route and try to solve its generalization issues instead. However as previously mentioned the project, does not provide enough information for a clear cut solution unless further work is done. \n",
        "\n",
        "A future development to the project is to continually update models as the new patches to DOTA2 arrive to make sure the predictions stay up to date with the changes to the game. Another development will be a recommendation engine similar to the one proposed in the Stanford project [1]. As creating application that can recommend heroes based off the models' past match predictions provides a more accessible way for players to solve the problem of which heroes to pick in order to win games.    "
      ],
      "metadata": {
        "id": "UEueyjIXQ843"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **References**\n",
        "Citations to similar projects, datasets, and API documentation can be seen below:"
      ],
      "metadata": {
        "id": "yaxqlm6kRcmb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1] Conley, K., Perry, D., \"How Does He Saw Me? A Recommendation Engine For Picking Heroes in DOTA 2\", *Stanford University*, 2013, [Online], Available:   https://cs229.stanford.edu/proj2013/PerryConley-HowDoesHeSawMeARecommendationEngineForPickingHeroesInDota2.pdf \n",
        "\n",
        "[2] OpenDota, OpenDota API V19.0.0, https://docs.opendota.com/ \n",
        "\n",
        "[3] Anzelmo, D., \"Dota 2 Matches\", *Kaggle*, 2020, [Online], Available: https://www.kaggle.com/datasets/devinanzelmo/dota-2-matches "
      ],
      "metadata": {
        "id": "ASlFzWBG7aCI"
      }
    }
  ]
}