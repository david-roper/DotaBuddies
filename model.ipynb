{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import warnings\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "np.set_printoptions(precision=3, suppress=True)  # Print as 0.001 instead of 9.876e-4\n",
    "torch.set_printoptions(precision=3, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding match data from file\n",
    "data = np.loadtxt('matchdata.csv',skiprows=1,delimiter=',')\n",
    "X_data = np.array(data[:,1:]).astype(np.int32)\n",
    "y_data = np.array(data[:,:1]).astype(np.int32)\n",
    "\n",
    "#turn all data into feature vector\n",
    "#feature vector creation\n",
    "X_val_trn = torch.zeros((20000,138*2),dtype=torch.float32)\n",
    "j = 0\n",
    "for d in X_data:\n",
    "    for i in range(len(d)):\n",
    "        if(i < len(d)/2):\n",
    "            h = d[i]\n",
    "            X_val_trn[j][h] += 1\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            h = d[i]\n",
    "            X_val_trn[j][h+137] += 1\n",
    "      \n",
    "    j += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn train test split\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_val_trn,y_data, test_size = 0.2, shuffle= True)\n",
    "\n",
    "#split train into train/validation set\n",
    "\n",
    "X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(X_train,y_train, test_size = 0.15, shuffle= True)\n",
    "\n",
    "X_train = torch.tensor(X_train,dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train,dtype=torch.float32)\n",
    "\n",
    "X_val = torch.tensor(X_val,dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val,dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor(X_test,dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test,dtype=torch.float32)\n",
    "#sklearn train test split\n",
    "#use test set to calculate error, CCE, accuracy etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model creation\n",
    "#addition of multiple hidden layers and drop rate to help with regularization\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(276,100),\n",
    "    torch.nn.Dropout(),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(100,50),\n",
    "    torch.nn.Dropout(),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50,1)\n",
    ")\n",
    "\n",
    "model2 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(276,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function and optimizer\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "optim = torch.optim.Adam(model.parameters(),lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "#epoch number\n",
    "num_epoch = 100\n",
    "next_epoch = 1\n",
    "batch_size = 100\n",
    "\n",
    "#training loop\n",
    "for epoch in range(next_epoch, next_epoch+num_epoch):\n",
    "    \n",
    "    \n",
    "    # Make an entire pass (an 'epoch') over the training data in batch_size chunks\n",
    "    for i in range(0, len(X_train), batch_size):        \n",
    "        X = X_train[i:i+batch_size]     # Slice out a mini-batch of features\n",
    "        y = y_train[i:i+batch_size]     # Slice out a mini-batch of targets\n",
    "        \n",
    "        y_pred = model(X)                   # Make predictions (final-layer activations)\n",
    "        \n",
    "        l = loss(y_pred, y)                 # Compute loss with respect to predictions\n",
    "        \n",
    "        model.zero_grad()                   # Reset all gradient accumulators to zero (PyTorch thing)\n",
    "        l.backward()                        # Compute gradient of loss wrt all parameters (backprop!)\n",
    "        optim.step()                    # Use the gradients to take a step with SGD.\n",
    "        \n",
    "    print(\"Epoch %2d: loss on final training batch: %.4f\" % (epoch, l.item()))\n",
    "    pred = torch.sign(model(X_val))\n",
    "    acc = torch.mean((pred == y_val).float())\n",
    "    \n",
    "    #create dire query\n",
    "    dire_X =  torch.index_select(X, 1, torch.LongTensor([*range(138,276)]))\n",
    "    dire_X = torch.cat((dire_X,torch.index_select(X, 1, torch.LongTensor([*range(0,138)]))),1)\n",
    "\n",
    "    \n",
    "    print(\"Epoch %2d: accuracy on validation set: %.4f\" % (epoch, acc))\n",
    "    \n",
    "    print(\"Epoch %2d: loss on validation set: %.4f\" % (epoch, loss(model(X_val), y_val)))\n",
    "\n",
    "next_epoch = epoch+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "model = sklearn.linear_model.LogisticRegression(random_state=0)\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
